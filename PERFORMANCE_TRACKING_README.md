# â±ï¸ SYSTÃˆME DE TRACKING PERFORMANCE RAG

## ğŸ¯ OBJECTIF

Mesurer en temps rÃ©el:
- âœ… **Temps d'exÃ©cution** de chaque Ã©tape du pipeline RAG
- âœ… **Tokens rÃ©els** utilisÃ©s par le LLM (70B/8B)
- âœ… **CoÃ»t exact** par requÃªte en USD
- âœ… **Affichage en ROUGE** dans les logs serveur

## ğŸ“¦ FICHIERS CRÃ‰Ã‰S

### 1. `core/rag_performance_tracker.py`
SystÃ¨me de tracking complet avec:
- Mesure temps de chaque Ã©tape
- Calcul coÃ»ts rÃ©els par modÃ¨le LLM
- Affichage rÃ©sumÃ© en ROUGE

### 2. `core/llm_client.py` (MODIFIÃ‰)
- Extraction tokens usage de l'API Groq
- Retourne `{response, usage, model}`

### 3. `core/universal_rag_engine.py` (MODIFIÃ‰)
- IntÃ©gration tracker dans chaque Ã©tape
- Passage request_id

### 4. `app.py` (MODIFIÃ‰)
- Initialisation tracker au dÃ©but
- Affichage rÃ©sumÃ© ROUGE Ã  la fin
- Sauvegarde performance dans logs JSON

## ğŸš€ UTILISATION

### **Automatique**
Le systÃ¨me fonctionne automatiquement pour chaque requÃªte `/chat`.

### **RÃ©sultat dans les logs serveur:**

```
================================================================================
â±ï¸  PERFORMANCE TRACKING - a1b2c3d4
================================================================================
ğŸ• DURÃ‰E TOTALE: 11450.23ms (11.45s)

ğŸ“Š Ã‰TAPES DU PIPELINE:
  â”œâ”€ endpoint_init: 2.15ms
  â”œâ”€ search_sources: 3245.67ms | {'documents_found': 5}
  â”œâ”€ llm_generation: 7892.34ms | {'prompt_length': 2345}
  â””â”€ response_processing: 310.07ms

ğŸ¤– USAGE LLM:
  â”œâ”€ ModÃ¨le: llama-3.3-70b-versatile
  â”œâ”€ Tokens prompt: 2,345
  â”œâ”€ Tokens completion: 156
  â”œâ”€ Tokens total: 2,501
  â”œâ”€ CoÃ»t prompt: $0.001384
  â”œâ”€ CoÃ»t completion: $0.000123
  â””â”€ COÃ›T TOTAL: $0.001507

ğŸ“ˆ ANALYSE:
  â”œâ”€ Ã‰tape la plus lente: llm_generation (7892.34ms)
  â””â”€ Overhead systÃ¨me: 0.00ms
================================================================================
```

## ğŸ’° COÃ›TS PAR MODÃˆLE

| ModÃ¨le | Input ($/1M tokens) | Output ($/1M tokens) |
|--------|---------------------|----------------------|
| **llama-3.3-70b-versatile** | $0.59 | $0.79 |
| **llama-3.1-8b-instant** | $0.05 | $0.08 |
| **openai/gpt-oss-120b** | $0.50 | $0.70 |

## ğŸ“Š LOGS JSON

Les performances sont aussi sauvegardÃ©es dans les logs JSON:

```json
{
  "request_id": "a1b2c3d4",
  "metadata": {
    "processing_time_ms": 11450.23,
    "performance": {
      "total_duration_ms": 11450.23,
      "steps": [
        {
          "name": "search_sources",
          "duration_ms": 3245.67,
          "metadata": {"documents_found": 5}
        },
        {
          "name": "llm_generation",
          "duration_ms": 7892.34
        }
      ],
      "llm_usage": {
        "model": "llama-3.3-70b-versatile",
        "prompt_tokens": 2345,
        "completion_tokens": 156,
        "total_tokens": 2501,
        "total_cost_usd": 0.001507
      }
    }
  }
}
```

## ğŸ” CONSULTER LES PERFORMANCES

### **Voir les logs JSON avec performance:**
```bash
cat logs/requests/2025-10-14.json | jq '.[] | {request_id, total_time: .metadata.processing_time_ms, llm_cost: .metadata.performance.llm_usage.total_cost_usd}'
```

### **Calculer coÃ»t total du jour:**
```bash
cat logs/requests/2025-10-14.json | jq '[.[] | .metadata.performance.llm_usage.total_cost_usd] | add'
```

### **Voir les requÃªtes les plus lentes:**
```bash
cat logs/requests/2025-10-14.json | jq 'sort_by(.metadata.processing_time_ms) | reverse | .[] | {request_id, time_ms: .metadata.processing_time_ms, message}'
```

### **Comparer 70B vs 8B:**
```bash
# RequÃªtes 70B
cat logs/requests/2025-10-14.json | jq '[.[] | select(.metadata.performance.llm_usage.model == "llama-3.3-70b-versatile")] | length'

# RequÃªtes 8B
cat logs/requests/2025-10-14.json | jq '[.[] | select(.metadata.performance.llm_usage.model == "llama-3.1-8b-instant")] | length'
```

## ğŸ“ˆ STATISTIQUES ATTENDUES

### **Temps moyen par Ã©tape:**
- `endpoint_init`: ~2ms
- `search_sources`: ~3-5s (MeiliSearch/Supabase)
- `llm_generation`: ~5-10s (70B) ou ~2-4s (8B)
- `response_processing`: ~300ms

### **CoÃ»t moyen par requÃªte:**
- **70B:** ~$0.0015 (1.5 milliÃ¨mes de dollar)
- **8B:** ~$0.0001 (0.1 milliÃ¨me de dollar)

### **Pour 1000 requÃªtes/jour:**
- **70B:** ~$1.50/jour
- **8B:** ~$0.10/jour

## ğŸ¯ AVANTAGES

âœ… **VisibilitÃ© totale** sur les performances
âœ… **CoÃ»ts rÃ©els** par requÃªte
âœ… **Identification** des goulots d'Ã©tranglement
âœ… **Optimisation** basÃ©e sur donnÃ©es rÃ©elles
âœ… **Affichage ROUGE** impossible Ã  manquer
âœ… **Historique complet** dans logs JSON

## ğŸ”§ PERSONNALISATION

### **Ajouter une nouvelle Ã©tape:**
```python
tracker = get_tracker(request_id)
tracker.start_step("ma_nouvelle_etape", custom_param="value")
# ... code ...
tracker.end_step(result_count=42)
```

### **Modifier les couleurs:**
Ã‰diter `rag_performance_tracker.py` ligne ~150:
```python
RED = '\033[91m'  # Rouge
YELLOW = '\033[93m'  # Jaune
GREEN = '\033[92m'  # Vert
```

---

**CrÃ©Ã© le:** 2025-10-14
**Version:** 1.0
**Auteur:** SystÃ¨me RAG Performance Tracking
