#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸš€ PARALLEL SEARCH ENGINE - PHASE 3
ParallÃ©lisation intelligente MeiliSearch + Supabase 384
StratÃ©gie: PrioritÃ© MeiliSearch + Backup Supabase instantanÃ©
"""

import asyncio
import time
import logging
from typing import List, Dict, Any, Optional

logger = logging.getLogger(__name__)

# âœ… TIMEOUT OPTIMAL CALIBRÃ‰ (PHASE 2 TERMINÃ‰E)
# BasÃ© sur mesures rÃ©elles: MAX(0.406s) + MARGE(0.5s) = 0.91s
MEILISEARCH_TIMEOUT = 0.91  # MeiliSearch ultra-rapide!


async def search_parallel_intelligent(
    query: str,
    company_id: str,
    limit: int = 5,
    timeout_meili: float = MEILISEARCH_TIMEOUT
) -> Dict[str, Any]:
    """
    ğŸš€ RECHERCHE PARALLÃ‰LISÃ‰E INTELLIGENTE (PHASE 3)
    
    StratÃ©gie:
    1. Lance MeiliSearch ET Supabase 384 en parallÃ¨le
    2. Attend MeiliSearch en prioritÃ© (timeout configurable)
    3. Si MeiliSearch Ã©choue/timeout â†’ Supabase dÃ©jÃ  prÃªt!
    4. Si MeiliSearch rÃ©ussit â†’ Annule Supabase (Ã©conomie)
    
    Args:
        query: RequÃªte utilisateur
        company_id: ID entreprise
        limit: Nombre max rÃ©sultats
        timeout_meili: Timeout MeiliSearch (dÃ©faut: 2.5s)
    
    Returns:
        {
            'documents': List[Dict],
            'method': str ('meilisearch' ou 'supabase_fallback'),
            'duration_ms': float,
            'meili_duration_ms': Optional[float],
            'supabase_duration_ms': Optional[float]
        }
    """
    
    start_time = time.time()
    
    logger.info(f"ğŸš€ [PARALLEL_SEARCH] Lancement parallÃ¨le pour: '{query[:50]}...'")
    
    # âœ… LANCER LES DEUX RECHERCHES EN PARALLÃˆLE
    meili_task = asyncio.create_task(_search_meilisearch(query, company_id, limit))
    supabase_task = asyncio.create_task(_search_supabase_384(query, company_id, limit))
    
    meili_duration = None
    supabase_duration = None
    
    try:
        # âœ… ATTENDRE MEILISEARCH EN PRIORITÃ‰ (avec timeout)
        meili_start = time.time()
        meili_results = await asyncio.wait_for(meili_task, timeout=timeout_meili)
        meili_duration = (time.time() - meili_start) * 1000
        
        # âœ… MEILISEARCH A RÃ‰USSI
        if meili_results and len(meili_results) > 0:
            logger.info(f"âœ… [PARALLEL_SEARCH] MeiliSearch: {len(meili_results)} docs en {meili_duration:.2f}ms")
            
            # Annuler Supabase (Ã©conomie ressources)
            supabase_task.cancel()
            
            total_duration = (time.time() - start_time) * 1000
            
            return {
                'documents': meili_results,
                'method': 'meilisearch',
                'duration_ms': total_duration,
                'meili_duration_ms': meili_duration,
                'supabase_duration_ms': None
            }
        
        else:
            # âš ï¸ MEILISEARCH 0 RÃ‰SULTATS â†’ Attendre Supabase
            logger.warning(f"âš ï¸ [PARALLEL_SEARCH] MeiliSearch: 0 docs â†’ Attente Supabase backup")
            
            supabase_start = time.time()
            supabase_results = await supabase_task
            supabase_duration = (time.time() - supabase_start) * 1000
            
            logger.info(f"âœ… [PARALLEL_SEARCH] Supabase backup: {len(supabase_results)} docs en {supabase_duration:.2f}ms")
            
            total_duration = (time.time() - start_time) * 1000
            
            return {
                'documents': supabase_results,
                'method': 'supabase_fallback',
                'duration_ms': total_duration,
                'meili_duration_ms': meili_duration,
                'supabase_duration_ms': supabase_duration
            }
    
    except asyncio.TimeoutError:
        # âŒ MEILISEARCH TIMEOUT â†’ Supabase dÃ©jÃ  en cours!
        logger.warning(f"â° [PARALLEL_SEARCH] MeiliSearch timeout ({timeout_meili}s) â†’ Supabase backup")
        
        supabase_start = time.time()
        supabase_results = await supabase_task
        supabase_duration = (time.time() - supabase_start) * 1000
        
        logger.info(f"âœ… [PARALLEL_SEARCH] Supabase backup: {len(supabase_results)} docs en {supabase_duration:.2f}ms")
        
        total_duration = (time.time() - start_time) * 1000
        
        return {
            'documents': supabase_results,
            'method': 'supabase_fallback_timeout',
            'duration_ms': total_duration,
            'meili_duration_ms': timeout_meili * 1000,  # Timeout
            'supabase_duration_ms': supabase_duration
        }
    
    except Exception as e:
        # âŒ ERREUR CRITIQUE â†’ Fallback Supabase
        logger.error(f"âŒ [PARALLEL_SEARCH] Erreur: {e}")
        
        try:
            supabase_results = await supabase_task
            total_duration = (time.time() - start_time) * 1000
            
            return {
                'documents': supabase_results,
                'method': 'supabase_fallback_error',
                'duration_ms': total_duration,
                'meili_duration_ms': None,
                'supabase_duration_ms': None
            }
        except:
            # Dernier recours: retourner vide
            total_duration = (time.time() - start_time) * 1000
            return {
                'documents': [],
                'method': 'error',
                'duration_ms': total_duration,
                'meili_duration_ms': None,
                'supabase_duration_ms': None
            }


async def _search_meilisearch(query: str, company_id: str, limit: int) -> List[Dict[str, Any]]:
    """Recherche MeiliSearch (rapide)"""
    try:
        from database.vector_store_clean_v2 import search_all_indexes_parallel
        import json
        
        results_json = await search_all_indexes_parallel(
            query=query,
            company_id=company_id,
            limit=limit
        )
        
        # Parser JSON response
        try:
            results = json.loads(results_json) if isinstance(results_json, str) else results_json
            if isinstance(results, dict):
                results = results.get('results', [])
        except:
            results = []
        
        return results or []
    
    except Exception as e:
        logger.error(f"âŒ [MEILI] Erreur: {e}")
        return []


async def _search_supabase_384(query: str, company_id: str, limit: int) -> List[Dict[str, Any]]:
    """Recherche Supabase 384 (fallback, modÃ¨le prÃ©-chargÃ©)"""
    try:
        from core.supabase_optimized_384 import get_supabase_optimized_384
        
        # âœ… Instance singleton avec modÃ¨le prÃ©-chargÃ© (PHASE 1)
        supabase_384 = get_supabase_optimized_384(use_float16=True)
        
        results = await supabase_384.search_documents(
            query=query,
            company_id=company_id,
            limit=limit
        )
        
        return results or []
    
    except Exception as e:
        logger.error(f"âŒ [SUPABASE_384] Erreur: {e}")
        return []


# ============================================================================
# FONCTION HELPER POUR INTÃ‰GRATION FACILE
# ============================================================================

async def search_documents_optimized(
    query: str,
    company_id: str,
    limit: int = 5
) -> List[Dict[str, Any]]:
    """
    ğŸ¯ FONCTION PRINCIPALE - Recherche optimisÃ©e parallÃ¨le
    
    Remplace l'ancienne fonction search_documents_parallel_global
    Utilise la nouvelle stratÃ©gie parallÃ©lisÃ©e intelligente
    
    Returns:
        Liste des documents trouvÃ©s
    """
    result = await search_parallel_intelligent(
        query=query,
        company_id=company_id,
        limit=limit
    )
    
    # Logger les mÃ©triques
    logger.info(
        f"ğŸ“Š [SEARCH_OPTIMIZED] MÃ©thode: {result['method']} | "
        f"Docs: {len(result['documents'])} | "
        f"Temps: {result['duration_ms']:.2f}ms"
    )
    
    return result['documents']
