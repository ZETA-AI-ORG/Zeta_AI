#!/usr/bin/env python3
"""
üîÑ SYST√àME DE FALLBACK INTELLIGENT 2024
Gestion intelligente des √©checs et des r√©ponses de secours
"""

import asyncio
import time
import json
import re
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass
from enum import Enum
import logging
from datetime import datetime

from .advanced_intent_classifier import IntentType, IntentResult
from .llm_client import GroqLLMClient

logger = logging.getLogger(__name__)

class FallbackType(Enum):
    """Types de fallback"""
    NO_DOCUMENTS = "no_documents"
    LOW_CONFIDENCE = "low_confidence"
    VALIDATION_FAILED = "validation_failed"
    LLM_ERROR = "llm_error"
    TIMEOUT = "timeout"
    RATE_LIMIT = "rate_limit"
    UNKNOWN_ERROR = "unknown_error"

@dataclass
class FallbackResponse:
    """R√©ponse de fallback intelligente"""
    response: str
    fallback_type: FallbackType
    confidence: float
    is_helpful: bool
    suggested_actions: List[str]
    escalation_required: bool
    processing_time_ms: float

class IntelligentFallbackSystem:
    """
    üîÑ SYST√àME DE FALLBACK INTELLIGENT 2024
    
    Fonctionnalit√©s avanc√©es :
    1. D√©tection intelligente des types d'√©chec
    2. R√©ponses contextuelles adaptatives
    3. Escalation automatique
    4. Apprentissage des patterns d'√©chec
    5. Suggestions d'actions utilisateur
    """
    
    def __init__(self):
        self.llm_client = GroqLLMClient()
        self.start_time = datetime.now()
        
        # Templates de r√©ponses de fallback
        self.fallback_templates = self._build_fallback_templates()
        
        # Patterns d'√©chec
        self.failure_patterns = self._build_failure_patterns()
        
        # Cache des fallbacks
        self.fallback_cache = {}
        self.cache_ttl = 3600  # 1 heure
        
        # Statistiques d'√©chec
        self.failure_stats = {}
        
        logger.info("[FALLBACK_SYSTEM] Syst√®me de fallback intelligent initialis√©")
    
    def _build_fallback_templates(self) -> Dict[FallbackType, Dict[str, str]]:
        """Construit les templates de r√©ponses de fallback"""
        return {
            FallbackType.NO_DOCUMENTS: {
                'social': "Bonjour ! Je suis l√† pour vous aider. Que puis-je faire pour vous ?",
                'business': "Je n'ai pas trouv√© d'informations sp√©cifiques sur votre demande. Pouvez-vous me donner plus de d√©tails ?",
                'critical': "Pour cette question technique, je recommande de contacter directement notre service client qui pourra vous donner une r√©ponse pr√©cise."
            },
            FallbackType.LOW_CONFIDENCE: {
                'social': "Je ne suis pas s√ªr de bien comprendre. Pouvez-vous reformuler votre question ?",
                'business': "Je voudrais m'assurer de bien r√©pondre √† votre question. Pouvez-vous me donner plus de contexte ?",
                'critical': "Cette question n√©cessite une expertise technique. Je vous recommande de contacter notre √©quipe sp√©cialis√©e."
            },
            FallbackType.VALIDATION_FAILED: {
                'social': "Je ne peux pas r√©pondre √† cette question de mani√®re appropri√©e. Comment puis-je vous aider autrement ?",
                'business': "Je ne peux pas confirmer cette information. Pouvez-vous contacter notre service client ?",
                'critical': "Pour des informations techniques pr√©cises, je recommande de contacter directement nos experts."
            },
            FallbackType.LLM_ERROR: {
                'social': "Je rencontre une difficult√© technique. Pouvez-vous reformuler votre question ?",
                'business': "Je rencontre un probl√®me technique. Pouvez-vous r√©essayer dans quelques instants ?",
                'critical': "Syst√®me temporairement indisponible. Veuillez contacter notre support technique."
            },
            FallbackType.TIMEOUT: {
                'social': "Je prends un peu plus de temps √† r√©pondre. Pouvez-vous patienter ?",
                'business': "Le traitement de votre demande prend plus de temps que pr√©vu. Pouvez-vous r√©essayer ?",
                'critical': "Syst√®me surcharg√©. Veuillez contacter notre support pour une assistance imm√©diate."
            },
            FallbackType.RATE_LIMIT: {
                'social': "Je re√ßois beaucoup de demandes en ce moment. Pouvez-vous r√©essayer dans quelques minutes ?",
                'business': "Syst√®me temporairement surcharg√©. Veuillez r√©essayer dans quelques instants.",
                'critical': "Trafic √©lev√© d√©tect√©. Pour une assistance prioritaire, contactez notre support."
            },
            FallbackType.UNKNOWN_ERROR: {
                'social': "Je rencontre une difficult√© inattendue. Comment puis-je vous aider autrement ?",
                'business': "Une erreur inattendue s'est produite. Pouvez-vous r√©essayer ?",
                'critical': "Erreur syst√®me d√©tect√©e. Veuillez contacter notre support technique."
            }
        }
    
    def _build_failure_patterns(self) -> Dict[str, List[str]]:
        """Construit les patterns de d√©tection d'√©chec"""
        return {
            'no_documents': [
                'aucun document trouv√©',
                'no documents found',
                'aucun r√©sultat',
                'no results'
            ],
            'low_confidence': [
                'confidence too low',
                'confiance trop faible',
                'uncertain',
                'incertain'
            ],
            'validation_failed': [
                'validation failed',
                'validation √©chou√©e',
                'rejected',
                'rejet√©'
            ],
            'llm_error': [
                'llm error',
                'erreur llm',
                'model error',
                'erreur mod√®le'
            ],
            'timeout': [
                'timeout',
                'd√©lai d√©pass√©',
                'time limit exceeded',
                'limite de temps'
            ],
            'rate_limit': [
                'rate limit',
                'limite de taux',
                'too many requests',
                'trop de requ√™tes'
            ]
        }
    
    async def generate_fallback_response(
        self,
        user_query: str,
        intent_result: IntentResult,
        error_context: Dict[str, Any] = None,
        company_context: Dict[str, Any] = None
    ) -> FallbackResponse:
        """
        üîÑ G√âN√âRATION DE R√âPONSE DE FALLBACK INTELLIGENTE
        
        Args:
            user_query: Question utilisateur
            intent_result: R√©sultat de classification d'intention
            error_context: Contexte de l'erreur
            company_context: Contexte de l'entreprise
            
        Returns:
            FallbackResponse: R√©ponse de fallback intelligente
        """
        start_time = time.time()
        
        # D√©tection du type de fallback
        fallback_type = self._detect_fallback_type(error_context)
        
        # D√©termination du niveau de criticit√©
        criticality_level = self._determine_criticality_level(intent_result, fallback_type)
        
        # G√©n√©ration de la r√©ponse adaptative
        response = await self._generate_adaptive_response(
            user_query, intent_result, fallback_type, criticality_level, company_context
        )
        
        # G√©n√©ration des suggestions d'actions
        suggested_actions = self._generate_suggested_actions(
            intent_result, fallback_type, criticality_level
        )
        
        # D√©termination de l'escalation
        escalation_required = self._requires_escalation(fallback_type, criticality_level)
        
        # Calcul de la confiance
        confidence = self._calculate_fallback_confidence(intent_result, fallback_type)
        
        # Mise √† jour des statistiques
        self._update_failure_stats(fallback_type, intent_result.primary_intent)
        
        result = FallbackResponse(
            response=response,
            fallback_type=fallback_type,
            confidence=confidence,
            is_helpful=True,
            suggested_actions=suggested_actions,
            escalation_required=escalation_required,
            processing_time_ms=(time.time() - start_time) * 1000
        )
        
        logger.info(f"[FALLBACK_SYSTEM] Fallback g√©n√©r√©: {fallback_type.value} (conf: {confidence:.2f})")
        
        return result
    
    def _detect_fallback_type(self, error_context: Dict[str, Any] = None) -> FallbackType:
        """D√©tecte le type de fallback bas√© sur le contexte d'erreur"""
        if not error_context:
            return FallbackType.UNKNOWN_ERROR
        
        error_message = str(error_context.get('error', '')).lower()
        
        # D√©tection par patterns
        for fallback_type, patterns in self.failure_patterns.items():
            if any(pattern in error_message for pattern in patterns):
                return FallbackType(fallback_type)
        
        # D√©tection par type d'erreur
        error_type = error_context.get('error_type', '')
        if 'timeout' in error_type.lower():
            return FallbackType.TIMEOUT
        elif 'rate_limit' in error_type.lower():
            return FallbackType.RATE_LIMIT
        elif 'llm' in error_type.lower():
            return FallbackType.LLM_ERROR
        elif 'validation' in error_type.lower():
            return FallbackType.VALIDATION_FAILED
        elif 'no_documents' in error_message:
            return FallbackType.NO_DOCUMENTS
        elif 'confidence' in error_message:
            return FallbackType.LOW_CONFIDENCE
        
        return FallbackType.UNKNOWN_ERROR
    
    def _determine_criticality_level(self, intent_result: IntentResult, fallback_type: FallbackType) -> str:
        """D√©termine le niveau de criticit√©"""
        # Intentions critiques
        if intent_result.primary_intent in [IntentType.TECHNICAL_SPECS, IntentType.MEDICAL_ADVICE]:
            return 'critical'
        
        # Intentions m√©tier
        if intent_result.primary_intent in [IntentType.PRODUCT_INQUIRY, IntentType.PRICING_INFO, IntentType.DELIVERY_INFO]:
            return 'business'
        
        # Intentions sociales
        if intent_result.primary_intent in [IntentType.SOCIAL_GREETING, IntentType.POLITENESS, IntentType.GENERAL_CONVERSATION]:
            return 'social'
        
        return 'business'
    
    async def _generate_adaptive_response(
        self,
        user_query: str,
        intent_result: IntentResult,
        fallback_type: FallbackType,
        criticality_level: str,
        company_context: Dict[str, Any] = None
    ) -> str:
        """G√©n√®re une r√©ponse adaptative bas√©e sur le contexte"""
        
        # R√©cup√©ration du template de base
        template = self.fallback_templates[fallback_type][criticality_level]
        
        # Personnalisation bas√©e sur l'entreprise
        if company_context:
            company_name = company_context.get('company_name', 'notre entreprise')
            ai_name = company_context.get('ai_name', 'votre assistant')
            
            # Remplacement des placeholders
            template = template.replace('notre entreprise', company_name)
            template = template.replace('votre assistant', ai_name)
        
        # Personnalisation bas√©e sur l'intention
        if intent_result.primary_intent == IntentType.SOCIAL_GREETING:
            template = f"Bonjour ! {template}"
        elif intent_result.primary_intent == IntentType.POLITENESS:
            template = f"Merci pour votre patience. {template}"
        
        # G√©n√©ration de r√©ponse LLM si n√©cessaire
        if fallback_type in [FallbackType.LLM_ERROR, FallbackType.UNKNOWN_ERROR]:
            try:
                llm_response = await self._generate_llm_fallback_response(
                    user_query, intent_result, template, company_context
                )
                if llm_response:
                    return llm_response
            except Exception as e:
                logger.warning(f"[FALLBACK_SYSTEM] Erreur g√©n√©ration LLM: {e}")
        
        return template
    
    async def _generate_llm_fallback_response(
        self,
        user_query: str,
        intent_result: IntentResult,
        base_template: str,
        company_context: Dict[str, Any] = None
    ) -> Optional[str]:
        """G√©n√®re une r√©ponse de fallback via LLM"""
        
        prompt = f"""Tu es un assistant client professionnel. G√©n√®re une r√©ponse de fallback appropri√©e.

CONTEXTE:
- Question utilisateur: "{user_query}"
- Intention d√©tect√©e: {intent_result.primary_intent.value}
- Template de base: "{base_template}"

CONTEXTE ENTREPRISE:
{json.dumps(company_context, ensure_ascii=False) if company_context else "Non disponible"}

R√àGLES:
1. Sois professionnel et empathique
2. Reste dans le contexte de l'intention d√©tect√©e
3. Propose des alternatives utiles
4. Garde la r√©ponse concise (max 100 mots)

R√âPONSE:"""
        
        try:
            response = await asyncio.wait_for(
                self.llm_client.complete(prompt, temperature=0.7, max_tokens=150),
                timeout=5.0
            )
            return response.strip()
        except Exception as e:
            logger.warning(f"[FALLBACK_SYSTEM] Erreur LLM fallback: {e}")
            return None
    
    def _generate_suggested_actions(
        self,
        intent_result: IntentResult,
        fallback_type: FallbackType,
        criticality_level: str
    ) -> List[str]:
        """G√©n√®re des suggestions d'actions pour l'utilisateur"""
        
        suggestions = []
        
        # Suggestions bas√©es sur l'intention
        if intent_result.primary_intent == IntentType.PRODUCT_INQUIRY:
            suggestions.extend([
                "Consultez notre catalogue en ligne",
                "Contactez notre service commercial",
                "Visitez notre magasin"
            ])
        elif intent_result.primary_intent == IntentType.PRICING_INFO:
            suggestions.extend([
                "Demandez un devis personnalis√©",
                "Contactez notre service commercial",
                "Consultez nos offres promotionnelles"
            ])
        elif intent_result.primary_intent == IntentType.DELIVERY_INFO:
            suggestions.extend([
                "V√©rifiez les zones de livraison",
                "Contactez notre service logistique",
                "Consultez nos conditions de livraison"
            ])
        elif intent_result.primary_intent == IntentType.SUPPORT_CONTACT:
            suggestions.extend([
                "Appelez notre service client",
                "Envoyez un email de support",
                "Utilisez notre chat en direct"
            ])
        
        # Suggestions bas√©es sur le type de fallback
        if fallback_type == FallbackType.NO_DOCUMENTS:
            suggestions.extend([
                "Reformulez votre question",
                "Donnez plus de d√©tails",
                "Contactez notre support"
            ])
        elif fallback_type == FallbackType.LLM_ERROR:
            suggestions.extend([
                "R√©essayez dans quelques instants",
                "Contactez notre support technique",
                "Utilisez un autre canal de communication"
            ])
        elif fallback_type == FallbackType.TIMEOUT:
            suggestions.extend([
                "R√©essayez plus tard",
                "Contactez notre support",
                "Utilisez notre site web"
            ])
        
        # Suggestions bas√©es sur la criticit√©
        if criticality_level == 'critical':
            suggestions.extend([
                "Contactez imm√©diatement notre support",
                "Appelez notre num√©ro d'urgence",
                "Demandez √† parler √† un expert"
            ])
        
        return suggestions[:5]  # Limiter √† 5 suggestions
    
    def _requires_escalation(self, fallback_type: FallbackType, criticality_level: str) -> bool:
        """D√©termine si une escalation est n√©cessaire"""
        
        # Escalation pour les erreurs critiques
        if fallback_type in [FallbackType.LLM_ERROR, FallbackType.UNKNOWN_ERROR]:
            return True
        
        # Escalation pour les intentions critiques
        if criticality_level == 'critical':
            return True
        
        # Escalation pour les erreurs r√©p√©t√©es
        if self._is_repeated_failure(fallback_type):
            return True
        
        return False
    
    def _is_repeated_failure(self, fallback_type: FallbackType) -> bool:
        """V√©rifie si c'est un √©chec r√©p√©t√©"""
        key = f"{fallback_type.value}_count"
        count = self.failure_stats.get(key, 0)
        return count >= 3  # Seuil de 3 √©checs cons√©cutifs
    
    def _calculate_fallback_confidence(
        self,
        intent_result: IntentResult,
        fallback_type: FallbackType
    ) -> float:
        """Calcule la confiance de la r√©ponse de fallback"""
        
        base_confidence = 0.5
        
        # Ajustement bas√© sur l'intention
        if intent_result.primary_intent in [IntentType.SOCIAL_GREETING, IntentType.POLITENESS]:
            base_confidence += 0.3
        elif intent_result.primary_intent in [IntentType.PRODUCT_INQUIRY, IntentType.PRICING_INFO]:
            base_confidence += 0.2
        
        # Ajustement bas√© sur le type de fallback
        if fallback_type == FallbackType.NO_DOCUMENTS:
            base_confidence += 0.2
        elif fallback_type == FallbackType.LOW_CONFIDENCE:
            base_confidence += 0.1
        elif fallback_type in [FallbackType.LLM_ERROR, FallbackType.UNKNOWN_ERROR]:
            base_confidence -= 0.2
        
        return max(0.0, min(1.0, base_confidence))
    
    def _update_failure_stats(self, fallback_type: FallbackType, intent: IntentType):
        """Met √† jour les statistiques d'√©chec"""
        key = f"{fallback_type.value}_count"
        self.failure_stats[key] = self.failure_stats.get(key, 0) + 1
        
        # Reset p√©riodique des compteurs
        if self.failure_stats[key] > 10:
            self.failure_stats[key] = 0
    
    def get_failure_stats(self) -> Dict[str, Any]:
        """Retourne les statistiques d'√©chec"""
        return {
            'stats': self.failure_stats.copy(),
            'total_failures': sum(self.failure_stats.values()),
            'most_common_failure': max(self.failure_stats.items(), key=lambda x: x[1])[0] if self.failure_stats else None
        }
    
    def clear_cache(self):
        """Vide le cache de fallback"""
        self.fallback_cache.clear()
        logger.info("[FALLBACK_SYSTEM] Cache de fallback vid√©")

# Instance globale
fallback_system = IntelligentFallbackSystem()

# Fonction d'interface pour compatibilit√©
async def generate_intelligent_fallback(
    user_query: str,
    intent_result: IntentResult,
    error_context: Dict[str, Any] = None,
    company_context: Dict[str, Any] = None
) -> FallbackResponse:
    """Interface simplifi√©e pour la g√©n√©ration de fallback"""
    return await fallback_system.generate_fallback_response(
        user_query, intent_result, error_context, company_context
    )

if __name__ == "__main__":
    # Test du syst√®me de fallback
    async def test_fallback():
        from .advanced_intent_classifier import IntentType, IntentResult
        
        # Test avec intention sociale
        social_intent = IntentResult(
            primary_intent=IntentType.SOCIAL_GREETING,
            confidence=0.9,
            all_intents={},
            requires_documents=False,
            is_critical=False,
            fallback_required=False,
            context_hints=[],
            processing_time_ms=0.0
        )
        
        result = await generate_intelligent_fallback(
            "Comment tu t'appelles ?",
            social_intent,
            {'error': 'no_documents found'},
            {'company_name': 'Rue du Gros', 'ai_name': 'Gamma'}
        )
        
        print(f"Fallback: {result.response}")
        print(f"Actions sugg√©r√©es: {result.suggested_actions}")
    
    asyncio.run(test_fallback())
