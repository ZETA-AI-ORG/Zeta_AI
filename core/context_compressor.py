"""
ğŸ—œï¸ CONTEXT COMPRESSOR - Compression intelligente du contexte
RÃ©duit encore plus le contexte en supprimant redondances et infos inutiles
"""

import re
from typing import List, Dict, Any
import logging

logger = logging.getLogger(__name__)


def compress_context(docs: List[Dict[str, Any]], max_chars: int = 3000) -> List[Dict[str, Any]]:
    """
    Compresse le contexte en supprimant redondances
    
    Args:
        docs: Documents extraits
        max_chars: Limite de caractÃ¨res totale
        
    Returns:
        Documents compressÃ©s
    """
    if not docs:
        return []
    
    total_chars = sum(len(doc.get("content", "")) for doc in docs)
    
    if total_chars <= max_chars:
        logger.info(f"ğŸ“Š [COMPRESSION] Pas nÃ©cessaire ({total_chars} <= {max_chars})")
        return docs
    
    logger.info(f"ğŸ—œï¸ [COMPRESSION] RÃ©duction {total_chars} â†’ {max_chars} chars...")
    
    compressed_docs = []
    current_chars = 0
    seen_content = set()  # DÃ©tecter doublons
    
    for doc in docs:
        content = doc.get("content", "")
        
        # 1. Supprimer lignes vides multiples
        content = re.sub(r'\n\n+', '\n\n', content)
        
        # 2. Supprimer espaces inutiles
        content = re.sub(r' +', ' ', content)
        
        # 3. DÃ©tecter contenu dupliquÃ© (similaritÃ© simple)
        content_hash = _get_content_hash(content)
        if content_hash in seen_content:
            logger.debug(f"ğŸ—œï¸ [COMPRESSION] Doublon dÃ©tectÃ©, skip")
            continue
        seen_content.add(content_hash)
        
        # 4. Tronquer si nÃ©cessaire
        remaining_chars = max_chars - current_chars
        if len(content) > remaining_chars:
            content = content[:remaining_chars] + "..."
            logger.debug(f"ğŸ—œï¸ [COMPRESSION] TronquÃ© Ã  {remaining_chars} chars")
        
        doc_copy = doc.copy()
        doc_copy["content"] = content
        doc_copy["compressed"] = True
        compressed_docs.append(doc_copy)
        
        current_chars += len(content)
        
        if current_chars >= max_chars:
            logger.info(f"ğŸ—œï¸ [COMPRESSION] Limite atteinte ({current_chars}/{max_chars})")
            break
    
    reduction = ((total_chars - current_chars) / total_chars * 100) if total_chars > 0 else 0
    logger.info(f"âœ… [COMPRESSION] {len(docs)} â†’ {len(compressed_docs)} docs, -{reduction:.1f}% chars")
    
    return compressed_docs


def _get_content_hash(content: str) -> str:
    """Hash simple pour dÃ©tecter doublons"""
    # Normaliser et hasher les 100 premiers caractÃ¨res
    normalized = re.sub(r'\s+', ' ', content.lower())[:100]
    return str(hash(normalized))


def remove_redundant_info(content: str) -> str:
    """
    Supprime infos redondantes dans un document
    
    Exemples:
    - Headers rÃ©pÃ©tÃ©s
    - Notes en double
    - Sections vides
    """
    lines = content.split("\n")
    cleaned_lines = []
    seen_lines = set()
    
    for line in lines:
        line_stripped = line.strip()
        
        # Skip lignes vides
        if not line_stripped:
            continue
        
        # Skip lignes rÃ©pÃ©tÃ©es
        line_normalized = re.sub(r'\s+', ' ', line_stripped.lower())
        if line_normalized in seen_lines:
            continue
        seen_lines.add(line_normalized)
        
        # Skip headers gÃ©nÃ©riques rÃ©pÃ©tÃ©s
        if re.match(r'^(PRODUIT|LIVRAISON|PAIEMENT|CONTACT):?\s*$', line_stripped, re.IGNORECASE):
            continue
        
        cleaned_lines.append(line)
    
    return "\n".join(cleaned_lines)


def smart_truncate(text: str, max_length: int) -> str:
    """
    Tronque intelligemment (coupe Ã  la phrase)
    """
    if len(text) <= max_length:
        return text
    
    # Chercher derniÃ¨re phrase complÃ¨te
    truncated = text[:max_length]
    
    # Chercher dernier point/retour ligne
    last_period = max(truncated.rfind('.'), truncated.rfind('\n'))
    
    if last_period > max_length * 0.7:  # Au moins 70% du texte
        return truncated[:last_period + 1]
    
    # Sinon couper brutalement
    return truncated + "..."


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TESTS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    test_docs = [
        {
            "content": """PRODUIT: Couches Ã  pression


Taille 3 - 6 Ã  11 kg - 300 couches | 22.900 F CFA
   - Prix: 22 900 FCFA
   - QuantitÃ©: 300 pcs


NOTES IMPORTANTES:
Vendu par lot de 300 minimum"""
        },
        {
            "content": """LIVRAISON - ZONES CENTRALES


- AngrÃ© : 1 500 FCFA
- Cocody : 1 500 FCFA


DÃ©lais: Livraison le jour mÃªme si commande avant 13h"""
        }
    ]
    
    compressed = compress_context(test_docs, max_chars=200)
    
    print("ğŸ“Š AVANT:")
    for doc in test_docs:
        print(f"  - {len(doc['content'])} chars")
    
    print("\nğŸ“Š APRÃˆS:")
    for doc in compressed:
        print(f"  - {len(doc['content'])} chars")
        print(f"    {doc['content'][:50]}...")
