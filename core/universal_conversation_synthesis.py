#!/usr/bin/env python3
"""
ðŸ§  SYNTHÃˆSE CONVERSATIONNELLE UNIVERSELLE
BasÃ© sur les meilleures pratiques d'OpenAI, Anthropic et LangChain
"""

import json
import asyncio
from typing import Dict, List, Optional, Any
from datetime import datetime, timedelta
from dataclasses import dataclass, asdict

@dataclass
class ConversationExchange:
    """Un Ã©change dans la conversation"""
    timestamp: datetime
    user_message: str
    assistant_response: str
    extracted_entities: Dict[str, Any]
    importance_score: float  # 0-1, calculÃ© automatiquement

@dataclass
class ConversationSynthesis:
    """SynthÃ¨se d'une conversation"""
    user_id: str
    company_id: str
    session_start: datetime
    last_update: datetime
    
    # SynthÃ¨se progressive
    current_summary: str
    key_facts: Dict[str, Any]  # Faits importants extraits
    user_preferences: Dict[str, Any]  # PrÃ©fÃ©rences dÃ©tectÃ©es
    pending_actions: List[str]  # Actions en attente
    
    # Ã‰changes rÃ©cents (gardÃ©s intÃ©gralement)
    recent_exchanges: List[ConversationExchange]
    
    # MÃ©triques
    total_exchanges: int
    synthesis_version: int

class UniversalConversationSynthesis:
    """
    ðŸŒ SYNTHÃˆSE CONVERSATIONNELLE UNIVERSELLE
    
    Principe : Comme les grands acteurs du domaine
    - Garde les Ã©changes rÃ©cents intÃ©gralement
    - SynthÃ©tise progressivement les anciens
    - Extrait automatiquement les entitÃ©s importantes
    - S'adapte Ã  n'importe quel domaine mÃ©tier
    """
    
    def __init__(self, max_recent_exchanges: int = 5, synthesis_threshold: int = 10):
        self.max_recent_exchanges = max_recent_exchanges
        self.synthesis_threshold = synthesis_threshold
        self.active_syntheses: Dict[str, ConversationSynthesis] = {}
        
        # Prompts universels pour synthÃ¨se
        self.synthesis_prompt_template = """
Tu es un expert en synthÃ¨se conversationnelle. Analyse cette conversation et crÃ©e un rÃ©sumÃ© CONCIS et FACTUEL.

CONVERSATION PRÃ‰CÃ‰DENTE:
{previous_summary}

NOUVEAUX Ã‰CHANGES:
{new_exchanges}

INSTRUCTIONS:
1. Garde UNIQUEMENT les informations critiques pour la suite de la conversation
2. Extrait les faits importants (prix, quantitÃ©s, prÃ©fÃ©rences, dÃ©cisions)
3. Note les actions en attente ou promesses faites
4. Ignore les politesses et rÃ©pÃ©titions
5. Reste neutre et factuel

SYNTHÃˆSE MISE Ã€ JOUR:
"""

        self.entity_extraction_prompt = """
Extrait les entitÃ©s importantes de cet Ã©change commercial:

USER: {user_message}
ASSISTANT: {assistant_response}

Identifie et structure:
- Produits/services mentionnÃ©s
- QuantitÃ©s, prix, tailles
- Lieux, adresses, zones
- PrÃ©fÃ©rences exprimÃ©es
- DÃ©cisions prises
- Actions promises

Format JSON:
{{"entities": {{"products": [], "quantities": [], "prices": [], "locations": [], "preferences": [], "decisions": [], "actions": []}}}}
"""

    def get_synthesis_key(self, user_id: str, company_id: str) -> str:
        """GÃ©nÃ¨re la clÃ© unique pour une synthÃ¨se"""
        return f"{company_id}_{user_id}"

    async def add_exchange(self, user_id: str, company_id: str, 
                          user_message: str, assistant_response: str,
                          llm_client) -> ConversationSynthesis:
        """
        ðŸ”„ Ajoute un nouvel Ã©change et met Ã  jour la synthÃ¨se
        """
        synthesis_key = self.get_synthesis_key(user_id, company_id)
        
        # RÃ©cupÃ©rer ou crÃ©er la synthÃ¨se
        if synthesis_key not in self.active_syntheses:
            self.active_syntheses[synthesis_key] = ConversationSynthesis(
                user_id=user_id,
                company_id=company_id,
                session_start=datetime.now(),
                last_update=datetime.now(),
                current_summary="",
                key_facts={},
                user_preferences={},
                pending_actions=[],
                recent_exchanges=[],
                total_exchanges=0,
                synthesis_version=1
            )
        
        synthesis = self.active_syntheses[synthesis_key]
        
        # Extraire les entitÃ©s de l'Ã©change
        entities = await self._extract_entities(user_message, assistant_response, llm_client)
        importance = self._calculate_importance(user_message, assistant_response, entities)
        
        # CrÃ©er l'Ã©change
        exchange = ConversationExchange(
            timestamp=datetime.now(),
            user_message=user_message,
            assistant_response=assistant_response,
            extracted_entities=entities,
            importance_score=importance
        )
        
        # Ajouter aux Ã©changes rÃ©cents
        synthesis.recent_exchanges.append(exchange)
        synthesis.total_exchanges += 1
        synthesis.last_update = datetime.now()
        
        # DÃ©clencher synthÃ¨se si nÃ©cessaire
        if len(synthesis.recent_exchanges) > self.max_recent_exchanges:
            await self._perform_synthesis(synthesis, llm_client)
        
        # Mettre Ã  jour les faits clÃ©s
        self._update_key_facts(synthesis, entities)
        
        return synthesis

    async def _extract_entities(self, user_message: str, assistant_response: str, 
                               llm_client) -> Dict[str, Any]:
        """
        ðŸŽ¯ Extraction universelle d'entitÃ©s (sans hardcodage)
        """
        try:
            prompt = self.entity_extraction_prompt.format(
                user_message=user_message,
                assistant_response=assistant_response
            )
            
            response = await llm_client.complete(prompt, temperature=0.1, max_tokens=300)
            
            # GÃ©rer dict, tuple ou string
            if isinstance(response, dict):
                response_text = response.get("response", "")
            elif isinstance(response, tuple):
                response_text = response[0]
            else:
                response_text = response
            
            # Parser la rÃ©ponse JSON
            import re
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if json_match:
                return json.loads(json_match.group())
            
        except Exception as e:
            print(f"[ENTITY EXTRACTION] Erreur: {e}")
        
        return {"entities": {}}

    def _calculate_importance(self, user_message: str, assistant_response: str, 
                            entities: Dict[str, Any]) -> float:
        """
        ðŸ“Š Calcule l'importance d'un Ã©change (0-1)
        """
        importance = 0.0
        
        # Facteurs d'importance
        user_lower = user_message.lower()
        assistant_lower = assistant_response.lower()
        
        # Mots-clÃ©s critiques
        critical_keywords = [
            'prix', 'coÃ»t', 'total', 'commande', 'confirme', 'achÃ¨te',
            'livraison', 'adresse', 'paiement', 'acompte', 'wave'
        ]
        
        for keyword in critical_keywords:
            if keyword in user_lower or keyword in assistant_lower:
                importance += 0.15
        
        # PrÃ©sence d'entitÃ©s
        entity_count = sum(len(v) if isinstance(v, list) else 1 
                          for v in entities.get('entities', {}).values())
        importance += min(entity_count * 0.1, 0.4)
        
        # Longueur des messages (plus long = plus important)
        length_factor = min((len(user_message) + len(assistant_response)) / 1000, 0.2)
        importance += length_factor
        
        return min(importance, 1.0)

    async def _perform_synthesis(self, synthesis: ConversationSynthesis, llm_client):
        """
        ðŸ§  Effectue la synthÃ¨se des Ã©changes anciens
        """
        if len(synthesis.recent_exchanges) <= self.max_recent_exchanges:
            return
        
        # Prendre les Ã©changes Ã  synthÃ©tiser (les plus anciens)
        exchanges_to_synthesize = synthesis.recent_exchanges[:-self.max_recent_exchanges]
        synthesis.recent_exchanges = synthesis.recent_exchanges[-self.max_recent_exchanges:]
        
        # Formater les Ã©changes pour synthÃ¨se
        exchanges_text = ""
        for exchange in exchanges_to_synthesize:
            exchanges_text += f"USER: {exchange.user_message}\n"
            exchanges_text += f"ASSISTANT: {exchange.assistant_response}\n"
            exchanges_text += f"ENTITÃ‰S: {exchange.extracted_entities}\n\n"
        
        # GÃ©nÃ©rer la nouvelle synthÃ¨se
        try:
            prompt = self.synthesis_prompt_template.format(
                previous_summary=synthesis.current_summary,
                new_exchanges=exchanges_text
            )
            
            response = await llm_client.complete(prompt, temperature=0.2, max_tokens=500)
            
            # GÃ©rer dict, tuple ou string
            if isinstance(response, dict):
                new_summary = response.get("response", "").strip()
            elif isinstance(response, tuple):
                new_summary = response[0].strip()
            else:
                new_summary = response.strip()
            
            synthesis.current_summary = new_summary
            synthesis.synthesis_version += 1
            
            print(f"[SYNTHESIS] Nouvelle synthÃ¨se v{synthesis.synthesis_version} gÃ©nÃ©rÃ©e")
            
        except Exception as e:
            print(f"[SYNTHESIS] Erreur synthÃ¨se: {e}")

    def _update_key_facts(self, synthesis: ConversationSynthesis, entities: Dict[str, Any]):
        """
        ðŸ“ Met Ã  jour les faits clÃ©s avec les nouvelles entitÃ©s
        """
        entity_data = entities.get('entities', {})
        
        for category, values in entity_data.items():
            if values:  # Si la liste n'est pas vide
                if category not in synthesis.key_facts:
                    synthesis.key_facts[category] = []
                
                # Ajouter les nouvelles valeurs (Ã©viter doublons)
                for value in values:
                    if value not in synthesis.key_facts[category]:
                        synthesis.key_facts[category].append(value)

    def get_context_for_llm(self, user_id: str, company_id: str) -> str:
        """
        ðŸ“‹ GÃ©nÃ¨re le contexte conversationnel pour le LLM
        """
        synthesis_key = self.get_synthesis_key(user_id, company_id)
        
        if synthesis_key not in self.active_syntheses:
            return ""
        
        synthesis = self.active_syntheses[synthesis_key]
        
        context_parts = []
        
        # SynthÃ¨se des Ã©changes anciens
        if synthesis.current_summary:
            context_parts.append(f"=== HISTORIQUE SYNTHÃ‰TISÃ‰ ===\n{synthesis.current_summary}")
        
        # Faits clÃ©s extraits
        if synthesis.key_facts:
            facts_text = []
            for category, values in synthesis.key_facts.items():
                if values:
                    facts_text.append(f"{category.upper()}: {', '.join(map(str, values))}")
            
            if facts_text:
                context_parts.append(f"=== FAITS CLÃ‰S ===\n" + "\n".join(facts_text))
        
        # Ã‰changes rÃ©cents (intÃ©graux)
        if synthesis.recent_exchanges:
            recent_text = "=== Ã‰CHANGES RÃ‰CENTS ==="
            for exchange in synthesis.recent_exchanges[-3:]:  # 3 derniers
                recent_text += f"\nUSER: {exchange.user_message}"
                recent_text += f"\nASSISTANT: {exchange.assistant_response}\n"
            
            context_parts.append(recent_text)
        
        return "\n\n".join(context_parts)

    def cleanup_expired_syntheses(self, max_age_hours: int = 24):
        """
        ðŸ§¹ Nettoie les synthÃ¨ses expirÃ©es
        """
        now = datetime.now()
        expired_keys = []
        
        for key, synthesis in self.active_syntheses.items():
            age = now - synthesis.last_update
            if age > timedelta(hours=max_age_hours):
                expired_keys.append(key)
        
        for key in expired_keys:
            del self.active_syntheses[key]
        
        return len(expired_keys)

    def get_synthesis_stats(self, user_id: str, company_id: str) -> Dict[str, Any]:
        """
        ðŸ“Š Statistiques de la synthÃ¨se
        """
        synthesis_key = self.get_synthesis_key(user_id, company_id)
        
        if synthesis_key not in self.active_syntheses:
            return {}
        
        synthesis = self.active_syntheses[synthesis_key]
        
        return {
            "total_exchanges": synthesis.total_exchanges,
            "recent_exchanges_count": len(synthesis.recent_exchanges),
            "synthesis_version": synthesis.synthesis_version,
            "key_facts_categories": len(synthesis.key_facts),
            "session_duration_minutes": (datetime.now() - synthesis.session_start).total_seconds() / 60,
            "last_update": synthesis.last_update.isoformat()
        }

# Instance globale
universal_synthesis = UniversalConversationSynthesis()

async def add_conversation_exchange(user_id: str, company_id: str, 
                                  user_message: str, assistant_response: str, 
                                  llm_client) -> str:
    """
    ðŸ”„ Fonction utilitaire pour ajouter un Ã©change et rÃ©cupÃ©rer le contexte
    """
    await universal_synthesis.add_exchange(
        user_id, company_id, user_message, assistant_response, llm_client
    )
    
    return universal_synthesis.get_context_for_llm(user_id, company_id)

def get_conversation_synthesis_context(user_id: str, company_id: str) -> str:
    """
    ðŸ“‹ Fonction utilitaire pour rÃ©cupÃ©rer le contexte conversationnel
    """
    return universal_synthesis.get_context_for_llm(user_id, company_id)

if __name__ == "__main__":
    print("ðŸ§  SYNTHÃˆSE CONVERSATIONNELLE UNIVERSELLE")
    print("BasÃ©e sur les meilleures pratiques d'OpenAI, Anthropic et LangChain")
    print("=" * 70)
    print("Usage:")
    print("from core.universal_conversation_synthesis import add_conversation_exchange")
