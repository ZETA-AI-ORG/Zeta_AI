"""
ðŸ›¡ï¸ GARDE-FOU ANTI-HALLUCINATION INTELLIGENT
Architecture simplifiÃ©e basÃ©e sur l'intention + LLM Juge unique
"""

import asyncio
import time
import logging
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from core.intention_router import intention_router
from core.llm_client import GroqLLMClient

logger = logging.getLogger(__name__)

@dataclass
class IntelligentHallucinationCheck:
    """RÃ©sultat de vÃ©rification intelligente d'hallucination"""
    is_safe: bool
    confidence_score: float
    intention_detected: str
    search_required: bool
    documents_found: bool
    judge_decision: str
    reason: str
    processing_time_ms: float
    suggested_response: Optional[str] = None

class IntelligentHallucinationGuard:
    """
    ðŸ›¡ï¸ GARDE-FOU ANTI-HALLUCINATION INTELLIGENT
    
    NOUVELLE ARCHITECTURE SIMPLIFIÃ‰E:
    1. ðŸ§  DÃ©tection d'intention (dÃ©termine si recherche nÃ©cessaire)
    2. ðŸŽ¯ Routage intelligent (Ã©vite recherches inutiles)
    3. âš–ï¸ LLM Juge unique (validation basÃ©e sur l'intention)
    """
    
    def __init__(self):
        self.llm_client = GroqLLMClient()
        
        # Types d'intentions et leurs besoins en documents
        self.intention_requirements = {
            # Intentions qui NÃ‰CESSITENT des documents
            'product_catalog': {'requires_docs': True, 'critical': True},
            'pricing_info': {'requires_docs': True, 'critical': True},
            'delivery_info': {'requires_docs': True, 'critical': True},
            'support_contact': {'requires_docs': True, 'critical': False},
            'company_identity': {'requires_docs': True, 'critical': False},
            
            # Intentions qui N'ONT PAS BESOIN de documents
            'social_greeting': {'requires_docs': False, 'critical': False},
            'general_conversation': {'requires_docs': False, 'critical': False},
            'politeness': {'requires_docs': False, 'critical': False},
            'off_topic': {'requires_docs': False, 'critical': False}
        }
        
        # Cache des dÃ©cisions du juge
        self.judge_cache = {}
        self.cache_ttl = 3600  # 1 heure
    
    def analyze_search_necessity(self, intentions_result) -> Dict[str, Any]:
        """
        ðŸŽ¯ ANALYSE SI UNE RECHERCHE EST NÃ‰CESSAIRE
        BasÃ© sur les intentions dÃ©tectÃ©es
        """
        if not intentions_result or not intentions_result.intentions:
            # Pas d'intention claire â†’ recherche par sÃ©curitÃ©
            return {
                'search_required': True,
                'reason': 'Intention non dÃ©tectÃ©e',
                'critical_level': 'medium'
            }
        
        primary_intention = intentions_result.primary
        
        # VÃ©rifier si l'intention nÃ©cessite des documents
        intention_config = self.intention_requirements.get(primary_intention, {
            'requires_docs': True, 
            'critical': True
        })
        
        search_required = intention_config['requires_docs']
        critical_level = 'high' if intention_config['critical'] else 'low'
        
        logger.info(f"[INTELLIGENT_GUARD] Intention: {primary_intention}, Recherche requise: {search_required}")
        
        return {
            'search_required': search_required,
            'reason': f"Intention '{primary_intention}' {'nÃ©cessite' if search_required else 'ne nÃ©cessite pas'} de documents",
            'critical_level': critical_level,
            'primary_intention': primary_intention
        }
    
    def create_intelligent_judge_prompt(
        self, 
        user_query: str, 
        ai_response: str, 
        intention: str,
        search_was_required: bool,
        documents_found: bool,
        context: str = ""
    ) -> str:
        """
        ðŸ§  PROMPT INTELLIGENT POUR LE JUGE LLM
        AdaptÃ© selon l'intention dÃ©tectÃ©e
        """
        
        if not search_was_required:
            # Cas social/conversationnel - validation allÃ©gÃ©e
            return f"""Tu es un juge expert pour valider les rÃ©ponses conversationnelles.

CONTEXTE:
- Question utilisateur: "{user_query}"
- Intention dÃ©tectÃ©e: {intention}
- Type: Conversation sociale (pas de recherche de documents nÃ©cessaire)

RÃ‰PONSE Ã€ JUGER:
{ai_response}

CRITÃˆRES DE VALIDATION:
1. La rÃ©ponse est-elle appropriÃ©e et polie ?
2. Reste-t-elle dans le contexte d'un assistant commercial ?
3. N'invente-t-elle pas de fausses informations ?

DÃ‰CISION: RÃ©ponds UNIQUEMENT par:
- "ACCEPTER" si la rÃ©ponse est appropriÃ©e
- "REJETER: [raison]" si elle est inappropriÃ©e ou invente des faits"""

        else:
            # Cas nÃ©cessitant des documents - validation stricte
            doc_status = "DOCUMENTS TROUVÃ‰S" if documents_found else "AUCUN DOCUMENT TROUVÃ‰"
            
            return f"""Tu es un juge expert anti-hallucination TRÃˆS STRICT.

CONTEXTE:
- Question utilisateur: "{user_query}"
- Intention dÃ©tectÃ©e: {intention}
- Status documents: {doc_status}
- Type: RequÃªte nÃ©cessitant des informations prÃ©cises

RÃ‰PONSE Ã€ JUGER:
{ai_response}

DOCUMENTS DE RÃ‰FÃ‰RENCE:
{context[:800] if context else "AUCUN DOCUMENT DISPONIBLE"}

CRITÃˆRES STRICTS:
1. Si AUCUN DOCUMENT: la rÃ©ponse doit rediriger vers le service client
2. Si DOCUMENTS TROUVÃ‰S: tous les faits doivent Ãªtre dans les documents
3. AUCUNE invention de prix, stock, ou dÃ©tails techniques
4. Les chiffres doivent Ãªtre exacts

DÃ‰CISION: RÃ©ponds UNIQUEMENT par:
- "ACCEPTER" si la rÃ©ponse est fidÃ¨le aux documents
- "REJETER: [raison prÃ©cise]" si elle invente ou dÃ©forme des informations

Sois IMPITOYABLE - en cas de doute, REJETER."""

    async def evaluate_response(
        self,
        user_query: str,
        ai_response: str,
        company_id: str,
        supabase_results: List[Dict] = None,
        meili_results: List[Dict] = None,
        supabase_context: str = "",
        meili_context: str = ""
    ) -> IntelligentHallucinationCheck:
        """
        ðŸŽ¯ Ã‰VALUATION INTELLIGENTE COMPLÃˆTE
        
        Pipeline simplifiÃ©:
        1. DÃ©tection d'intention
        2. Analyse nÃ©cessitÃ© de recherche
        3. Validation par LLM Juge intelligent
        """
        start_time = time.time()
        
        logger.info(f"[INTELLIGENT_GUARD] ðŸ›¡ï¸ Analyse: {ai_response[:50]}...")
        
        # Ã‰TAPE 1: DÃ©tection d'intention
        intentions_result = intention_router.detect_intentions(user_query)
        primary_intention = intentions_result.primary if intentions_result else "unknown"
        
        # Ã‰TAPE 2: Analyser si recherche Ã©tait nÃ©cessaire
        search_analysis = self.analyze_search_necessity(intentions_result)
        search_required = search_analysis['search_required']
        
        # Ã‰TAPE 3: VÃ©rifier si des documents ont Ã©tÃ© trouvÃ©s
        documents_found = bool(
            (supabase_results and len(supabase_results) > 0) or
            (meili_results and len(meili_results) > 0) or
            (supabase_context and len(supabase_context.strip()) > 10) or
            (meili_context and len(meili_context.strip()) > 10)
        )
        
        # Ã‰TAPE 4: Validation par LLM Juge intelligent
        combined_context = f"{supabase_context}\n{meili_context}".strip()
        
        judge_prompt = self.create_intelligent_judge_prompt(
            user_query=user_query,
            ai_response=ai_response,
            intention=primary_intention,
            search_was_required=search_required,
            documents_found=documents_found,
            context=combined_context
        )
        
        try:
            # Appel du juge LLM
            judge_response = await self.llm_client.complete(
                prompt=judge_prompt,
                temperature=0.0,  # DÃ©terministe pour la validation
                max_tokens=100
            )
            
            # Analyser la dÃ©cision
            is_accepted = "ACCEPTER" in judge_response.upper()
            judge_decision = judge_response.strip()
            
            # Calcul du score de confiance
            if is_accepted:
                confidence_score = 0.9 if documents_found or not search_required else 0.7
            else:
                confidence_score = 0.1
            
            # RÃ©ponse suggÃ©rÃ©e si rejetÃ©e
            suggested_response = None
            if not is_accepted:
                if search_required and not documents_found:
                    suggested_response = "Je n'ai pas d'informations prÃ©cises sur ce point. Contactez notre service client pour plus de dÃ©tails."
                elif search_required:
                    suggested_response = "D'aprÃ¨s nos informations disponibles, je ne peux pas confirmer ces dÃ©tails. Veuillez nous contacter directement."
            
            processing_time = (time.time() - start_time) * 1000
            
            logger.info(f"[INTELLIGENT_GUARD] âœ… DÃ©cision: {'ACCEPTER' if is_accepted else 'REJETER'} en {processing_time:.1f}ms")
            
            return IntelligentHallucinationCheck(
                is_safe=is_accepted,
                confidence_score=confidence_score,
                intention_detected=primary_intention,
                search_required=search_required,
                documents_found=documents_found,
                judge_decision=judge_decision,
                reason=f"Intention: {primary_intention}, Recherche: {'requise' if search_required else 'non requise'}, Documents: {'trouvÃ©s' if documents_found else 'absents'}",
                processing_time_ms=processing_time,
                suggested_response=suggested_response
            )
            
        except Exception as e:
            logger.error(f"[INTELLIGENT_GUARD] Erreur juge LLM: {e}")
            processing_time = (time.time() - start_time) * 1000
            
            return IntelligentHallucinationCheck(
                is_safe=False,
                confidence_score=0.0,
                intention_detected=primary_intention,
                search_required=search_required,
                documents_found=documents_found,
                judge_decision=f"ERREUR: {str(e)}",
                reason=f"Erreur lors de l'Ã©valuation: {str(e)}",
                processing_time_ms=processing_time,
                suggested_response="Une erreur s'est produite. Veuillez rÃ©essayer ou contacter notre service client."
            )
    
    def should_skip_search(self, user_query: str, company_id: str) -> bool:
        """
        ðŸŽ¯ DÃ‰CIDER SI ON PEUT Ã‰VITER LA RECHERCHE
        Optimisation basÃ©e sur l'intention
        """
        try:
            intentions_result = intention_router.detect_intentions(user_query)
            search_analysis = self.analyze_search_necessity(intentions_result)
            
            should_skip = not search_analysis['search_required']
            
            if should_skip:
                logger.info(f"[INTELLIGENT_GUARD] ðŸš€ Recherche Ã©vitÃ©e pour: {user_query[:30]}...")
            
            return should_skip
            
        except Exception as e:
            logger.error(f"[INTELLIGENT_GUARD] Erreur analyse intention: {e}")
            return False  # Par sÃ©curitÃ©, faire la recherche
