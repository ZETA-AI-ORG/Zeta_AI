#!/usr/bin/env python3
"""
ğŸ”„ DATA CHANGE TRACKER - Suivi des modifications de donnÃ©es
Objectif: Logger clairement tous les changements de donnÃ©es collectÃ©es
Architecture: Comparaison avant/aprÃ¨s + logs dÃ©taillÃ©s
"""

from typing import Dict, Any, Optional, List
from datetime import datetime
from utils import log3


class DataChangeTracker:
    """
    ğŸ”„ Tracker des changements de donnÃ©es collectÃ©es
    Compare l'Ã©tat avant/aprÃ¨s et log les modifications
    """
    
    # MÃ©tadonnÃ©es internes Ã  ignorer dans les logs
    INTERNAL_METADATA = {
        'created_at', 'last_updated', 'conversation_count',
        'products', 'quantities', 'calculated_totals',
        'confirmation'  # MÃ©tadonnÃ©e technique
    }
    
    def __init__(self):
        self.changes_history: List[Dict[str, Any]] = []
        self.current_state: Dict[str, Any] = {}
    
    def compare_and_log(
        self,
        old_data: Dict[str, Any],
        new_data: Dict[str, Any],
        source: str = "unknown"
    ) -> Dict[str, Any]:
        """
        ğŸ” Compare deux Ã©tats et log les changements
        
        Args:
            old_data: DonnÃ©es avant
            new_data: DonnÃ©es aprÃ¨s
            source: Source du changement (thinking, regex, notepad, etc.)
            
        Returns:
            Dict des changements dÃ©tectÃ©s
        """
        changes = {
            "timestamp": datetime.now().isoformat(),
            "source": source,
            "modifications": [],
            "additions": [],
            "deletions": []
        }
        
        # DÃ©tecter les modifications et additions
        for key, new_value in new_data.items():
            # Ignorer les mÃ©tadonnÃ©es internes
            if key in self.INTERNAL_METADATA:
                continue
                
            old_value = old_data.get(key)
            
            if old_value is None and new_value is not None:
                # Nouvelle donnÃ©e ajoutÃ©e
                changes["additions"].append({
                    "field": key,
                    "value": new_value
                })
                log3("[DATA_CHANGE]", f"â• AJOUT: {key} = {new_value} (source: {source})")
                
            elif old_value != new_value and new_value is not None:
                # DonnÃ©e modifiÃ©e (Ã‰CRASEMENT)
                changes["modifications"].append({
                    "field": key,
                    "old_value": old_value,
                    "new_value": new_value
                })
                log3("[DATA_CHANGE]", f"ğŸ”„ MODIF: {key} = {old_value} â†’ {new_value} (source: {source})")
        
        # DÃ©tecter les suppressions
        for key, old_value in old_data.items():
            # Ignorer les mÃ©tadonnÃ©es internes
            if key in self.INTERNAL_METADATA:
                continue
                
            if key not in new_data and old_value is not None:
                changes["deletions"].append({
                    "field": key,
                    "old_value": old_value
                })
                log3("[DATA_CHANGE]", f"â– SUPPRESSION: {key} = {old_value} (source: {source})")
        
        # Sauvegarder dans l'historique
        if changes["modifications"] or changes["additions"] or changes["deletions"]:
            self.changes_history.append(changes)
            self._log_summary(changes)
        else:
            log3("[DATA_CHANGE]", f"âœ… Aucun changement dÃ©tectÃ© (source: {source})")
        
        return changes
    
    def _log_summary(self, changes: Dict[str, Any]):
        """ğŸ“Š Log un rÃ©sumÃ© des changements"""
        total = (
            len(changes["modifications"]) +
            len(changes["additions"]) +
            len(changes["deletions"])
        )
        
        log3("[DATA_CHANGE]", f"ğŸ“Š RÃ‰SUMÃ‰: {total} changements dÃ©tectÃ©s")
        log3("[DATA_CHANGE]", f"   â”œâ”€ Modifications: {len(changes['modifications'])}")
        log3("[DATA_CHANGE]", f"   â”œâ”€ Ajouts: {len(changes['additions'])}")
        log3("[DATA_CHANGE]", f"   â””â”€ Suppressions: {len(changes['deletions'])}")
    
    def track_thinking_changes(
        self,
        thinking_data: Dict[str, Any],
        current_notepad: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        ğŸ§  Track les changements depuis le thinking parsÃ©
        
        Args:
            thinking_data: DonnÃ©es extraites du <thinking>
            current_notepad: Ã‰tat actuel du notepad
            
        Returns:
            Nouvelles donnÃ©es Ã  appliquer
        """
        log3("[DATA_CHANGE]", "ğŸ§  Analyse changements depuis <thinking>...")
        
        # Extraire deja_collecte du thinking
        deja_collecte = thinking_data.get("deja_collecte", {})
        
        # Convertir en format notepad
        new_data = {}
        
        if deja_collecte.get("type_produit"):
            new_data["produit"] = deja_collecte["type_produit"]
        
        if deja_collecte.get("quantite"):
            new_data["quantite"] = deja_collecte["quantite"]
        
        if deja_collecte.get("zone"):
            new_data["zone"] = deja_collecte["zone"]
        
        if deja_collecte.get("telephone"):
            new_data["telephone"] = deja_collecte["telephone"]
        
        if deja_collecte.get("paiement"):
            new_data["paiement"] = deja_collecte["paiement"]
        
        # Comparer avec l'Ã©tat actuel
        changes = self.compare_and_log(current_notepad, new_data, source="thinking_yaml")
        
        return new_data
    
    def track_regex_changes(
        self,
        regex_data: Dict[str, Any],
        current_notepad: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        ğŸ” Track les changements depuis les regex (livraison, etc.)
        
        Args:
            regex_data: DonnÃ©es extraites par regex
            current_notepad: Ã‰tat actuel du notepad
            
        Returns:
            Nouvelles donnÃ©es Ã  appliquer
        """
        log3("[DATA_CHANGE]", "ğŸ” Analyse changements depuis regex...")
        
        changes = self.compare_and_log(current_notepad, regex_data, source="regex_extraction")
        
        return regex_data
    
    def get_changes_history(self, limit: int = 10) -> List[Dict[str, Any]]:
        """
        ğŸ“œ RÃ©cupÃ¨re l'historique des changements
        
        Args:
            limit: Nombre max de changements Ã  retourner
            
        Returns:
            Liste des derniers changements
        """
        return self.changes_history[-limit:]
    
    def log_current_state(self, state: Dict[str, Any], label: str = "Ã‰tat actuel"):
        """
        ğŸ“Š Log l'Ã©tat complet des donnÃ©es collectÃ©es
        
        Args:
            state: Ã‰tat Ã  logger
            label: Label pour le log
        """
        log3("[DATA_STATE]", f"ğŸ“Š {label}:")
        
        for key, value in state.items():
            if value is not None:
                log3("[DATA_STATE]", f"   âœ… {key}: {value}")
            else:
                log3("[DATA_STATE]", f"   âš ï¸ {key}: NON COLLECTÃ‰")
        
        # Calculer complÃ©tude
        total_fields = len(state)
        filled_fields = sum(1 for v in state.values() if v is not None)
        completude = (filled_fields / total_fields * 100) if total_fields > 0 else 0
        
        log3("[DATA_STATE]", f"ğŸ“Š ComplÃ©tude: {filled_fields}/{total_fields} ({completude:.0f}%)")
    
    def merge_sources(
        self,
        thinking_data: Dict[str, Any],
        regex_data: Dict[str, Any],
        notepad_data: Dict[str, Any],
        priority: str = "thinking"
    ) -> Dict[str, Any]:
        """
        ğŸ”€ Fusionne les donnÃ©es de plusieurs sources avec prioritÃ©
        
        Args:
            thinking_data: DonnÃ©es du thinking YAML
            regex_data: DonnÃ©es des regex
            notepad_data: DonnÃ©es du notepad
            priority: Source prioritaire ("thinking", "regex", "notepad")
            
        Returns:
            DonnÃ©es fusionnÃ©es
        """
        log3("[DATA_MERGE]", f"ğŸ”€ Fusion des sources (prioritÃ©: {priority})...")
        
        # DÃ©finir l'ordre de prioritÃ©
        if priority == "thinking":
            sources = [thinking_data, regex_data, notepad_data]
            labels = ["thinking", "regex", "notepad"]
        elif priority == "regex":
            sources = [regex_data, thinking_data, notepad_data]
            labels = ["regex", "thinking", "notepad"]
        else:  # notepad
            sources = [notepad_data, thinking_data, regex_data]
            labels = ["notepad", "thinking", "regex"]
        
        # Fusionner avec prioritÃ©
        merged = {}
        source_map = {}  # Pour tracker d'oÃ¹ vient chaque donnÃ©e
        
        for source, label in zip(sources, labels):
            for key, value in source.items():
                if value is not None and key not in merged:
                    merged[key] = value
                    source_map[key] = label
        
        # Logger la source de chaque donnÃ©e
        log3("[DATA_MERGE]", "ğŸ“‹ Sources des donnÃ©es fusionnÃ©es:")
        for key, value in merged.items():
            source = source_map.get(key, "unknown")
            log3("[DATA_MERGE]", f"   {key}: {value} (source: {source})")
        
        return merged
    
    def clear_history(self):
        """ğŸ§¹ Nettoie l'historique des changements"""
        count = len(self.changes_history)
        self.changes_history.clear()
        log3("[DATA_CHANGE]", f"ğŸ§¹ Historique nettoyÃ©: {count} entrÃ©es supprimÃ©es")


# Instance globale singleton
_data_change_tracker = None

def get_data_change_tracker() -> DataChangeTracker:
    """ğŸ¯ Singleton pour le tracker de changements"""
    global _data_change_tracker
    if _data_change_tracker is None:
        _data_change_tracker = DataChangeTracker()
        log3("[DATA_CHANGE]", "ğŸš€ DataChangeTracker initialisÃ©")
    return _data_change_tracker
