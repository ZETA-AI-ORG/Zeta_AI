#!/usr/bin/env python3
"""
ğŸ¤– BOTLIVE RAG HYBRID - SystÃ¨me hybride DeepSeek V3 + Groq 70B
IntÃ©gration du routeur intelligent avec prompts spÃ©cialisÃ©s et outils
"""

import os
import re
import json
import logging
import asyncio
from typing import Dict, Any, Optional, Tuple
from datetime import datetime

# Imports locaux
from .hyde_smart_router import hyde_router
from .botlive_prompts_supabase import get_prompts_manager  # â† NOUVEAU: Supabase au lieu de hardcodÃ©
from .botlive_tools import execute_tools_in_response, should_suggest_calculator, should_suggest_notepad

logger = logging.getLogger(__name__)

class BotliveRAGHybrid:
    """
    SystÃ¨me RAG hybride pour Botlive avec routage intelligent
    """
    
    def __init__(self, company_id: str = None):
        self.router = hyde_router
        self.company_id = company_id  # â† NOUVEAU: Stocker company_id
        
        # Initialiser le gestionnaire de prompts avec fallback
        try:
            self.prompts_manager = get_prompts_manager()
            if self.prompts_manager:
                logger.info("âœ… [BOTLIVE_HYBRID] Prompts manager Supabase activÃ©")
            else:
                logger.warning("âš ï¸ [BOTLIVE_HYBRID] Prompts manager None - Utilisation hardcodÃ©s")
        except Exception as e:
            logger.error(f"âŒ [BOTLIVE_HYBRID] Erreur init prompts_manager: {e}")
            self.prompts_manager = None
        
        self.stats = {
            'total_requests': 0,
            'deepseek_requests': 0,
            'groq_requests': 0,
            'tools_used': 0,
            'fallbacks': 0
        }
        
    async def process_request(self, 
                            user_id: str,
                            message: str, 
                            context: Dict[str, Any],
                            conversation_history: str = "",
                            company_id: str = None) -> Dict[str, Any]:
        """
        Traite une requÃªte avec le systÃ¨me hybride
        
        Args:
            user_id: Identifiant utilisateur
            message: Message utilisateur
            context: Contexte (vision, transactions, etc.)
            conversation_history: Historique conversation
        
        Returns:
            Dict: RÃ©ponse complÃ¨te avec mÃ©tadonnÃ©es
        """
        import os
        print("\n========== DEBUG BOTLIVE SUPABASE ==========")
        print(f"SUPABASE_URL: {os.getenv('SUPABASE_URL')}")
        print(f"SUPABASE_SERVICE_KEY: {os.getenv('SUPABASE_SERVICE_KEY')}")
        print(f"prompts_manager: {self.prompts_manager}")
        print(f"company_id reÃ§u: {company_id} | self.company_id: {self.company_id}")
        print("============================================\n")

        start_time = datetime.now()
        timings = {}  # Track temps par Ã©tape
        
        try:
            # â•â•â• Ã‰TAPE 1: ROUTAGE INTELLIGENT â•â•â•
            step_start = datetime.now()
            llm_choice, routing_reason, router_metrics = await self.router.route_request(
                user_id, message, context, conversation_history
            )
            timings['routing'] = (datetime.now() - step_start).total_seconds()
            
            logger.info(f"ğŸ¯ Routage: {llm_choice} - Raison: {routing_reason}")
            
            # â•â•â• Ã‰TAPE 1.5: VALIDATION AUTOMATIQUE PAIEMENT â•â•â•
            payment_validation = None
            if context.get('filtered_transactions'):
                from core.payment_validator import validate_payment_cumulative, format_payment_for_prompt
                
                # Extraire montant requis du contexte (dynamique)
                expected_deposit_str = context.get('expected_deposit', '2000 FCFA')
                try:
                    import re
                    m = re.search(r'(\d+)', expected_deposit_str)
                    required_amount = int(m.group(1)) if m else 2000
                except:
                    required_amount = 2000
                
                payment_validation = validate_payment_cumulative(
                    current_transactions=context.get('filtered_transactions', []),
                    conversation_history=conversation_history,
                    required_amount=required_amount
                )
                
                logger.info(f"ğŸ’° Validation paiement: {payment_validation['message']}")
                
                # Ajouter au contexte pour le prompt
                context['payment_validation'] = payment_validation
                
                # ğŸ”¥ CORRECTION CRITIQUE: Persister le paiement validÃ© dans order_state
                if payment_validation.get('valid'):
                    from core.order_state_tracker import order_tracker
                    total_received = payment_validation.get('total_received', 0)
                    order_tracker.update_paiement(user_id, f"validÃ©_{total_received}F")
                    logger.info(f"âœ… [PERSISTENCE] Paiement {total_received}F sauvegardÃ© pour {user_id}")
            
            # â•â•â• Ã‰TAPE 2: GÃ‰NÃ‰RATION PROMPT SPÃ‰CIALISÃ‰ â•â•â•
            step_start = datetime.now()
            
            # PrÃ©parer les donnÃ©es pour le prompt
            formatted_transactions = self._format_transactions(context.get('filtered_transactions', []))
            
            # Si paiement validÃ© automatiquement, enrichir le prompt
            if payment_validation:
                validation_message = format_payment_for_prompt(payment_validation)
                formatted_transactions += validation_message
                logger.info(f"ğŸ’³ Message validation ajoutÃ© au prompt: {validation_message[:150]}...")
            
            logger.debug(f"ğŸ“‹ TRANSACTIONS envoyÃ©es au LLM: {formatted_transactions[:300]}...")
            
            # â•â•â• RÃ‰CUPÃ‰RATION Ã‰TAT COMMANDE (MÃ‰MOIRE CONTEXTE) â•â•â•
            from core.order_state_tracker import order_tracker
            state = order_tracker.get_state(user_id)
            missing = state.get_missing_fields()
            
            # CrÃ©er rÃ©sumÃ© Ã©tat pour le LLM
            state_resume = f"""
ğŸ“Š Ã‰TAT ACTUEL COMMANDE (NE PAS REDEMANDER CE QUI EST âœ…):
- PRODUIT: {"âœ… " + state.produit if state.produit else "âŒ manquant"}
- PAIEMENT: {"âœ… " + state.paiement if state.paiement else "âŒ manquant"}
- ZONE: {"âœ… " + state.zone if state.zone else "âŒ manquant"}
- NUMÃ‰RO: {"âœ… " + state.numero if state.numero else "âŒ manquant"}

âš ï¸ RÃˆGLES MÃ‰MOIRE CRITIQUE:
1. Si champ = âœ… â†’ NE JAMAIS redemander, juste confirmer si client corrige
2. Si client corrige info âœ… â†’ Accuser rÃ©ception SANS redemander ("Parfait, j'ai mis Ã  jour")
3. Demander UNIQUEMENT les champs âŒ manquants
4. Si tous âœ… â†’ Finaliser: "Commande OK ! on vous reviens pour la livraison ğŸ˜Š"
"""
            
            logger.info(f"ğŸ“Š [ORDER_STATE] Ã‰tat pour {user_id}:")
            logger.info(f"   - Produit: {state.produit or 'NON COLLECTÃ‰'}")
            logger.info(f"   - Paiement: {state.paiement or 'NON COLLECTÃ‰'}")
            logger.info(f"   - Zone: {state.zone or 'NON COLLECTÃ‰'}")
            logger.info(f"   - NumÃ©ro: {state.numero or 'NON COLLECTÃ‰'}")
            
            # â† NOUVEAU: RÃ©cupÃ©rer prompt depuis Supabase
            # Utiliser company_id du paramÃ¨tre ou de l'instance
            active_company_id = company_id or self.company_id
            if not active_company_id:
                raise ValueError("âŒ company_id requis pour rÃ©cupÃ©rer les prompts Botlive")
            
            logger.info(f"ğŸ” [BOTLIVE] RÃ©cupÃ©ration prompt pour company_id={active_company_id}, llm={llm_choice}")
            
            # VÃ©rifier si prompts_manager est disponible
            if not self.prompts_manager:
                logger.error("âŒ [BOTLIVE] prompts_manager est None - Impossible de rÃ©cupÃ©rer le prompt")
                raise ValueError("Prompts manager non initialisÃ© - Utiliser fallback _botlive_handle")
            
            # â•â•â• RÃ‰CUPÃ‰RATION PROMPT AVEC DEBUG COMPLET â•â•â•
            try:
                print(f"[DEBUG] Avant appel format_prompt...")
                prompt = self.prompts_manager.format_prompt(
                    company_id=active_company_id,
                    llm_choice=llm_choice,
                    conversation_history=conversation_history,
                    question=message,
                    detected_objects=self._format_detected_objects(context.get('detected_objects', [])),
                    filtered_transactions=formatted_transactions,
                    expected_deposit=context.get('expected_deposit', '2000'),
                    order_state=state_resume  # â† AJOUT MÃ‰MOIRE CONTEXTE
                )
                print(f"[DEBUG] AprÃ¨s appel format_prompt: {len(prompt)} chars")
                
                # VÃ©rifier que le prompt n'est pas vide ou trop court
                if not prompt or len(prompt) < 100:
                    raise ValueError(f"âŒ Prompt Supabase invalide ou vide: {len(prompt) if prompt else 0} chars")
                
                print(f"[DEBUG] âœ… Prompt Supabase valide: {len(prompt)} chars")
                
            except Exception as prompt_error:
                import traceback
                print(f"\n{'='*80}")
                print(f"âŒ [ERREUR RÃ‰CUPÃ‰RATION PROMPT SUPABASE]")
                print(f"{'='*80}")
                print(f"Company ID: {active_company_id}")
                print(f"LLM Choice: {llm_choice}")
                print(f"Erreur: {prompt_error}")
                print(f"Type: {type(prompt_error).__name__}")
                print(f"\nTraceback complet:")
                traceback.print_exc()
                print(f"{'='*80}\n")
                logger.error(f"âŒ Erreur rÃ©cupÃ©ration prompt Supabase: {prompt_error}", exc_info=True)
                raise
            
            logger.info(f"âœ… [BOTLIVE] Prompt rÃ©cupÃ©rÃ©: {len(prompt)} caractÃ¨res")
            # === PRINT PROMPT EFFECTIF (stdout, visible mÃªme si niveau de logs Ã©levÃ©) ===
            try:
                print("\n" + "="*100)
                print(f"PROMPT (EFFECTIF) â†’ {llm_choice}: {len(prompt)} chars")
                print("="*100 + "\n")
                print(prompt)
                print("\n" + "="*100 + "\n")
            except Exception:
                pass
            timings['prompt_generation'] = (datetime.now() - step_start).total_seconds()
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # ğŸŒ¸ AFFICHAGE COMPLET DU PROMPT FINAL ENVOYÃ‰ AU LLM (EN ROSE)
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            MAGENTA = '\033[95m'
            BOLD = '\033[1m'
            RESET = '\033[0m'
            logger.info(f"\n{MAGENTA}{BOLD}{'='*100}{RESET}")
            logger.info(f"{MAGENTA}{BOLD}ğŸŒ¸ PROMPT COMPLET ENVOYÃ‰ Ã€ {llm_choice.upper()} ({len(prompt)} caractÃ¨res, ~{len(prompt)//4} tokens){RESET}")
            logger.info(f"{MAGENTA}{BOLD}{'='*100}{RESET}")
            logger.info(f"{MAGENTA}{prompt}{RESET}")
            logger.info(f"{MAGENTA}{BOLD}{'='*100}{RESET}\n")
            
            # â•â•â• Ã‰TAPE 3: APPEL LLM â•â•â•
            step_start = datetime.now()
            if llm_choice == "deepseek-v3":
                response_data = await self._call_deepseek(prompt, user_id)
                self.stats['deepseek_requests'] += 1
            else:  # groq-70b
                response_data = await self._call_groq(prompt, user_id)
                self.stats['groq_requests'] += 1
            timings['llm_call'] = (datetime.now() - step_start).total_seconds()
            
            # â•â•â• Ã‰TAPE 4: VALIDATION RÃ‰PONSE â•â•â•
            if not self._is_valid_response(response_data, llm_choice):
                # Fallback automatique vers Groq si DeepSeek Ã©choue
                if llm_choice == "deepseek-v3":
                    logger.warning(f"ğŸ”„ Fallback DeepSeek â†’ Groq pour {user_id}")
                    self.router.record_failure(user_id, "deepseek-v3")
                    
                    # Nouveau prompt Groq depuis Supabase
                    groq_prompt = self.prompts_manager.format_prompt(
                        company_id=self.company_id,
                        llm_choice="groq-70b",
                        conversation_history=conversation_history,
                        question=message,
                        detected_objects=self._format_detected_objects(context.get('detected_objects', [])),
                        filtered_transactions=self._format_transactions(context.get('filtered_transactions', [])),
                        expected_deposit=context.get('expected_deposit', '2000')
                    )
                    
                    # ğŸŒ¸ AFFICHAGE PROMPT GROQ FALLBACK (EN ROSE)
                    logger.info(f"\n{MAGENTA}{BOLD}{'='*100}{RESET}")
                    logger.info(f"{MAGENTA}{BOLD}ğŸŒ¸ PROMPT FALLBACK GROQ-70B ({len(groq_prompt)} caractÃ¨res, ~{len(groq_prompt)//4} tokens){RESET}")
                    logger.info(f"{MAGENTA}{BOLD}{'='*100}{RESET}")
                    logger.info(f"{MAGENTA}{groq_prompt}{RESET}")
                    logger.info(f"{MAGENTA}{BOLD}{'='*100}{RESET}\n")
                    
                    response_data = await self._call_groq(groq_prompt, user_id)
                    llm_choice = "groq-70b"  # Mise Ã  jour pour les stats
                    self.stats['fallbacks'] += 1
            
            # â•â•â• Ã‰TAPE 5: EXTRACTION THINKING/RESPONSE â•â•â•
            step_start = datetime.now()
            raw_response = response_data.get('response', '')
            thinking = response_data.get('thinking', '')
            final_response = raw_response
            
            # Extraire thinking et response si format structurÃ©
            if "<thinking>" in raw_response and "</thinking>" in raw_response:
                import re
                thinking_match = re.search(r'<thinking>(.*?)</thinking>', raw_response, re.DOTALL)
                response_match = re.search(r'<response>(.*?)</response>', raw_response, re.DOTALL)
                
                if thinking_match:
                    thinking = thinking_match.group(1).strip()
                    # âœ… CRITIQUE: ExÃ©cuter les outils dans <thinking> (notepad, calculator)
                    # Ne pas garder le rÃ©sultat (juste pour side-effects comme sync state tracker)
                    execute_tools_in_response(thinking, user_id)
                    logger.debug(f"ğŸ§  [THINKING] Outils exÃ©cutÃ©s pour {user_id}")
                    
                if response_match:
                    final_response = response_match.group(1).strip()
                else:
                    # Si pas de balise response, prendre tout aprÃ¨s thinking
                    final_response = re.sub(r'<thinking>.*?</thinking>', '', raw_response, flags=re.DOTALL).strip()
            
            # â•â•â• Ã‰TAPE 6: VALIDATION ANTI-HALLUCINATION â•â•â•
            from core.llm_response_validator import validator as llm_validator
            from core.order_state_tracker import order_tracker
            
            validation_result = llm_validator.validate(
                response=final_response,
                thinking=thinking,
                order_state=order_tracker.get_state(user_id),
                payment_validation=payment_validation,
                context_documents=[context.get('context_used', '')]
            )
            
            # Si hallucination dÃ©tectÃ©e, rÃ©gÃ©nÃ©rer
            if validation_result.should_regenerate:
                logger.warning(f"ğŸš¨ [HALLUCINATION] RÃ©gÃ©nÃ©ration requise pour {user_id}")
                logger.warning(f"   Erreurs: {validation_result.errors}")
                
                # RÃ©gÃ©nÃ©rer avec prompt corrigÃ©
                corrected_prompt = prompt + "\n\n" + validation_result.correction_prompt
                
                logger.info(f"ğŸ”„ [REGENERATION] Appel LLM avec correction...")
                if llm_choice == "deepseek-v3":
                    response_data = await self._call_deepseek(corrected_prompt, user_id)
                else:
                    response_data = await self._call_groq(corrected_prompt, user_id)
                
                # Extraire nouvelle rÃ©ponse
                raw_response = response_data.get('response', '')
                thinking_match = re.search(r'<thinking>(.*?)</thinking>', raw_response, re.DOTALL)
                response_match = re.search(r'<response>(.*?)</response>', raw_response, re.DOTALL)
                
                if thinking_match:
                    thinking = thinking_match.group(1).strip()
                if response_match:
                    final_response = response_match.group(1).strip()
                else:
                    final_response = re.sub(r'<thinking>.*?</thinking>', '', raw_response, flags=re.DOTALL).strip()
                
                # Valider Ã  nouveau
                validation_result2 = llm_validator.validate(
                    response=final_response,
                    thinking=thinking,
                    order_state=order_tracker.get_state(user_id),
                    payment_validation=payment_validation,
                    context_documents=[context.get('context_used', '')]
                )
                
                if not validation_result2.valid:
                    logger.error("âŒ [REGENERATION] Ã‰chec aprÃ¨s correction, rÃ©ponse conservÃ©e")
            
            # â•â•â• Ã‰TAPE 7: EXÃ‰CUTION OUTILS â•â•â•
            processed_response = execute_tools_in_response(final_response, user_id)
            timings['tools_execution'] = (datetime.now() - step_start).total_seconds()
            
            if processed_response != final_response:
                self.stats['tools_used'] += 1
                logger.debug(f"ğŸ§  Outils exÃ©cutÃ©s pour {user_id}")
            
            # â•â•â• Ã‰TAPE 6.4: DÃ‰TECTION AUTOMATIQUE ET SAUVEGARDE (OPTIMISÃ‰E) â•â•â•
            try:
                from core.order_state_tracker import order_tracker
                import re
                
                # DÃ©tecter et sauvegarder automatiquement les donnÃ©es
                vision_objects = context.get('vision_objects', [])
                detected_objects = context.get('detected_objects', [])
                message_text = context.get('message', message)  # Utiliser message du paramÃ¨tre si pas dans context
                message_lower = message_text.lower() if message_text else ""
                
                # ğŸ” DEBUG: Voir ce qui arrive vraiment
                logger.info(f"ğŸ” [AUTO-DETECT DEBUG] user_id={user_id}")
                logger.info(f"ğŸ” [AUTO-DETECT DEBUG] vision_objects={vision_objects}")
                logger.info(f"ğŸ” [AUTO-DETECT DEBUG] detected_objects={detected_objects}")
                logger.info(f"ğŸ” [AUTO-DETECT DEBUG] message_text={message_text[:100] if message_text else 'VIDE'}")
                logger.info(f"ğŸ” [AUTO-DETECT DEBUG] context.keys()={list(context.keys())}")
                
                # 1. PRODUIT dÃ©tectÃ© dans VISION ou DETECTED_OBJECTS
                if vision_objects or detected_objects:
                    # Fusionner les deux sources
                    all_objects = vision_objects + detected_objects
                    if all_objects:
                        # DÃ©tecter le produit (tout objet non monÃ©taire)
                        for obj in all_objects:
                            obj_text = None
                            
                            # FORMAT 1: Dict {'label': '...', 'confidence': 0.85}
                            if isinstance(obj, dict) and 'label' in obj:
                                obj_text = obj['label']
                            
                            # FORMAT 2: String "objet:lingettes~0.85"
                            elif isinstance(obj, str) and obj.startswith('objet:'):
                                # Extraire le label entre "objet:" et "~"
                                obj_text = obj.split('objet:')[1].split('~')[0] if '~' in obj else obj.split('objet:')[1]
                            
                            # FORMAT 3: String simple
                            elif isinstance(obj, str):
                                obj_text = obj
                            
                            # FORMAT 4: Autre (fallback)
                            else:
                                obj_text = str(obj)
                            
                            if obj_text:
                                obj_str = obj_text.lower()
                                # Exclure les montants et strings "montant:..."
                                if not re.search(r'\d+\s*f', obj_str) and not obj_str.startswith('montant:') and len(obj_str) > 2:
                                    produit = f"{obj_text[:50]}[VISION]" if len(obj_text) > 50 else f"{obj_text}[VISION]"
                                    order_tracker.update_produit(user_id, produit)
                                    logger.info(f"ğŸ“¦ [AUTO-DETECT] Produit: {produit}")
                                    break
                
                # 2. PAIEMENT dÃ©tectÃ© dans TRANSACTIONS (prioritaire) ou vision
                filtered_transactions = context.get('filtered_transactions', [])
                if filtered_transactions:
                    # Transactions OCR dÃ©tectÃ©es
                    first_transaction = filtered_transactions[0]
                    montant = f"{first_transaction.get('amount', 'INCONNU')}F[TRANSACTIONS]"
                    order_tracker.update_paiement(user_id, montant)
                    logger.info(f"ğŸ’° [AUTO-DETECT] Paiement (OCR): {montant}")
                else:
                    # Sinon chercher dans vision
                    for obj in vision_objects + detected_objects:
                        obj_str = str(obj).lower()
                        if 'fcfa' in obj_str or re.search(r'\d+\s*f\b', obj_str):
                            # Extraire montant
                            montant_match = re.search(r'(\d+)\s*f', obj_str)
                            if montant_match:
                                montant = f"{montant_match.group(1)}F[VISION]"
                                order_tracker.update_paiement(user_id, montant)
                                logger.info(f"ğŸ’° [AUTO-DETECT] Paiement (vision): {montant}")
                                break
                
                # 3. ZONE dÃ©tectÃ©e dans message
                zones = ["yopougon", "cocody", "plateau", "adjamÃ©", "abobo", "marcory", 
                         "koumassi", "treichville", "angrÃ©", "riviera", "port-bouet", "attÃ©coubÃ©"]
                for zone in zones:
                    if zone in message_lower:
                        zone_formatted = f"{zone.capitalize()}-1500F[MESSAGE]"
                        order_tracker.update_zone(user_id, zone_formatted)
                        logger.info(f"ğŸ“ [AUTO-DETECT] Zone: {zone_formatted}")
                        break
                
                # 4. NUMÃ‰RO dÃ©tectÃ© dans message (4 formats)
                numero_patterns = [
                    r'\+225\s?0?([157]\d{8})',  # +2250787360757 ou +225 0787360757
                    r'\b(0[157]\d{8})\b',        # 0787360757
                    r'\b0([157])\s?(\d{2})\s?(\d{2})\s?(\d{2})\s?(\d{2})\b'  # 07 87 36 07 57
                ]
                
                numero = None
                for pattern in numero_patterns:
                    match = re.search(pattern, message_text) if message_text else None
                    if match:
                        if len(match.groups()) == 1:
                            # Format simple
                            numero = f"0{match.group(1)}[MESSAGE]" if not match.group(1).startswith('0') else f"{match.group(1)}[MESSAGE]"
                        else:
                            # Format avec espaces
                            numero = f"0{''.join(match.groups())}[MESSAGE]"
                        break
                
                if numero:
                    order_tracker.update_numero(user_id, numero)
                    logger.info(f"ğŸ“ [AUTO-DETECT] NumÃ©ro: {numero}")
                    
            except Exception as e:
                logger.error(f"âš ï¸ Auto-dÃ©tection Ã©chouÃ©e: {e}")
            
            # â•â•â• Ã‰TAPE 6.5: FINALISATION FORCÃ‰E SI COMMANDE COMPLÃˆTE â•â•â•
            try:
                from core.order_state_tracker import order_tracker
                state = order_tracker.get_state(user_id)
                if state.is_complete():
                    processed_response = "Commande OK ! on vous reviens pour la livraison ğŸ˜Š Si tout es ok. Ne rÃ©ponds pas Ã  ce message."
                    logger.info(f"âœ… [FINALISATION AUTO] Commande complÃ¨te pour {user_id}")
            except Exception as e:
                logger.debug(f"âš ï¸ VÃ©rification finalisation Ã©chouÃ©e: {e}")
            
            # â•â•â• Ã‰TAPE 6.6: NETTOYAGE TRACES TECHNIQUES â•â•â•
            processed_response = self._clean_response(processed_response)
            
            # â•â•â• Ã‰TAPE 7: ENREGISTREMENT SUCCÃˆS â•â•â•
            self.router.record_success(user_id, llm_choice)
            
            # â•â•â• Ã‰TAPE 8: CONSTRUCTION RÃ‰PONSE FINALE â•â•â•
            end_time = datetime.now()
            processing_time = (end_time - start_time).total_seconds()
            
            self.stats['total_requests'] += 1
            
            return {
                'response': processed_response,
                'thinking': thinking,
                'llm_used': llm_choice,
                'validation': {  # â† NOUVEAU: RÃ©sultats validation
                    'valid': validation_result.valid,
                    'errors': validation_result.errors,
                    'warnings': validation_result.warnings,
                    'should_regenerate': validation_result.should_regenerate
                } if 'validation_result' in locals() else None,
                'routing_reason': routing_reason,
                'processing_time': processing_time,
                'timings': timings,
                'router_metrics': router_metrics,
                'tools_executed': processed_response != final_response,
                'prompt_tokens': response_data.get('prompt_tokens', 0),
                'completion_tokens': response_data.get('completion_tokens', 0),
                'total_cost': response_data.get('total_cost', 0),
                'success': True
            }
            
        except Exception as e:
            logger.error(f"âŒ Erreur traitement requÃªte {user_id}: {e}")
            return {
                'response': "DÃ©solÃ©, erreur technique. RÃ©essayez s'il vous plaÃ®t.",
                'thinking': '',
                'llm_used': 'error',
                'routing_reason': f'Erreur: {str(e)}',
                'processing_time': (datetime.now() - start_time).total_seconds(),
                'tools_executed': False,
                'success': False
            }
    
    def _clean_response(self, response: str) -> str:
        """
        Nettoie la rÃ©ponse pour enlever toute trace technique
        (notepad, calculator, etc.)
        
        Args:
            response: RÃ©ponse brute du LLM
        
        Returns:
            str: RÃ©ponse nettoyÃ©e
        """
        import re
        # Supprimer notepad(...) et contenu associÃ©
        response = re.sub(r'notepad\([^)]*\)\s*puis\s*[^\s]+', '', response)
        response = re.sub(r'notepad\([^)]*\)', '', response)
        response = re.sub(r'calculator\([^)]*\)', '', response)
        # Supprimer traces âœ…CHAMP:valeur[SOURCE]
        response = re.sub(r'âœ…\w+:[^\s\|]+\[\w+\]', '', response)
        # Nettoyer espaces multiples
        response = re.sub(r'\s{2,}', ' ', response).strip()
        return response
    
    async def _call_deepseek(self, prompt: str, user_id: str) -> Dict[str, Any]:
        """
        Appel API DeepSeek V3
        
        Args:
            prompt: Prompt formatÃ©
            user_id: ID utilisateur
        
        Returns:
            Dict: RÃ©ponse DeepSeek avec mÃ©tadonnÃ©es
        """
        try:
            # Import du bon module Groq
            from core.llm_client_groq import complete
            
            logger.debug(f"ğŸ“¡ Appel DeepSeek V3 pour {user_id}")
            
            # Pour l'instant, utiliser Groq en attendant l'API DeepSeek
            # TODO: Remplacer par vraie API DeepSeek quand disponible
            content, token_info = await complete(
                prompt=prompt,
                model_name="llama-3.3-70b-versatile",  # Temporaire
                max_tokens=500,
                temperature=0.1
            )
            
            return {
                'response': content,
                'thinking': '',  # Extraire si format <thinking>
                'prompt_tokens': token_info.get('prompt_tokens', 600),
                'completion_tokens': token_info.get('completion_tokens', 50),
                'total_cost': 0.0003,  # CoÃ»t DeepSeek simulÃ©
                'model': 'deepseek-chat'
            }
            
        except Exception as e:
            logger.error(f"âŒ Erreur DeepSeek API: {e}")
            raise
    
    async def _call_groq(self, prompt: str, user_id: str) -> Dict[str, Any]:
        """
        Appel API Groq 70B
        
        Args:
            prompt: Prompt formatÃ©
            user_id: ID utilisateur
        
        Returns:
            Dict: RÃ©ponse Groq avec mÃ©tadonnÃ©es
        """
        try:
            # Import du bon module Groq
            from core.llm_client_groq import complete
            
            logger.debug(f"ğŸ“¡ Appel Groq 70B pour {user_id}")
            
            # Appel API Groq rÃ©el
            content, token_info = await complete(
                prompt=prompt,
                model_name="llama-3.3-70b-versatile",
                max_tokens=1000,
                temperature=0.1
            )
            
            # Extraire thinking/response si format spÃ©cialisÃ©
            thinking = ""
            response = content
            
            if "<thinking>" in content and "</thinking>" in content:
                import re
                thinking_match = re.search(r'<thinking>(.*?)</thinking>', content, re.DOTALL)
                response_match = re.search(r'<response>(.*?)</response>', content, re.DOTALL)
                
                if thinking_match:
                    thinking = thinking_match.group(1).strip()
                if response_match:
                    response = response_match.group(1).strip()
            
            return {
                'response': response,
                'thinking': thinking,
                'prompt_tokens': token_info.get('prompt_tokens', 800),
                'completion_tokens': token_info.get('completion_tokens', 150),
                'total_cost': self._calculate_groq_cost(token_info),
                'model': token_info.get('model', 'llama-3.3-70b-versatile')
            }
            
        except Exception as e:
            logger.error(f"âŒ Erreur Groq API: {e}")
            raise
    
    def _calculate_groq_cost(self, token_info: Dict) -> float:
        """Calcule le coÃ»t Groq selon les tokens utilisÃ©s"""
        prompt_tokens = token_info.get('prompt_tokens', 0)
        completion_tokens = token_info.get('completion_tokens', 0)
        
        # Tarifs Groq 70B (USD)
        input_cost = (prompt_tokens / 1_000_000) * 0.59
        output_cost = (completion_tokens / 1_000_000) * 0.79
        
        return input_cost + output_cost
    
    def _is_valid_response(self, response_data: Dict, llm_used: str) -> bool:
        """
        Valide la qualitÃ© d'une rÃ©ponse LLM
        
        Args:
            response_data: DonnÃ©es de rÃ©ponse
            llm_used: LLM utilisÃ©
        
        Returns:
            bool: True si rÃ©ponse valide
        """
        response = response_data.get('response', '')
        
        # 1. RÃ©ponse non vide
        if not response or len(response.strip()) < 5:
            logger.warning(f"âš ï¸ RÃ©ponse vide de {llm_used}")
            return False
        
        # 2. Pas de rÃ©ponse gÃ©nÃ©rique rÃ©pÃ©titive (pour DeepSeek)
        if llm_used == "deepseek-v3":
            generic_responses = [
                "salut ğŸ‘‹ envoie photo produit",
                "envoie photo du produit",
                "impossible de tÃ©lÃ©charger"
            ]
            
            if any(generic.lower() in response.lower() for generic in generic_responses):
                # Acceptable pour DeepSeek si c'est appropriÃ© au contexte
                pass
        
        # 3. Format thinking/response respectÃ© (pour Groq)
        if llm_used == "groq-70b":
            if "<thinking>" in response and "</thinking>" not in response:
                logger.warning(f"âš ï¸ Format thinking malformÃ© de {llm_used}")
                return False
        
        return True
    
    def _format_detected_objects(self, detected_objects: list) -> str:
        """Formate les objets dÃ©tectÃ©s pour le prompt"""
        if not detected_objects:
            return "[AUCUN OBJET DÃ‰TECTÃ‰]"
        
        formatted = []
        for obj in detected_objects:
            if isinstance(obj, str):
                formatted.append(obj)
            elif isinstance(obj, dict):
                # Support pour format BLIP-2: {'label': 'nom', 'confidence': 0.85}
                label = obj.get('label', obj.get('type', obj.get('description', 'objet inconnu')))
                confidence = obj.get('confidence', 0)
                if confidence > 0:
                    formatted.append(f"{label} (confiance: {confidence:.0%})")
                else:
                    formatted.append(label)
        
        return ", ".join(formatted) if formatted else "[AUCUN OBJET DÃ‰TECTÃ‰]"
    
    def _format_transactions(self, transactions: list) -> str:
        """Formate les transactions pour le prompt (optimisÃ© tokens)"""
        if not transactions:
            return "0F"
        
        formatted = []
        for trans in transactions:
            if isinstance(trans, dict):
                amount = trans.get('amount', '0')
                phone = trans.get('phone', '')
                # Tronquer numÃ©ro pour Ã©conomiser tokens (garder 4 derniers chiffres)
                if phone and len(phone) >= 4:
                    phone_short = f"...{phone[-4:]}"
                else:
                    phone_short = phone
                formatted.append(f"{amount}F -> +225{phone_short}")
        
        return ", ".join(formatted) if formatted else "0F"
    
    def get_stats(self) -> Dict[str, Any]:
        """
        Retourne les statistiques du systÃ¨me hybride
        
        Returns:
            Dict: Statistiques complÃ¨tes
        """
        router_stats = self.router.get_stats()
        
        return {
            **self.stats,
            **router_stats,
            'deepseek_percentage': (self.stats['deepseek_requests'] / max(self.stats['total_requests'], 1)) * 100,
            'groq_percentage': (self.stats['groq_requests'] / max(self.stats['total_requests'], 1)) * 100,
            'tools_usage_rate': (self.stats['tools_used'] / max(self.stats['total_requests'], 1)) * 100,
            'fallback_rate': (self.stats['fallbacks'] / max(self.stats['total_requests'], 1)) * 100
        }
    
    def reset_stats(self):
        """Remet Ã  zÃ©ro les statistiques"""
        self.stats = {
            'total_requests': 0,
            'deepseek_requests': 0,
            'groq_requests': 0,
            'tools_used': 0,
            'fallbacks': 0
        }

# Instance globale
botlive_hybrid = BotliveRAGHybrid()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ§ª FONCTIONS DE TEST
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def test_hybrid_system():
    """Test rapide du systÃ¨me hybride"""
    print("ğŸ§ª Test systÃ¨me hybride Botlive")
    
    # Test cas simple (DeepSeek attendu)
    print("\n1. Test cas simple:")
    result1 = await botlive_hybrid.process_request(
        user_id="test_user_1",
        message="Bonjour",
        context={},
        conversation_history=""
    )
    print(f"LLM: {result1['llm_used']} | RÃ©ponse: {result1['response']}")
    
    # Test cas complexe (Groq attendu)
    print("\n2. Test cas complexe:")
    result2 = await botlive_hybrid.process_request(
        user_id="test_user_2", 
        message="Validation paiement",
        context={
            'filtered_transactions': [{'amount': '2020', 'phone': '0787360757'}],
            'expected_deposit': '2000 FCFA'
        },
        conversation_history="Photo reÃ§ue ! Confirmes ?"
    )
    print(f"LLM: {result2['llm_used']} | RÃ©ponse: {result2['response']}")
    
    # Affichage stats
    print(f"\nğŸ“Š Stats: {botlive_hybrid.get_stats()}")

if __name__ == "__main__":
    asyncio.run(test_hybrid_system())
