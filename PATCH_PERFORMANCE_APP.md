# üöÄ PATCH PERFORMANCE POUR APP.PY

## MODIFICATIONS √Ä FAIRE DANS `app.py`

### 1Ô∏è‚É£ **IMPORT DE L'OPTIMISEUR** (Ligne ~50)

Ajouter apr√®s les autres imports:
```python
from core.performance_optimizer import initialize_performance_optimizations, get_performance_optimizer
```

### 2Ô∏è‚É£ **INITIALISATION AU D√âMARRAGE** (Ligne ~100, dans `@app.on_event("startup")`)

Ajouter dans la fonction `startup_event()`:
```python
@app.on_event("startup")
async def startup_event():
    """Initialisation au d√©marrage"""
    logger.info("üöÄ D√©marrage de l'application...")
    
    # NOUVEAU: Initialiser les optimisations de performance
    try:
        await initialize_performance_optimizations()
        logger.info("‚úÖ Optimisations de performance initialis√©es")
    except Exception as e:
        logger.error(f"‚ö†Ô∏è Erreur initialisation optimisations: {e}")
    
    # ... reste du code existant ...
```

### 3Ô∏è‚É£ **UTILISATION DANS L'ENDPOINT /chat** (Ligne ~500)

Modifier la fonction `chat_endpoint()` pour utiliser l'optimiseur:

```python
@app.post("/chat")
async def chat_endpoint(request: ChatRequest):
    """Endpoint principal de chat"""
    
    # ... code existant jusqu'√† la recherche RAG ...
    
    # NOUVEAU: Utiliser l'optimiseur pour la recherche
    optimizer = get_performance_optimizer()
    
    # Si tu utilises MeiliSearch avec n-grams
    # AVANT:
    # results = await search_meilisearch(company_id, query, ngrams)
    
    # APR√àS:
    # results = await optimizer.parallel_meilisearch_optimized(
    #     indexes=get_company_indexes(company_id),
    #     ngrams=ngrams,
    #     search_func=lambda idx, ng: search_single_index(idx, ng),
    #     max_concurrent=50
    # )
    
    # ... reste du code existant ...
```

### 4Ô∏è‚É£ **CACHE PROMPT OPTIMIS√â** (Ligne ~600)

Modifier la r√©cup√©ration du prompt:

```python
# AVANT:
# prompt = await get_prompt_from_supabase(company_id)

# APR√àS:
optimizer = get_performance_optimizer()
prompt = await optimizer.get_prompt_cached(
    company_id=company_id,
    fetch_func=lambda: get_prompt_from_supabase(company_id)
)
```

---

## üìã R√âSUM√â DES CHANGEMENTS

### ‚úÖ **Ce qui est optimis√©**
1. **Cache embedding persistant**: Mod√®les pr√©charg√©s au d√©marrage
2. **N-grams optimis√©s**: 30 ‚Üí 20 n-grams les plus pertinents
3. **Cache prompt m√©moire**: √âvite les requ√™tes Supabase r√©p√©t√©es
4. **Connection pooling**: HTTP/2 avec 200 connexions max
5. **Recherche parall√®le**: Batches de 50 au lieu de 120 simultan√©es

### ‚ùå **Ce qui N'EST PAS touch√©**
1. **Format LLM**: Aucune modification du prompt ou du parsing
2. **Logique RAG**: M√™me algorithme de recherche
3. **Scoring**: M√™me syst√®me de scoring
4. **Filtrage**: M√™me logique de filtrage

---

## üöÄ COMMENT APPLIQUER

### M√©thode 1: Automatique (recommand√©)
```bash
# Lancer le script d'application
python apply_performance_optimizations.py

# Red√©marrer le serveur
# Les optimisations seront actives
```

### M√©thode 2: Manuelle
1. Copier les 4 modifications ci-dessus dans `app.py`
2. Red√©marrer le serveur
3. V√©rifier les logs pour confirmer l'initialisation

---

## üìä GAINS ATTENDUS

| Composant | Avant | Apr√®s | Gain |
|-----------|-------|-------|------|
| Cache embedding | 4s | 0.01s | -4s |
| N-grams (30‚Üí20) | 18s | 8s | -10s |
| Cache prompt | 2s | 0.01s | -2s |
| Connection pool | 3s | 1s | -2s |
| **TOTAL** | **68s** | **~5s** | **-63s** |

---

## ‚úÖ VALIDATION

Apr√®s application, v√©rifier dans les logs:
```bash
‚úÖ Optimisations de performance initialis√©es
‚úÖ 2 mod√®les pr√©charg√©s
‚úÖ Cache embedding v√©rifi√©
‚úÖ Optimiseur configur√©
```

Et dans la r√©ponse:
```bash
‚è±Ô∏è DUR√âE TOTALE: ~5000ms (5s)  # Au lieu de 68s
```
