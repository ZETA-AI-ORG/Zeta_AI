#!/usr/bin/env python3
"""
üß™ TEST CONVERSATION RAG COMPL√àTE - SIMULATION CLIENT R√âEL
===========================================================
Test d'une conversation compl√®te : Prise d'info ‚Üí Doutes ‚Üí Commande finale
√âvalue la pertinence, la coh√©rence et la m√©moire conversationnelle du RAG
"""

import asyncio
import time
from typing import Dict, List, Any, Tuple
from datetime import datetime
import json

# Imports du syst√®me RAG
from core.universal_rag_engine import UniversalRAGEngine
from core.enhanced_rag_with_semantic_cache import EnhancedRAGWithSemanticCache
from core.intention_detector import detect_user_intention, format_intention_for_llm

class FullRAGConversationTest:
    """üß™ Test conversation RAG compl√®te avec √©valuation"""
    
    def __init__(self):
        self.company_id = "MpfnlSbqwaZ6F4HvxQLRL9du0yG3"
        self.user_id = "testuser143"
        
        # Initialisation du RAG (CACHE S√âMANTIQUE D√âSACTIV√â)
        self.base_rag = UniversalRAGEngine()
        self.enhanced_rag = EnhancedRAGWithSemanticCache(self.base_rag)
        
        # üö´ D√âSACTIVER LE CACHE S√âMANTIQUE - PRIORIT√â M√âMOIRE CONVERSATIONNELLE
        self.enhanced_rag.enable_cache(False)
        
        # Historique de conversation
        self.conversation_history = []
        self.conversation_context = ""
        
        # M√©triques d'√©valuation
        self.metrics = {
            "total_queries": 0,
            "cache_hits": 0,
            "response_times": [],
            "intention_accuracy": [],
            "context_preservation": [],
            "source_relevance": []
        }
    
    async def run_full_conversation_test(self):
        """üöÄ Lance le test de conversation compl√®te"""
        print("üß™ TEST CONVERSATION RAG COMPL√àTE - CACHE D√âSACTIV√â")
        print("=" * 60)
        print(f"üè¢ Company ID: {self.company_id}")
        print(f"üë§ User ID: {self.user_id}")
        print(f"üö´ Cache s√©mantique: D√âSACTIV√â")
        print(f"üéØ Priorit√©: M√âMOIRE CONVERSATIONNELLE + FIABILIT√â")
        print(f"‚è∞ D√©but: {datetime.now().strftime('%H:%M:%S')}")
        print()
        
        # Sc√©nario de conversation r√©aliste
        conversation_scenario = [
            {
                "phase": "D√âCOUVERTE",
                "query": "Bonjour, j'aimerais conna√Ætre vos produits disponibles",
                "expected_intentions": ["PRODUIT", "INFORMATION", "COMMANDE"],
                "context": "Premier contact client"
            },
            {
                "phase": "INFORMATION PRIX",
                "query": "√áa co√ªte combien vos articles ?",
                "expected_intentions": ["PRIX", "PRODUIT"],
                "context": "Client int√©ress√© par les tarifs"
            },
            {
                "phase": "LIVRAISON",
                "query": "Vous livrez dans quelle zone ? Je suis √† Cocody",
                "expected_intentions": ["LIVRAISON", "LOCALISATION"],
                "context": "Client v√©rifie la faisabilit√© livraison"
            },
            {
                "phase": "DOUTE PRIX",
                "query": "Le transport c'est en plus du prix du produit ?",
                "expected_intentions": ["PRIX", "LIVRAISON", "PRODUIT"],
                "context": "Client a des doutes sur le co√ªt total"
            },
            {
                "phase": "PAIEMENT",
                "query": "Je peux payer comment ? Vous acceptez Wave ?",
                "expected_intentions": ["PAIEMENT"],
                "context": "Client v√©rifie les modalit√©s de paiement"
            },
            {
                "phase": "H√âSITATION",
                "query": "J'h√©site encore... Vous avez d'autres mod√®les ?",
                "expected_intentions": ["PRODUIT", "INFORMATION"],
                "context": "Client h√©site, cherche alternatives"
            },
            {
                "phase": "COMMANDE",
                "query": "OK je prends le produit premium, livraison express √† Cocody",
                "expected_intentions": ["COMMANDE", "PRODUIT", "LIVRAISON"],
                "context": "Client d√©cid√©, passe commande"
            },
            {
                "phase": "CONFIRMATION",
                "query": "√áa fait combien au total avec la livraison ?",
                "expected_intentions": ["PRIX", "LIVRAISON", "COMMANDE"],
                "context": "Client veut confirmation prix total"
            }
        ]
        
        print("üìã SC√âNARIO DE CONVERSATION:")
        for i, step in enumerate(conversation_scenario, 1):
            print(f"  {i}. {step['phase']}: {step['query']}")
        print()
        
        # Ex√©cution de la conversation
        for step_num, step in enumerate(conversation_scenario, 1):
            print(f"\n{'='*60}")
            print(f"üîÑ √âTAPE {step_num}/8 - {step['phase']}")
            print(f"{'='*60}")
            
            await self._process_conversation_step(step, step_num)
            
            # Pause entre les √©tapes pour simuler r√©flexion client
            await asyncio.sleep(0.5)
        
        # Rapport final
        self._generate_final_evaluation_report()
    
    async def _process_conversation_step(self, step: Dict[str, Any], step_num: int):
        """Traite une √©tape de la conversation"""
        query = step["query"]
        phase = step["phase"]
        expected_intentions = step["expected_intentions"]
        context = step["context"]
        
        print(f"üë§ CLIENT: {query}")
        print(f"üéØ Phase: {phase}")
        print(f"üìù Contexte: {context}")
        print()
        
        # Mesure du temps de r√©ponse
        start_time = time.time()
        
        try:
            # üö´ D√âTECTION D'INTENTION D√âSACTIV√âE INT√âGRALEMENT
            # mock_results = {...}
            # intention_result = detect_user_intention(query)
            # intentions = intention_result.get("detected_intentions", [])
            
            # Intentions simul√©es pour le test (sans d√©tection)
            intentions = ["GENERAL"]
            
            # G√©n√©ration de la r√©ponse RAG
            response_data = await self.enhanced_rag.process_query(
                query=query,
                company_id=self.company_id,
                user_id=self.user_id,
                conversation_history=self.conversation_context
            )
            
            response_time = time.time() - start_time
            self.metrics["response_times"].append(response_time)
            self.metrics["total_queries"] += 1
            
            # Extraction des donn√©es de r√©ponse
            response = response_data.get("response", "Erreur: Pas de r√©ponse")
            sources = response_data.get("sources", [])
            cache_used = response_data.get("cache_hit", False)
            
            if cache_used:
                self.metrics["cache_hits"] += 1
            
            # Affichage de la r√©ponse
            print(f"ü§ñ ASSISTANT: {response}")
            print()
            
            # Affichage des intentions d√©tect√©es
            print(f"üéØ INTENTIONS D√âTECT√âES: {intentions}")
            expected_set = set(expected_intentions)
            detected_set = set(intentions)
            intention_accuracy = len(expected_set.intersection(detected_set)) / len(expected_set) if expected_set else 0
            self.metrics["intention_accuracy"].append(intention_accuracy)
            print(f"üìä Pr√©cision intentions: {intention_accuracy:.1%}")
            print()
            
            # Affichage des sources
            print(f"üìö SOURCES UTILIS√âES ({len(sources)}):")
            source_relevance_scores = []
            for i, source in enumerate(sources[:3], 1):  # Top 3 sources
                content = source.get("content", "")[:150] + "..." if len(source.get("content", "")) > 150 else source.get("content", "")
                score = source.get("score", 0)
                index = source.get("index", "unknown")
                
                print(f"  {i}. [{index}] Score: {score:.3f}")
                print(f"     {content}")
                print()
                
                source_relevance_scores.append(score)
            
            avg_source_relevance = sum(source_relevance_scores) / len(source_relevance_scores) if source_relevance_scores else 0
            self.metrics["source_relevance"].append(avg_source_relevance)
            
            # √âvaluation de la pr√©servation du contexte
            context_preservation = self._evaluate_context_preservation(query, response, step_num)
            self.metrics["context_preservation"].append(context_preservation)
            
            # Mise √† jour de l'historique
            self.conversation_history.append({
                "query": query,
                "response": response,
                "phase": phase,
                "timestamp": datetime.now().isoformat()
            })
            
            # Mise √† jour du contexte conversationnel
            self.conversation_context += f"Client: {query}\nAssistant: {response}\n"
            
            # M√©triques de performance
            cache_status = "üéØ CACHE HIT" if cache_used else "üîç RAG SEARCH"
            print(f"‚ö° Temps de r√©ponse: {response_time:.2f}s | {cache_status}")
            print(f"üìà Pertinence sources: {avg_source_relevance:.3f}")
            print(f"üß† Pr√©servation contexte: {context_preservation:.1%}")
            
        except Exception as e:
            print(f"‚ùå ERREUR: {e}")
            self.metrics["response_times"].append(10.0)  # P√©nalit√© pour erreur
    
    def _evaluate_context_preservation(self, query: str, response: str, step_num: int) -> float:
        """√âvalue si le contexte conversationnel est pr√©serv√© - FOCUS M√âMOIRE CONVERSATIONNELLE"""
        if step_num <= 2:
            return 1.0  # Pas de contexte √† pr√©server au d√©but
        
        # V√©rifications contextuelles renforc√©es
        context_indicators = 0
        total_checks = 0
        
        # CRIT√àRE 1: Pr√©servation de la localisation "Cocody" (√©tape 3+)
        if step_num >= 3:
            total_checks += 1
            # V√©rifier dans la r√©ponse ET dans l'historique conversationnel
            cocody_in_response = "cocody" in response.lower()
            cocody_in_context = "cocody" in self.conversation_context.lower()
            
            if cocody_in_response or cocody_in_context:
                context_indicators += 1
                print(f"    ‚úÖ Contexte Cocody pr√©serv√© √† l'√©tape {step_num} (r√©ponse: {cocody_in_response}, contexte: {cocody_in_context})")
            else:
                print(f"    ‚ùå Contexte Cocody perdu √† l'√©tape {step_num}")
        
        # CRIT√àRE 2: Coh√©rence des prix mentionn√©s (√©tape 2+)
        if step_num >= 2:
            total_checks += 1
            prix_patterns = ["5.500", "5500", "17.900", "17900", "28.900", "28900", "fcfa", "1500", "2000"]
            if any(price in response.lower() for price in prix_patterns):
                context_indicators += 1
                print(f"    ‚úÖ Prix coh√©rents √† l'√©tape {step_num}")
            else:
                print(f"    ‚ùå Prix incoh√©rents √† l'√©tape {step_num}")
        
        # CRIT√àRE 3: R√©f√©rence aux produits sp√©cifiques (√©tape 1+)
        if step_num >= 1:
            total_checks += 1
            produits_patterns = ["couches", "pression", "culottes", "paquet", "taille"]
            if any(prod in response.lower() for prod in produits_patterns):
                context_indicators += 1
                print(f"    ‚úÖ Produits sp√©cifiques mentionn√©s √† l'√©tape {step_num}")
            else:
                print(f"    ‚ùå Produits g√©n√©riques √† l'√©tape {step_num}")
        
        # CRIT√àRE 4: Coh√©rence des informations de livraison (√©tape 3+)
        if step_num >= 3:
            total_checks += 1
            livraison_patterns = ["livraison", "transport", "zone", "centrale", "1500"]
            if any(word in response.lower() for word in livraison_patterns):
                context_indicators += 1
                print(f"    ‚úÖ Informations livraison coh√©rentes √† l'√©tape {step_num}")
            else:
                print(f"    ‚ùå Informations livraison incoh√©rentes √† l'√©tape {step_num}")
        
        # CRIT√àRE 5: Progression logique de la conversation (√©tape 5+)
        if step_num >= 5:
            total_checks += 1
            progression_patterns = ["wave", "paiement", "acompte", "2000", "commande"]
            if any(word in response.lower() for word in progression_patterns):
                context_indicators += 1
                print(f"    ‚úÖ Progression logique √† l'√©tape {step_num}")
            else:
                print(f"    ‚ùå Pas de progression logique √† l'√©tape {step_num}")
        
        score = context_indicators / total_checks if total_checks > 0 else 1.0
        print(f"    üìä Score contexte: {context_indicators}/{total_checks} = {score:.1%}")
        return score
    
    def _generate_final_evaluation_report(self):
        """G√©n√®re le rapport d'√©valuation final"""
        print("\n" + "="*80)
        print("üìä RAPPORT D'√âVALUATION FINAL - CONVERSATION RAG COMPL√àTE")
        print("="*80)
        
        # M√©triques g√©n√©rales
        total_queries = self.metrics["total_queries"]
        cache_hits = self.metrics["cache_hits"]
        cache_hit_rate = (cache_hits / total_queries) * 100 if total_queries > 0 else 0
        
        avg_response_time = sum(self.metrics["response_times"]) / len(self.metrics["response_times"]) if self.metrics["response_times"] else 0
        avg_intention_accuracy = sum(self.metrics["intention_accuracy"]) / len(self.metrics["intention_accuracy"]) if self.metrics["intention_accuracy"] else 0
        avg_context_preservation = sum(self.metrics["context_preservation"]) / len(self.metrics["context_preservation"]) if self.metrics["context_preservation"] else 0
        avg_source_relevance = sum(self.metrics["source_relevance"]) / len(self.metrics["source_relevance"]) if self.metrics["source_relevance"] else 0
        
        print(f"üî¢ M√âTRIQUES G√âN√âRALES:")
        print(f"  ‚Ä¢ Total requ√™tes: {total_queries}")
        print(f"  ‚Ä¢ Cache hits: {cache_hits}/{total_queries} ({cache_hit_rate:.1f}%)")
        print(f"  ‚Ä¢ Temps de r√©ponse moyen: {avg_response_time:.2f}s")
        print()
        
        print(f"üéØ QUALIT√â DES R√âPONSES:")
        print(f"  ‚Ä¢ Pr√©cision intentions: {avg_intention_accuracy:.1%}")
        print(f"  ‚Ä¢ Pertinence sources: {avg_source_relevance:.3f}")
        print(f"  ‚Ä¢ Pr√©servation contexte: {avg_context_preservation:.1%}")
        print()
        
        # √âvaluation globale - PRIORIT√â M√âMOIRE CONVERSATIONNELLE (cache d√©sactiv√©)
        overall_score = (
            avg_intention_accuracy * 0.3 +      # 30% pour pr√©cision intentions
            avg_source_relevance * 0.2 +        # 20% pour pertinence sources  
            avg_context_preservation * 0.5      # 50% pour m√©moire conversationnelle ‚≠ê
        ) * 100
        
        print(f"üèÜ SCORE GLOBAL: {overall_score:.1f}%")
        
        # √âvaluation qualitative
        if overall_score >= 90:
            evaluation = "üéâ EXCELLENT - RAG pr√™t pour production"
        elif overall_score >= 80:
            evaluation = "‚úÖ TR√àS BON - Quelques optimisations mineures"
        elif overall_score >= 70:
            evaluation = "‚ö†Ô∏è BON - Am√©liorations n√©cessaires"
        else:
            evaluation = "‚ùå INSUFFISANT - Corrections majeures requises"
        
        print(f"üìã √âVALUATION: {evaluation}")
        print()
        
        # Analyse d√©taill√©e par phase
        print(f"üìà ANALYSE PAR PHASE:")
        phases = ["D√âCOUVERTE", "INFORMATION PRIX", "LIVRAISON", "DOUTE PRIX", 
                 "PAIEMENT", "H√âSITATION", "COMMANDE", "CONFIRMATION"]
        
        for i, phase in enumerate(phases):
            if i < len(self.metrics["intention_accuracy"]):
                intention_acc = self.metrics["intention_accuracy"][i]
                response_time = self.metrics["response_times"][i]
                context_pres = self.metrics["context_preservation"][i] if i < len(self.metrics["context_preservation"]) else 0
                
                print(f"  {i+1}. {phase}:")
                print(f"     Intentions: {intention_acc:.1%} | Temps: {response_time:.2f}s | Contexte: {context_pres:.1%}")
        print()
        
        # Recommandations - FOCUS M√âMOIRE CONVERSATIONNELLE
        print(f"üí° RECOMMANDATIONS (PRIORIT√â M√âMOIRE CONVERSATIONNELLE):")
        
        if avg_context_preservation < 0.8:
            print("  üéØ PRIORIT√â 1: Am√©liorer la m√©moire conversationnelle")
            print("    - Enrichir le contexte pass√© au LLM")
            print("    - Conserver les √©l√©ments cl√©s (Cocody, produits choisis)")
            print("    - Impl√©menter un r√©sum√© intelligent de conversation")
        
        if avg_intention_accuracy < 0.8:
            print("  üéØ PRIORIT√â 2: Enrichir les patterns de d√©tection d'intention")
        
        if avg_source_relevance < 0.5:
            print("  üéØ PRIORIT√â 3: Optimiser le routing des index")
            print("    - Am√©liorer la s√©lection d'index par pertinence")
            print("    - √âviter les documents non pertinents")
        
        if avg_response_time > 5.0:
            print("  ‚Ä¢ Optimiser les performances (sans cache)")
        
        print("  ‚úÖ Cache s√©mantique d√©sactiv√© - Focus sur fiabilit√©")
        
        print()
        print(f"‚è∞ Test termin√©: {datetime.now().strftime('%H:%M:%S')}")
        print("="*80)
        
        # Sauvegarde des r√©sultats
        self._save_test_results(overall_score, evaluation)
    
    def _save_test_results(self, overall_score: float, evaluation: str):
        """Sauvegarde les r√©sultats du test"""
        results = {
            "timestamp": datetime.now().isoformat(),
            "company_id": self.company_id,
            "user_id": self.user_id,
            "overall_score": overall_score,
            "evaluation": evaluation,
            "metrics": self.metrics,
            "conversation_history": self.conversation_history
        }
        
        filename = f"rag_conversation_test_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False)
            print(f"üíæ R√©sultats sauvegard√©s: {filename}")
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur sauvegarde: {e}")

async def main():
    """üöÄ Fonction principale"""
    print("üöÄ LANCEMENT TEST CONVERSATION RAG COMPL√àTE")
    print()
    
    test_suite = FullRAGConversationTest()
    await test_suite.run_full_conversation_test()

if __name__ == "__main__":
    asyncio.run(main())
