#!/usr/bin/env python3
"""
üß™ TESTS COMPLETS DU SYST√àME DE CACHE S√âMANTIQUE R√âVOLUTIONNAIRE
================================================================
Tests de validation pour le cache dynamique intention-FAQ

TESTS COUVERTS:
- Performance du cache s√©mantique
- Two-Stage Retrieval Engine
- Matching s√©mantique avec embeddings
- Int√©gration avec le syst√®me RAG existant
- Gestion des intentions et entit√©s
"""

import asyncio
import time
import json
from typing import Dict, Any, List
from datetime import datetime

from core.semantic_intent_cache import (
    get_semantic_intent_cache, 
    IntentSignature,
    create_intent_signature_from_detection
)
from core.enhanced_rag_with_semantic_cache import create_enhanced_rag_with_cache
from core.rag_cache_integration import get_rag_cache_integration, with_semantic_cache
from core.universal_rag_engine import UniversalRAGEngine
from utils import log3

class SemanticCacheTestSuite:
    """üß™ Suite de tests pour le cache s√©mantique"""
    
    def __init__(self):
        self.semantic_cache = get_semantic_intent_cache()
        self.test_results = []
        self.performance_metrics = {
            "cache_hits": 0,
            "cache_misses": 0,
            "avg_cache_response_time": 0.0,
            "avg_rag_response_time": 0.0,
            "semantic_matches": 0,
            "exact_matches": 0
        }
    
    async def run_all_tests(self) -> Dict[str, Any]:
        """üöÄ Ex√©cute tous les tests du cache s√©mantique"""
        print("üß™ D√âMARRAGE TESTS CACHE S√âMANTIQUE R√âVOLUTIONNAIRE")
        print("=" * 70)
        
        # Vider le cache avant les tests
        await self.semantic_cache.clear_cache()
        
        test_methods = [
            self.test_basic_cache_operations,
            self.test_semantic_similarity_matching,
            self.test_intent_based_caching,
            self.test_two_stage_retrieval,
            self.test_performance_comparison,
            self.test_multi_granular_cache,
            self.test_conversation_context_awareness,
            self.test_cache_integration
        ]
        
        for test_method in test_methods:
            try:
                print(f"\nüî¨ {test_method.__name__.replace('_', ' ').title()}")
                print("-" * 50)
                
                start_time = time.time()
                result = await test_method()
                execution_time = time.time() - start_time
                
                self.test_results.append({
                    "test_name": test_method.__name__,
                    "status": "PASSED" if result.get("success", False) else "FAILED",
                    "execution_time": execution_time,
                    "details": result
                })
                
                status_emoji = "‚úÖ" if result.get("success", False) else "‚ùå"
                print(f"{status_emoji} {test_method.__name__}: {result.get('message', 'Completed')} ({execution_time:.2f}s)")
                
            except Exception as e:
                print(f"‚ùå {test_method.__name__}: ERREUR - {e}")
                self.test_results.append({
                    "test_name": test_method.__name__,
                    "status": "ERROR",
                    "execution_time": 0,
                    "error": str(e)
                })
        
        return self._generate_test_report()
    
    async def test_basic_cache_operations(self) -> Dict[str, Any]:
        """Test des op√©rations de base du cache avec donn√©es RUE_DU_GROS"""
        intent_sig = IntentSignature(
            primary_intent="LIVRAISON",
            secondary_intents=["PRIX"],
            entities={"zone": "Cocody", "company_id": "MpfnlSbqwaZ6F4HvxQLRL9du0yG3"},
            context_hash="LIVRAISON|PRIX",
            confidence_score=1.0
        )
        
        # Test stockage avec vraies donn√©es Rue_du_gros
        store_success = await self.semantic_cache.store_response(
            query="Combien co√ªte la livraison √† Cocody ?",
            response="La livraison √† Cocody co√ªte 1500 FCFA (zone centrale Abidjan).",
            intent_signature=intent_sig,
            conversation_history="Client demande info livraison Rue_du_gros"
        )
        
        if not store_success:
            return {"success": False, "message": "√âchec stockage"}
        
        # Test r√©cup√©ration
        cache_result = await self.semantic_cache.get_cached_response(
            query="Combien co√ªte la livraison √† Cocody ?",
            intent_signature=intent_sig,
            conversation_history="Test basique"
        )
        
        if cache_result:
            response, confidence = cache_result
            return {
                "success": True,
                "message": f"Cache op√©rationnel (confiance: {confidence:.3f})",
                "response": response
            }
        
        return {"success": False, "message": "√âchec r√©cup√©ration"}
    
    async def test_semantic_similarity_matching(self) -> Dict[str, Any]:
        """Test du matching s√©mantique avec formulations diff√©rentes - RUE_DU_GROS"""
        intent_sig = IntentSignature(
            primary_intent="LIVRAISON",
            secondary_intents=["PRIX"],
            entities={"zone": "Yopougon", "company_id": "MpfnlSbqwaZ6F4HvxQLRL9du0yG3"},
            context_hash="LIVRAISON|PRIX",
            confidence_score=1.0
        )
        
        # Stocker avec une formulation (donn√©es r√©elles Rue_du_gros)
        await self.semantic_cache.store_response(
            query="Quel est le prix pour livrer √† Yopougon ?",
            response="La livraison √† Yopougon co√ªte 1500 FCFA (zone centrale Abidjan).",
            intent_signature=intent_sig
        )
        
        # Tester avec des formulations diff√©rentes
        test_queries = [
            "Combien √ßa co√ªte d'envoyer √† Yopougon ?",
            "Tarif livraison Yopougon ?",
            "Prix pour exp√©dier vers Yopougon",
            "Co√ªt transport Yopougon"
        ]
        
        matches = 0
        confidences = []
        
        for query in test_queries:
            result = await self.semantic_cache.get_cached_response(
                query=query,
                intent_signature=intent_sig
            )
            
            if result:
                response, confidence = result
                matches += 1
                confidences.append(confidence)
                self.performance_metrics["semantic_matches"] += 1
        
        avg_confidence = sum(confidences) / len(confidences) if confidences else 0
        
        return {
            "success": matches >= 2,  # Au moins 2 matches sur 4
            "message": f"{matches}/4 formulations match√©es (conf. moy: {avg_confidence:.3f})",
            "matches": matches,
            "avg_confidence": avg_confidence
        }
    
    async def test_intent_based_caching(self) -> Dict[str, Any]:
        """Test du cache bas√© sur les intentions - RUE_DU_GROS"""
        company_id = "MpfnlSbqwaZ6F4HvxQLRL9du0yG3"
        
        # Cr√©er diff√©rentes intentions avec donn√©es r√©elles
        intents = [
            IntentSignature("PRODUIT", ["PRIX"], {"produit": "couches", "company_id": company_id}, "PRODUIT|PRIX", 1.0),
            IntentSignature("LIVRAISON", ["PRIX"], {"zone": "Plateau", "company_id": company_id}, "LIVRAISON|PRIX", 1.0),
            IntentSignature("SUPPORT", ["COMMANDE"], {"type": "whatsapp", "company_id": company_id}, "SUPPORT|COMMANDE", 1.0)
        ]
        
        queries_responses = [
            ("Combien co√ªtent les couches culottes 3 paquets ?", "Les couches culottes 3 paquets co√ªtent 13.500 FCFA (4.500 F/paquet)."),
            ("Livraison au Plateau ?", "Livraison Plateau: 1500 FCFA (zone centrale Abidjan)."),
            ("Num√©ro WhatsApp pour commander ?", "WhatsApp: +2250160924560 | T√©l√©phone: +2250787360757")
        ]
        
        # Stocker les r√©ponses
        for i, (query, response) in enumerate(queries_responses):
            await self.semantic_cache.store_response(
                query=query,
                response=response,
                intent_signature=intents[i]
            )
        
        # Tester la r√©cup√©ration par intention
        correct_retrievals = 0
        
        for i, (test_query, expected_response) in enumerate(queries_responses):
            result = await self.semantic_cache.get_cached_response(
                query=test_query,
                intent_signature=intents[i]
            )
            
            if result:
                response, confidence = result
                if expected_response in response:
                    correct_retrievals += 1
        
        return {
            "success": correct_retrievals == 3,
            "message": f"{correct_retrievals}/3 intentions correctement r√©cup√©r√©es",
            "correct_retrievals": correct_retrievals
        }
    
    async def test_two_stage_retrieval(self) -> Dict[str, Any]:
        """Test du moteur Two-Stage Retrieval"""
        # Remplir le cache avec plusieurs entr√©es
        test_data = [
            ("Prix casque rouge", "PRIX_PRODUIT", {"produit": "casque", "couleur": "rouge"}, "Casque rouge: 7000 FCFA"),
            ("Prix casque bleu", "PRIX_PRODUIT", {"produit": "casque", "couleur": "bleu"}, "Casque bleu: 6500 FCFA"),
            ("Livraison Cocody", "LIVRAISON_INFO", {"zone": "Cocody"}, "Livraison Cocody: 1500 FCFA"),
            ("Livraison Yopougon", "LIVRAISON_INFO", {"zone": "Yopougon"}, "Livraison Yopougon: 1000 FCFA"),
        ]
        
        for query, intent, entities, response in test_data:
            intent_sig = IntentSignature(intent, [], entities, f"test_{intent}", 0.9)
            await self.semantic_cache.store_response(query, response, intent_sig)
        
        # Test Stage 1: Recherche rapide
        retrieval_engine = self.semantic_cache.retrieval_engine
        query_embedding = retrieval_engine.create_query_embedding("Combien co√ªte le casque rouge ?")
        
        candidates = retrieval_engine.stage1_rapid_search(query_embedding, self.semantic_cache.memory_cache)
        
        # Test Stage 2: Matching contextuel
        if candidates:
            intent_sig = IntentSignature("PRIX_PRODUIT", [], {"produit": "casque", "couleur": "rouge"}, "test", 0.9)
            context_embedding = retrieval_engine.create_context_embedding("")
            
            best_match = retrieval_engine.stage2_contextual_matching(
                query_embedding, context_embedding, intent_sig, candidates, self.semantic_cache.memory_cache
            )
            
            return {
                "success": best_match is not None,
                "message": f"Two-Stage: {len(candidates)} candidats ‚Üí {'Match trouv√©' if best_match else 'Aucun match'}",
                "candidates_count": len(candidates),
                "best_match_found": best_match is not None
            }
        
        return {"success": False, "message": "Aucun candidat trouv√© en Stage 1"}
    
    async def test_performance_comparison(self) -> Dict[str, Any]:
        """Test de comparaison de performance cache vs RAG"""
        # Simuler une r√©ponse RAG lente
        async def mock_rag_response(query: str) -> str:
            await asyncio.sleep(2)  # Simuler 2s de traitement RAG
            return f"R√©ponse RAG simul√©e pour: {query}"
        
        test_query = "Combien co√ªte la livraison express ?"
        intent_sig = IntentSignature("LIVRAISON_EXPRESS", [], {"type": "express"}, "perf_test", 0.9)
        
        # Test 1: RAG classique (cache miss)
        start_time = time.time()
        rag_response = await mock_rag_response(test_query)
        rag_time = time.time() - start_time
        
        # Stocker dans le cache
        await self.semantic_cache.store_response(test_query, rag_response, intent_sig)
        
        # Test 2: Cache hit
        start_time = time.time()
        cache_result = await self.semantic_cache.get_cached_response(test_query, intent_sig)
        cache_time = time.time() - start_time
        
        if cache_result:
            speedup = rag_time / cache_time if cache_time > 0 else float('inf')
            self.performance_metrics["avg_rag_response_time"] = rag_time
            self.performance_metrics["avg_cache_response_time"] = cache_time
            
            return {
                "success": speedup > 5,  # Au moins 5x plus rapide
                "message": f"Speedup: {speedup:.1f}x ({rag_time:.2f}s ‚Üí {cache_time:.3f}s)",
                "rag_time": rag_time,
                "cache_time": cache_time,
                "speedup": speedup
            }
        
        return {"success": False, "message": "Cache hit √©chou√©"}
    
    async def test_multi_granular_cache(self) -> Dict[str, Any]:
        """Test du cache multi-granulaire - RUE_DU_GROS"""
        company_id = "MpfnlSbqwaZ6F4HvxQLRL9du0yG3"
        
        # Niveau 1: Intention seule
        intent_general = IntentSignature("PRIX", [], {"company_id": company_id}, "PRIX", 1.0)
        await self.semantic_cache.store_response(
            "Quels sont vos prix ?", "Nos prix varient selon les produits: couches √† pression, couches culottes, couches adultes.", intent_general
        )
        
        # Niveau 2: Intention + entit√©
        intent_specific = IntentSignature("PRIX", [], {"produit": "couches", "company_id": company_id}, "PRIX", 1.0)
        await self.semantic_cache.store_response(
            "Prix des couches ?", "Couches culottes: 5.500-168.000 FCFA selon quantit√©.", intent_specific
        )
        
        # Niveau 3: Intention + entit√© + contexte
        intent_detailed = IntentSignature("PRIX", [], {"produit": "couches", "quantite": "3", "company_id": company_id}, "PRIX", 1.0)
        await self.semantic_cache.store_response(
            "Prix 3 paquets couches culottes ?", "3 paquets couches culottes: 13.500 FCFA (4.500 F/paquet).", intent_detailed
        )
        
        # Tester la granularit√©
        test_cases = [
            ("Prix ?", intent_general, "g√©n√©ral"),
            ("Prix couches ?", intent_specific, "sp√©cifique"),
            ("Prix 3 paquets couches culottes ?", intent_detailed, "d√©taill√©")
        ]
        
        matches = 0
        for query, intent, level in test_cases:
            result = await self.semantic_cache.get_cached_response(query, intent)
            if result:
                matches += 1
        
        return {
            "success": matches == 3,
            "message": f"Cache multi-granulaire: {matches}/3 niveaux fonctionnels",
            "matches": matches
        }
    
    async def test_conversation_context_awareness(self) -> Dict[str, Any]:
        """Test de la prise en compte du contexte conversationnel"""
        intent_sig = IntentSignature("PRIX_CONTEXTUEL", [], {"produit": "smartphone"}, "context_test", 0.9)
        
        # Contexte 1: Client int√©ress√©
        context1 = "L'utilisateur compare des smartphones pour un achat."
        await self.semantic_cache.store_response(
            "Prix smartphone ?", "Smartphone: 150000 FCFA. Excellent rapport qualit√©-prix !", 
            intent_sig, context1
        )
        
        # Contexte 2: Client h√©sitant
        context2 = "L'utilisateur h√©site et cherche des alternatives moins ch√®res."
        await self.semantic_cache.store_response(
            "Prix smartphone ?", "Smartphone: 150000 FCFA. Nous avons aussi des mod√®les √† 80000 FCFA.", 
            intent_sig, context2
        )
        
        # Tester avec contextes similaires
        result1 = await self.semantic_cache.get_cached_response(
            "Combien co√ªte le smartphone ?", intent_sig, 
            "L'utilisateur veut acheter un smartphone de qualit√©."
        )
        
        result2 = await self.semantic_cache.get_cached_response(
            "Prix du smartphone ?", intent_sig,
            "L'utilisateur cherche quelque chose de pas cher."
        )
        
        context_matches = 0
        if result1 and "qualit√©-prix" in result1[0]:
            context_matches += 1
        if result2 and "80000" in result2[0]:
            context_matches += 1
        
        return {
            "success": context_matches >= 1,
            "message": f"Contexte conversationnel: {context_matches}/2 matches contextuels",
            "context_matches": context_matches
        }
    
    async def test_cache_integration(self) -> Dict[str, Any]:
        """Test de l'int√©gration avec le syst√®me existant"""
        integration = get_rag_cache_integration()
        
        # Cr√©er une fonction mock avec le d√©corateur
        @with_semantic_cache
        async def mock_rag_function(query: str, company_id: str) -> str:
            await asyncio.sleep(1)  # Simuler traitement
            return f"R√©ponse RAG int√©gr√©e: {query}"
        
        # Test 1: Premi√®re requ√™te (cache miss)
        start1 = time.time()
        result1 = await mock_rag_function("Test int√©gration cache", "test_company")
        time1 = time.time() - start1
        
        # Test 2: Requ√™te similaire (cache hit attendu)
        start2 = time.time()
        result2 = await mock_rag_function("Test int√©gration du cache", "test_company")
        time2 = time.time() - start2
        
        # V√©rifier l'am√©lioration de performance
        speedup = time1 / time2 if time2 > 0 else 1
        
        return {
            "success": speedup > 2,  # Au moins 2x plus rapide
            "message": f"Int√©gration: {speedup:.1f}x speedup ({time1:.2f}s ‚Üí {time2:.2f}s)",
            "first_call_time": time1,
            "second_call_time": time2,
            "speedup": speedup
        }
    
    def _generate_test_report(self) -> Dict[str, Any]:
        """G√©n√®re le rapport final des tests"""
        passed_tests = sum(1 for result in self.test_results if result["status"] == "PASSED")
        total_tests = len(self.test_results)
        success_rate = (passed_tests / total_tests) * 100 if total_tests > 0 else 0
        
        cache_stats = self.semantic_cache.get_stats()
        
        report = {
            "test_summary": {
                "total_tests": total_tests,
                "passed_tests": passed_tests,
                "failed_tests": total_tests - passed_tests,
                "success_rate_percent": round(success_rate, 2)
            },
            "performance_metrics": self.performance_metrics,
            "cache_statistics": cache_stats,
            "detailed_results": self.test_results,
            "timestamp": datetime.now().isoformat(),
            "overall_status": "SUCCESS" if success_rate >= 80 else "PARTIAL" if success_rate >= 60 else "FAILED"
        }
        
        return report

async def main():
    """üöÄ Fonction principale de test"""
    print("üß™ LANCEMENT SUITE DE TESTS CACHE S√âMANTIQUE R√âVOLUTIONNAIRE")
    print("=" * 80)
    
    test_suite = SemanticCacheTestSuite()
    
    try:
        # Ex√©cuter tous les tests
        report = await test_suite.run_all_tests()
        
        # Afficher le rapport final
        print("\n" + "=" * 80)
        print("üìä RAPPORT FINAL DES TESTS")
        print("=" * 80)
        
        summary = report["test_summary"]
        print(f"‚úÖ Tests r√©ussis: {summary['passed_tests']}/{summary['total_tests']}")
        print(f"üìà Taux de r√©ussite: {summary['success_rate_percent']}%")
        print(f"üéØ Statut global: {report['overall_status']}")
        
        # Statistiques de performance
        perf = report["performance_metrics"]
        if perf["avg_cache_response_time"] > 0 and perf["avg_rag_response_time"] > 0:
            speedup = perf["avg_rag_response_time"] / perf["avg_cache_response_time"]
            print(f"‚ö° Speedup moyen: {speedup:.1f}x")
        
        # Statistiques du cache
        cache_stats = report["cache_statistics"]
        print(f"üéØ Taux de hit cache: {cache_stats.get('hit_rate_percent', 0)}%")
        print(f"üíæ Taille du cache: {cache_stats.get('cache_size', 0)} entr√©es")
        
        # Sauvegarder le rapport
        report_filename = f"semantic_cache_test_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_filename, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"üìÑ Rapport sauvegard√©: {report_filename}")
        
        # Verdict final
        if report["overall_status"] == "SUCCESS":
            print("\nüéâ SYST√àME DE CACHE S√âMANTIQUE R√âVOLUTIONNAIRE VALID√â !")
            print("‚úÖ Pr√™t pour la production")
        elif report["overall_status"] == "PARTIAL":
            print("\n‚ö†Ô∏è Syst√®me partiellement fonctionnel - Optimisations recommand√©es")
        else:
            print("\n‚ùå Probl√®mes d√©tect√©s - Corrections n√©cessaires")
        
    except Exception as e:
        print(f"\n‚ùå ERREUR CRITIQUE LORS DES TESTS: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(main())
