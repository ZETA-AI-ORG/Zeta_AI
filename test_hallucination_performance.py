#!/usr/bin/env python3
"""
‚ö° TEST DE PERFORMANCE - GARDE-FOU ANTI-HALLUCINATION
Mesure de l'impact performance du nouveau syst√®me
"""

import asyncio
import time
import statistics
import psutil
import os
from typing import List, Dict
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class PerformanceTester:
    """Testeur de performance pour le syst√®me anti-hallucination"""
    
    def __init__(self):
        self.results = []
        self.memory_usage = []
        self.cpu_usage = []
        
    def get_system_metrics(self) -> Dict:
        """R√©cup√®re les m√©triques syst√®me"""
        process = psutil.Process(os.getpid())
        return {
            'memory_mb': process.memory_info().rss / 1024 / 1024,
            'cpu_percent': process.cpu_percent(),
            'threads': process.num_threads()
        }
    
    async def test_old_system_performance(self, num_tests: int = 10) -> Dict:
        """Test de performance de l'ancien syst√®me"""
        print("üìä Test de performance de l'ANCIEN syst√®me...")
        
        try:
            from core.rag_engine_simplified_fixed import get_rag_response
            
            times = []
            memory_usage = []
            
            for i in range(num_tests):
                # Mesure des m√©triques avant
                metrics_before = self.get_system_metrics()
                
                start_time = time.time()
                
                # Test
                response = await get_rag_response(
                    message="Comment tu t'appelles ?",
                    company_id="test_company",
                    user_id="test_user"
                )
                
                end_time = time.time()
                
                # Mesure des m√©triques apr√®s
                metrics_after = self.get_system_metrics()
                
                processing_time = (end_time - start_time) * 1000
                memory_delta = metrics_after['memory_mb'] - metrics_before['memory_mb']
                
                times.append(processing_time)
                memory_usage.append(memory_delta)
                
                print(f"   Test {i+1}/{num_tests}: {processing_time:.2f}ms, {memory_delta:+.2f}MB")
            
            return {
                'system': 'old',
                'times': times,
                'memory_usage': memory_usage,
                'avg_time': statistics.mean(times),
                'median_time': statistics.median(times),
                'std_time': statistics.stdev(times) if len(times) > 1 else 0,
                'avg_memory': statistics.mean(memory_usage),
                'max_memory': max(memory_usage),
                'min_memory': min(memory_usage)
            }
            
        except Exception as e:
            print(f"   ‚ùå Erreur: {e}")
            return {'system': 'old', 'error': str(e)}
    
    async def test_new_system_performance(self, num_tests: int = 10) -> Dict:
        """Test de performance du nouveau syst√®me"""
        print("\nüìä Test de performance du NOUVEAU syst√®me...")
        
        try:
            from core.rag_engine_simplified_fixed import get_rag_response_advanced
            
            times = []
            memory_usage = []
            
            for i in range(num_tests):
                # Mesure des m√©triques avant
                metrics_before = self.get_system_metrics()
                
                start_time = time.time()
                
                # Test
                result = await get_rag_response_advanced(
                    message="Comment tu t'appelles ?",
                    user_id="test_user",
                    company_id="test_company"
                )
                
                end_time = time.time()
                
                # Mesure des m√©triques apr√®s
                metrics_after = self.get_system_metrics()
                
                processing_time = (end_time - start_time) * 1000
                memory_delta = metrics_after['memory_mb'] - metrics_before['memory_mb']
                
                times.append(processing_time)
                memory_usage.append(memory_delta)
                
                print(f"   Test {i+1}/{num_tests}: {processing_time:.2f}ms, {memory_delta:+.2f}MB")
            
            return {
                'system': 'new',
                'times': times,
                'memory_usage': memory_usage,
                'avg_time': statistics.mean(times),
                'median_time': statistics.median(times),
                'std_time': statistics.stdev(times) if len(times) > 1 else 0,
                'avg_memory': statistics.mean(memory_usage),
                'max_memory': max(memory_usage),
                'min_memory': min(memory_usage)
            }
            
        except Exception as e:
            print(f"   ‚ùå Erreur: {e}")
            return {'system': 'new', 'error': str(e)}
    
    async def test_concurrent_performance(self, num_concurrent: int = 5, num_tests: int = 20) -> Dict:
        """Test de performance en concurrence"""
        print(f"\nüìä Test de performance CONCURRENT ({num_concurrent} concurrent, {num_tests} tests)...")
        
        try:
            from core.rag_engine_simplified_fixed import get_rag_response_advanced
            
            async def single_concurrent_test(test_id: int):
                start_time = time.time()
                
                result = await get_rag_response_advanced(
                    message=f"Test concurrent {test_id}",
                    user_id=f"test_user_{test_id}",
                    company_id="test_company"
                )
                
                end_time = time.time()
                return (end_time - start_time) * 1000
            
            # Cr√©er les t√¢ches concurrentes
            tasks = []
            for i in range(num_tests):
                task = single_concurrent_test(i)
                tasks.append(task)
            
            # Ex√©cuter avec limitation de concurrence
            semaphore = asyncio.Semaphore(num_concurrent)
            
            async def limited_task(task):
                async with semaphore:
                    return await task
            
            # Ex√©cuter toutes les t√¢ches
            start_time = time.time()
            times = await asyncio.gather(*[limited_task(task) for task in tasks])
            total_time = time.time() - start_time
            
            return {
                'system': 'new_concurrent',
                'times': times,
                'total_time': total_time,
                'avg_time': statistics.mean(times),
                'median_time': statistics.median(times),
                'std_time': statistics.stdev(times) if len(times) > 1 else 0,
                'requests_per_second': num_tests / total_time,
                'concurrent_limit': num_concurrent
            }
            
        except Exception as e:
            print(f"   ‚ùå Erreur: {e}")
            return {'system': 'new_concurrent', 'error': str(e)}
    
    def compare_performance(self, old_results: Dict, new_results: Dict) -> Dict:
        """Compare les performances des deux syst√®mes"""
        print("\nüìä COMPARAISON DES PERFORMANCES")
        print("=" * 50)
        
        if 'error' in old_results or 'error' in new_results:
            print("‚ùå Impossible de comparer - erreurs d√©tect√©es")
            return {}
        
        # Comparaison du temps
        time_improvement = ((old_results['avg_time'] - new_results['avg_time']) / old_results['avg_time']) * 100
        
        print(f"‚è±Ô∏è  TEMPS DE TRAITEMENT:")
        print(f"   Ancien syst√®me: {old_results['avg_time']:.2f}ms (m√©diane: {old_results['median_time']:.2f}ms)")
        print(f"   Nouveau syst√®me: {new_results['avg_time']:.2f}ms (m√©diane: {new_results['median_time']:.2f}ms)")
        print(f"   Am√©lioration: {time_improvement:+.1f}%")
        
        # Comparaison de la m√©moire
        memory_impact = new_results['avg_memory'] - old_results['avg_memory']
        
        print(f"\nüíæ UTILISATION M√âMOIRE:")
        print(f"   Ancien syst√®me: {old_results['avg_memory']:+.2f}MB")
        print(f"   Nouveau syst√®me: {new_results['avg_memory']:+.2f}MB")
        print(f"   Impact: {memory_impact:+.2f}MB")
        
        # Analyse de la stabilit√©
        old_stability = old_results['std_time'] / old_results['avg_time'] * 100
        new_stability = new_results['std_time'] / new_results['avg_time'] * 100
        
        print(f"\nüìà STABILIT√â (coefficient de variation):")
        print(f"   Ancien syst√®me: {old_stability:.1f}%")
        print(f"   Nouveau syst√®me: {new_stability:.1f}%")
        
        # Recommandations
        print(f"\nüí° RECOMMANDATIONS:")
        
        if time_improvement > 20:
            print("   ‚úÖ Le nouveau syst√®me est significativement plus rapide")
        elif time_improvement > 0:
            print("   ‚úÖ Le nouveau syst√®me est l√©g√®rement plus rapide")
        elif time_improvement > -20:
            print("   ‚ö†Ô∏è  Le nouveau syst√®me est l√©g√®rement plus lent")
        else:
            print("   ‚ö†Ô∏è  Le nouveau syst√®me est significativement plus lent")
        
        if memory_impact < 10:
            print("   ‚úÖ Impact m√©moire acceptable")
        elif memory_impact < 50:
            print("   ‚ö†Ô∏è  Impact m√©moire mod√©r√©")
        else:
            print("   ‚ö†Ô∏è  Impact m√©moire √©lev√©")
        
        if new_stability < old_stability:
            print("   ‚úÖ Le nouveau syst√®me est plus stable")
        else:
            print("   ‚ö†Ô∏è  Le nouveau syst√®me est moins stable")
        
        return {
            'time_improvement': time_improvement,
            'memory_impact': memory_impact,
            'stability_improvement': old_stability - new_stability,
            'recommendations': self._generate_recommendations(time_improvement, memory_impact, new_stability)
        }
    
    def _generate_recommendations(self, time_improvement: float, memory_impact: float, stability: float) -> List[str]:
        """G√©n√®re des recommandations bas√©es sur les r√©sultats"""
        recommendations = []
        
        if time_improvement < -50:
            recommendations.append("Consid√©rer l'optimisation du nouveau syst√®me")
        
        if memory_impact > 100:
            recommendations.append("Surveiller l'utilisation m√©moire en production")
        
        if stability > 50:
            recommendations.append("Investiguer la variabilit√© des performances")
        
        if time_improvement > 0 and memory_impact < 50:
            recommendations.append("Le nouveau syst√®me est pr√™t pour la production")
        
        return recommendations

async def main():
    """Fonction principale"""
    print("‚ö° TEST DE PERFORMANCE - GARDE-FOU ANTI-HALLUCINATION")
    print("Mesure de l'impact performance du nouveau syst√®me")
    print("=" * 70)
    
    tester = PerformanceTester()
    
    # Test de performance de base
    print("üöÄ D√âMARRAGE DES TESTS DE PERFORMANCE")
    print("=" * 50)
    
    # Test ancien syst√®me
    old_results = await tester.test_old_system_performance(num_tests=5)
    
    # Test nouveau syst√®me
    new_results = await tester.test_new_system_performance(num_tests=5)
    
    # Comparaison
    comparison = tester.compare_performance(old_results, new_results)
    
    # Test de concurrence
    concurrent_results = await tester.test_concurrent_performance(num_concurrent=3, num_tests=10)
    
    if 'error' not in concurrent_results:
        print(f"\nüîÑ PERFORMANCE CONCURRENTE:")
        print(f"   Temps moyen: {concurrent_results['avg_time']:.2f}ms")
        print(f"   Requ√™tes/seconde: {concurrent_results['requests_per_second']:.2f}")
        print(f"   Limite concurrente: {concurrent_results['concurrent_limit']}")
    
    # R√©sum√© final
    print("\n" + "=" * 70)
    print("üìä R√âSUM√â FINAL")
    
    if 'error' not in old_results and 'error' not in new_results:
        print(f"   Impact temps: {comparison['time_improvement']:+.1f}%")
        print(f"   Impact m√©moire: {comparison['memory_impact']:+.2f}MB")
        print(f"   Am√©lioration stabilit√©: {comparison['stability_improvement']:+.1f}%")
        
        if comparison['recommendations']:
            print(f"\nüí° RECOMMANDATIONS:")
            for rec in comparison['recommendations']:
                print(f"   - {rec}")
    
    print("\nüéâ TESTS DE PERFORMANCE TERMIN√âS !")

if __name__ == "__main__":
    asyncio.run(main())
