#!/usr/bin/env python3
"""
ü§ñ DATA QUALITY AGENT - Enrichissement et correction automatique
Syst√®me autonome pour tester l'enrichissement LLM
"""
import json
import re
from typing import Dict, List, Any, Optional
from datetime import datetime

class DataQualityAgent:
    """Agent LLM pour enrichir, corriger et clarifier les donn√©es"""
    
    def __init__(self, llm_client=None):
        """
        Args:
            llm_client: Client LLM (si None, utilise celui par d√©faut)
        """
        if llm_client is None:
            try:
                from llm_client import get_llm_client
                self.llm = get_llm_client()
            except:
                print("‚ö†Ô∏è LLM client non disponible, mode simulation activ√©")
                self.llm = None
        else:
            self.llm = llm_client
    
    async def enrich_document(self, raw_document: Dict[str, Any]) -> Dict[str, Any]:
        """
        Enrichit un document brut avec correction orthographe + clarification ambigu√Øt√©s
        
        Args:
            raw_document: Document brut avec potentiellement des erreurs
        
        Returns:
            Document enrichi avec m√©tadonn√©es d'enrichissement
        """
        print(f"\n{'='*80}")
        print(f"ü§ñ ENRICHISSEMENT: {raw_document.get('product_name', 'Document')}")
        print(f"{'='*80}\n")
        
        # 1. Analyser le document
        analysis = self._analyze_document(raw_document)
        print(f"üìä Analyse:")
        print(f"   - Fautes d√©tect√©es: {len(analysis['spelling_errors'])}")
        print(f"   - Ambigu√Øt√©s: {len(analysis['ambiguities'])}")
        print(f"   - Score qualit√©: {analysis['quality_score']:.2f}/1.00")
        
        # 2. Appeler LLM pour enrichissement
        enrichment = await self._call_llm_for_enrichment(raw_document, analysis)
        
        # 3. Construire document enrichi
        enriched_doc = self._build_enriched_document(raw_document, enrichment, analysis)
        
        print(f"\n‚úÖ Enrichissement termin√©")
        print(f"   - Corrections: {len(enriched_doc['_metadata']['corrections'])}")
        print(f"   - Clarifications: {len(enriched_doc['_metadata']['clarifications'])}")
        print(f"   - Confiance: {enriched_doc['_metadata']['confidence']:.2f}")
        
        return enriched_doc
    
    def _analyze_document(self, doc: Dict) -> Dict:
        """Analyse pr√©liminaire du document"""
        
        text = doc.get('description', '') + ' ' + doc.get('notes', '')
        
        # D√©tection fautes orthographe (patterns simples)
        spelling_errors = []
        common_errors = {
            'disponnible': 'disponible',
            'taille': 'taille',  # OK
            'couleur': 'couleur',  # OK
            'livrasion': 'livraison',
            'paiemant': 'paiement',
            'garanti': 'garantie'
        }
        
        for wrong, correct in common_errors.items():
            if wrong in text.lower():
                spelling_errors.append({'wrong': wrong, 'correct': correct})
        
        # D√©tection ambigu√Øt√©s
        ambiguities = []
        
        # Ambigu√Øt√© 1: "toutes tailles" sans pr√©cision
        if re.search(r'toute.{0,5}taille', text, re.IGNORECASE):
            if not re.search(r'taille\s+\d+', text):
                ambiguities.append({
                    'type': 'missing_size_details',
                    'description': '"toutes tailles" mentionn√© sans liste explicite'
                })
        
        # Ambigu√Øt√© 2: Prix sans clarification variant
        if 'prix' in text.lower() or 'fcfa' in text.lower():
            if not any(word in text.lower() for word in ['unique', 'identique', 'm√™me']):
                ambiguities.append({
                    'type': 'price_ambiguity',
                    'description': 'Prix mentionn√© sans pr√©ciser si unique ou variable'
                })
        
        # Ambigu√Øt√© 3: Quantit√© minimale vague
        if re.search(r'lot|minimum|mini', text, re.IGNORECASE):
            if not re.search(r'\d+\s*(pi√®ces|unit√©s)', text):
                ambiguities.append({
                    'type': 'quantity_ambiguity',
                    'description': 'Quantit√© minimale non pr√©cis√©e'
                })
        
        # Score qualit√© (0-1)
        quality_score = 1.0
        quality_score -= len(spelling_errors) * 0.1  # -0.1 par faute
        quality_score -= len(ambiguities) * 0.15  # -0.15 par ambigu√Øt√©
        quality_score = max(0, quality_score)
        
        return {
            'spelling_errors': spelling_errors,
            'ambiguities': ambiguities,
            'quality_score': quality_score,
            'needs_enrichment': quality_score < 0.8
        }
    
    async def _call_llm_for_enrichment(self, doc: Dict, analysis: Dict) -> Dict:
        """Appelle le LLM pour enrichir le document"""
        
        if self.llm is None:
            return self._mock_llm_response(doc, analysis)
        
        # Construire le prompt
        prompt = self._build_enrichment_prompt(doc, analysis)
        
        try:
            response = await self.llm.complete(
                prompt=prompt,
                temperature=0.2,  # Bas pour coh√©rence
                max_tokens=1000
            )
            
            # Parser JSON response
            enrichment = json.loads(response)
            return enrichment
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur LLM: {e}")
            return self._mock_llm_response(doc, analysis)
    
    def _build_enrichment_prompt(self, doc: Dict, analysis: Dict) -> str:
        """Construit le prompt d'enrichissement"""
        
        return f"""Tu es un expert en correction et enrichissement de donn√©es e-commerce.

DOCUMENT ORIGINAL:
{json.dumps(doc, indent=2, ensure_ascii=False)}

PROBL√àMES D√âTECT√âS:
- Fautes d'orthographe: {len(analysis['spelling_errors'])}
- Ambigu√Øt√©s: {len(analysis['ambiguities'])}
- Score qualit√©: {analysis['quality_score']:.2f}/1.00

T√ÇCHES:
1. **CORRIGER** toutes les fautes d'orthographe
2. **CLARIFIER** toutes les ambigu√Øt√©s d√©tect√©es:
   {chr(10).join('   - ' + amb['description'] for amb in analysis['ambiguities'])}
3. **ENRICHIR** avec informations manquantes (SANS INVENTER):
   - Si "toutes tailles" ‚Üí Lister tailles STANDARD du secteur + mention "√† confirmer"
   - Si prix vague ‚Üí Pr√©ciser "Prix UNIQUE" ou "Variable selon X"
   - Si quantit√© floue ‚Üí Demander pr√©cision + sugg√©rer standard

R√àGLES STRICTES:
- NE JAMAIS inventer prix, tailles ou donn√©es absentes
- Si info manquante ‚Üí Marquer "√Ä CONFIRMER PAR CLIENT"
- Rester FACTUEL et bas√© sur le document original

FORMAT JSON ATTENDU:
{{
  "corrected_text": "...",
  "enriched_description": "...",
  "searchable_text": "...",
  "corrections_made": [
    {{"type": "spelling", "before": "...", "after": "..."}}
  ],
  "clarifications_added": [
    {{"type": "ambiguity", "field": "...", "clarification": "..."}}
  ],
  "needs_client_confirmation": [
    {{"field": "...", "question": "..."}}
  ],
  "confidence": 0.X
}}

G√âN√àRE LE JSON:"""
    
    def _mock_llm_response(self, doc: Dict, analysis: Dict) -> Dict:
        """Simulation LLM si non disponible"""
        
        description = doc.get('description', '')
        
        # Corrections orthographe
        corrections = []
        for error in analysis['spelling_errors']:
            description = description.replace(error['wrong'], error['correct'])
            corrections.append({
                'type': 'spelling',
                'before': error['wrong'],
                'after': error['correct']
            })
        
        # Clarifications
        clarifications = []
        enriched_desc = description
        
        # Clarifier prix si ambigu√Øt√©
        if any(amb['type'] == 'price_ambiguity' for amb in analysis['ambiguities']):
            enriched_desc += "\n‚ö†Ô∏è Prix UNIQUE pour toutes les variantes (√† confirmer par le client)."
            clarifications.append({
                'type': 'price',
                'field': 'pricing',
                'clarification': 'Ajout√© mention prix unique'
            })
        
        return {
            'corrected_text': description,
            'enriched_description': enriched_desc,
            'searchable_text': enriched_desc.replace('\n', ' '),
            'corrections_made': corrections,
            'clarifications_added': clarifications,
            'needs_client_confirmation': [
                {'field': 'tailles', 'question': 'Quelles tailles exactement ?'}
            ],
            'confidence': 0.75
        }
    
    def _build_enriched_document(self, original: Dict, enrichment: Dict, analysis: Dict) -> Dict:
        """Construit le document final enrichi"""
        
        enriched = original.copy()
        
        # Appliquer corrections
        if 'corrected_text' in enrichment:
            enriched['description'] = enrichment['enriched_description']
        
        if 'searchable_text' in enrichment:
            enriched['searchable_text'] = enrichment['searchable_text']
        
        # M√©tadonn√©es d'enrichissement
        enriched['_metadata'] = {
            'enriched_at': datetime.now().isoformat(),
            'original_quality': analysis['quality_score'],
            'corrections': enrichment.get('corrections_made', []),
            'clarifications': enrichment.get('clarifications_added', []),
            'needs_confirmation': enrichment.get('needs_client_confirmation', []),
            'confidence': enrichment.get('confidence', 0.5),
            'status': 'pending_validation'
        }
        
        return enriched

# Singleton pour utilisation facile
_agent_instance = None

def get_data_quality_agent():
    """R√©cup√®re l'instance singleton de l'agent"""
    global _agent_instance
    if _agent_instance is None:
        _agent_instance = DataQualityAgent()
    return _agent_instance
