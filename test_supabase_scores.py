#!/usr/bin/env python3
"""
ğŸ¯ TEST SCORES SUPABASE - DIAGNOSTIC PRÃ‰CIS
Teste les scores de similaritÃ© rÃ©els pour identifier le problÃ¨me
"""
import asyncio
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from core.supabase_vector_search import SupabaseVectorSearch

async def test_scores_supabase():
    """Test des scores rÃ©els de Supabase"""
    print("ğŸ¯ TEST SCORES SUPABASE")
    print("=" * 50)
    
    # RequÃªte de test (celle qui Ã©choue)
    query = "dite cc couches culottes pression disponible bebe 9kg?"
    company_id = "MpfnlSbqwaZ6F4HvxQLRL9du0yG3"
    
    # Initialisation du moteur
    engine = SupabaseVectorSearch()
    await engine.initialize()
    
    print(f"ğŸ” RequÃªte: {query}")
    print(f"ğŸ¢ Company ID: {company_id}")
    
    try:
        # 1. TEST AVEC SEUIL TRÃˆS BAS
        print("\n1ï¸âƒ£ TEST AVEC SEUIL TRÃˆS BAS (0.1)")
        results_low = await engine.search_vectors(
            query_embedding=await engine.generate_embedding(query),
            company_id=company_id,
            top_k=5,
            min_score=0.1,  # Seuil trÃ¨s bas
            include_metadata=True
        )
        
        print(f"ğŸ“Š RÃ©sultats avec seuil 0.1: {len(results_low)}")
        for i, result in enumerate(results_low, 1):
            print(f"   {i}. Score: {result.score:.4f} | ID: {result.id}")
            print(f"      Contenu: {result.content[:100]}...")
        
        # 2. TEST AVEC SEUIL NORMAL
        print("\n2ï¸âƒ£ TEST AVEC SEUIL NORMAL (0.3)")
        results_normal = await engine.search_vectors(
            query_embedding=await engine.generate_embedding(query),
            company_id=company_id,
            top_k=5,
            min_score=0.3,  # Seuil normal
            include_metadata=True
        )
        
        print(f"ğŸ“Š RÃ©sultats avec seuil 0.3: {len(results_normal)}")
        for i, result in enumerate(results_normal, 1):
            print(f"   {i}. Score: {result.score:.4f} | ID: {result.id}")
            print(f"      Contenu: {result.content[:100]}...")
        
        # 3. TEST AVEC SEUIL Ã‰LEVÃ‰
        print("\n3ï¸âƒ£ TEST AVEC SEUIL Ã‰LEVÃ‰ (0.5)")
        results_high = await engine.search_vectors(
            query_embedding=await engine.generate_embedding(query),
            company_id=company_id,
            top_k=5,
            min_score=0.5,  # Seuil Ã©levÃ©
            include_metadata=True
        )
        
        print(f"ğŸ“Š RÃ©sultats avec seuil 0.5: {len(results_high)}")
        for i, result in enumerate(results_high, 1):
            print(f"   {i}. Score: {result.score:.4f} | ID: {result.id}")
            print(f"      Contenu: {result.content[:100]}...")
        
        # 4. ANALYSE DES SCORES
        print("\n4ï¸âƒ£ ANALYSE DES SCORES")
        if results_low:
            best_score = max(result.score for result in results_low)
            worst_score = min(result.score for result in results_low)
            avg_score = sum(result.score for result in results_low) / len(results_low)
            
            print(f"ğŸ“ˆ Meilleur score: {best_score:.4f}")
            print(f"ğŸ“‰ Pire score: {worst_score:.4f}")
            print(f"ğŸ“Š Score moyen: {avg_score:.4f}")
            
            # Recommandation de seuil
            if best_score < 0.3:
                print(f"âš ï¸  PROBLÃˆME: Meilleur score ({best_score:.4f}) < seuil normal (0.3)")
                print(f"ğŸ’¡ SOLUTION: RÃ©duire min_score Ã  {best_score * 0.8:.2f}")
            else:
                print(f"âœ… Scores normaux, problÃ¨me ailleurs")
        
        # 5. TEST RECHERCHE COMPLÃˆTE
        print("\n5ï¸âƒ£ TEST RECHERCHE COMPLÃˆTE")
        results_complete, context = await engine.semantic_search(
            query=query,
            company_id=company_id,
            top_k=5,
            min_score=0.1,  # Seuil trÃ¨s permissif
            enable_reranking=True
        )
        
        print(f"ğŸ“Š Recherche complÃ¨te: {len(results_complete)} rÃ©sultats")
        print(f"ğŸ“„ Contexte gÃ©nÃ©rÃ©: {len(context)} caractÃ¨res")
        
        if context:
            print(f"ğŸ“ AperÃ§u contexte: {context[:200]}...")
        else:
            print("âŒ Aucun contexte gÃ©nÃ©rÃ©")
            
    except Exception as e:
        print(f"âŒ Erreur: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        await engine.cleanup()
    
    print("\n" + "=" * 50)
    print("ğŸ¯ TEST TERMINÃ‰")

if __name__ == "__main__":
    asyncio.run(test_scores_supabase())
