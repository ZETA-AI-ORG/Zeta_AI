# ğŸš€ PLAN D'AMÃ‰LIORATION RAG - VERSION FINALE

**Date:** 2025-10-14  
**Score actuel:** 62% (Test Hardcore) | 100% (Test Moyen)  
**Objectif:** 90%+ sur test Hardcore

---

## ğŸ“Š DIAGNOSTIC COMPLET

### **Performances actuelles:**
- â±ï¸ Temps moyen: **24.8s** (trop lent)
- ğŸ¯ Taux rÃ©ussite: **77%** (5 timeouts/22)
- ğŸ’° CoÃ»t: **$0.0028/requÃªte** (excellent)
- ğŸ§  PrÃ©cision: **85%** (3 erreurs donnÃ©es)

### **Goulots d'Ã©tranglement identifiÃ©s:**
1. **search_sources: 11.9s (48% du temps)** ğŸ”´
2. **endpoint_init: 6.7s (27% du temps)** ğŸ”´
3. **llm_generation: 3.9s (16% du temps)** ğŸŸ¡
4. **Supabase 8.5x plus lent que MeiliSearch** ğŸ”´

---

## ğŸ¯ PHASE 1: CORRECTIONS DONNÃ‰ES (URGENT - 30min)

### âœ… **1.1 Base de donnÃ©es MeiliSearch**

**Corrections Ã  faire:**

| Fichier | Erreur | Correction |
|---------|--------|------------|
| `couches-a-pression-taille-4...` | Prix incohÃ©rent | âœ… TOI: Uniformiser 24 000 ou 24 900 |
| `couches-a-pression-taille-6...` | Description "taille 5" | âœ… FAIT: ChangÃ© en "taille 6" |

**VÃ©rifications:**
- âœ… Lots 150 pression n'existent PAS (base correcte)
- âœ… Zones livraison correctes dans base
- âœ… Culottes: 150 et 300 disponibles

---

## ğŸ”´ PHASE 2: OPTIMISATION PERFORMANCES (URGENT - 2h)

### **2.1 RÃ©duire temps recherche (gain: -8s)**

**ProblÃ¨me:** Supabase fallback prend 15.4s vs MeiliSearch 1.8s

**Actions:**
```python
# core/universal_rag_engine.py

# RÃ©duire timeout Supabase
SUPABASE_TIMEOUT = 5  # Au lieu de 20s

# Forcer MeiliSearch plus agressivement
MEILISEARCH_MIN_DOCS = 2  # Au lieu de 3

# DÃ©sactiver Supabase si MeiliSearch trouve des docs
if meilisearch_docs >= 2:
    skip_supabase = True
```

**Gain attendu:** 15.4s â†’ 7s (-8s)

---

### **2.2 Optimiser endpoint_init (gain: -3s)**

**ProblÃ¨me:** HYDE + cache + prompt = 6.7s

**Actions:**
```python
# app.py

# 1. ParallÃ©liser HYDE et cache check
import asyncio
hyde_task = asyncio.create_task(clarify_request_with_hyde(req.message))
cache_task = asyncio.create_task(redis_cache.get(...))
hyde_result, cache_result = await asyncio.gather(hyde_task, cache_task)

# 2. DÃ©sactiver HYDE pour requÃªtes courtes (<10 mots)
if len(req.message.split()) < 10:
    skip_hyde = True

# 3. Cache prompt en mÃ©moire (dÃ©jÃ  fait mais vÃ©rifier)
```

**Gain attendu:** 6.7s â†’ 3.5s (-3s)

---

### **2.3 Prompt LLM - Garder 1500-2000 tokens**

**DÃ©cision:** NE PAS rÃ©duire Ã  512 tokens (trop agressif)

**Actions:**
```python
# Garder max_tokens actuel
max_tokens = 1024  # OK

# Mais optimiser structure prompt:
# - Supprimer rÃ©pÃ©titions
# - Contexte plus concis
# - RÃ¨gles en bullet points
```

**Gain attendu:** Maintien qualitÃ© + stabilitÃ© temps

---

## ğŸŸ¡ PHASE 3: AMÃ‰LIORATION MÃ‰MOIRE (IMPORTANT - 4h)

### **3.1 Notepad plus persistant**

**ProblÃ¨me:** Perd "2 lots" au rÃ©capitulatif final

**Recherche web nÃ©cessaire:**
- GitHub: "conversational memory LLM"
- Reddit: r/LocalLLaMA "context persistence"
- Papers: "long-term memory chatbots"

**Pistes:**
1. **Vector store pour notepad** (Pinecone/Qdrant)
2. **Compression mÃ©moire** (summarization)
3. **Extraction structurÃ©e** (JSON forcÃ©)

**Actions:**
```python
# core/conversation_notepad.py

# Option 1: Forcer extraction JSON
def extract_order_details(text):
    prompt = """
    Extrais UNIQUEMENT les infos commande en JSON:
    {
      "quantity": 2,
      "product": "Lot 300 taille 4",
      "zone": "Yopougon"
    }
    """
    # LLM call avec JSON mode

# Option 2: Sauvegarder dans Redis
def persist_to_redis(user_id, data):
    redis.setex(f"order:{user_id}", 3600, json.dumps(data))
```

**Gain attendu:** MÃ©moire 70% â†’ 95%

---

### **3.2 VÃ©rification stricte zones livraison**

**Solution:** âœ… FAIT - Injection rÃ¨gles dans prompt

```python
# core/universal_rag_engine.py (ligne 635)

delivery_rules = """
âš ï¸ RÃˆGLES STRICTES ZONES LIVRAISON:
- Yopougon: 1 500 FCFA (PAS 2 000!)
- Cocody: 1 500 FCFA
- Port-BouÃ«t: 2 000 FCFA
NE CONFONDS PAS!
"""
system_prompt += delivery_rules
```

**Gain attendu:** Erreurs zones 100% â†’ 0%

---

## ğŸŸ¢ PHASE 4: CACHE SÃ‰MANTIQUE (BONUS - 6h)

### **4.1 Pourquoi cache actuel ne marche pas**

**ProblÃ¨me:** Cache exact match uniquement
- "Bonjour prix taille 4" â‰  "Prix taille 4" âŒ
- PremiÃ¨re fois = pas de cache âœ… Normal

**Solution: Cache sÃ©mantique**

```python
# core/semantic_cache.py (NOUVEAU)

import numpy as np
from sentence_transformers import SentenceTransformer

class SemanticCache:
    def __init__(self):
        self.model = SentenceTransformer('all-MiniLM-L6-v2')
        self.cache = {}  # {embedding: response}
        self.threshold = 0.85  # SimilaritÃ© min
    
    def get(self, query):
        query_emb = self.model.encode(query)
        for cached_emb, response in self.cache.items():
            similarity = cosine_similarity(query_emb, cached_emb)
            if similarity > self.threshold:
                return response
        return None
    
    def set(self, query, response):
        query_emb = self.model.encode(query)
        self.cache[query_emb] = response
```

**Gain attendu:** Cache hit 5% â†’ 40%

---

## ğŸ¯ PHASE 5: SYSTÃˆME IMAGE INTELLIGENT (IMPLÃ‰MENTÃ‰ âœ…)

**Solution:** Botlive = Extracteur silencieux, RAG = Conversationnel

### **Architecture:**
```
Image reÃ§ue â†’ Botlive analyse â†’ Retourne JSON structurÃ© â†’ RAG formule rÃ©ponse
```

### **Fichiers crÃ©Ã©s:**
1. âœ… `core/image_analyzer.py` - Module analyse images
2. âœ… `core/botlive_integration.py` - Interface Botlive
3. âœ… IntÃ©gration dans `universal_rag_engine.py`

### **FonctionnalitÃ©s:**
- âœ… DÃ©tection automatique type image (produit/paiement)
- âœ… Cache Redis 24h (Ã©vite re-analyse)
- âœ… Extraction donnÃ©es structurÃ©es
- âœ… Validation paiement (â‰¥2000 FCFA)
- âœ… Description produit dÃ©taillÃ©e

### **Flux:**
1. Client envoie image
2. `image_analyzer` appelle Botlive
3. Botlive retourne DATA brute (pas de texte)
4. RAG injecte DATA dans prompt
5. LLM formule rÃ©ponse naturelle

**Gain:** Paiement vÃ©rifiÃ© automatiquement + Descriptions produits prÃ©cises

---

## ğŸ“ˆ GAINS ATTENDUS TOTAUX

| MÃ©trique | Avant | AprÃ¨s | Gain |
|----------|-------|-------|------|
| **Temps moyen** | 24.8s | **13s** | -47% ğŸš€ |
| **Taux rÃ©ussite** | 77% | **95%** | +18% âœ… |
| **PrÃ©cision donnÃ©es** | 85% | **100%** | +15% âœ… |
| **MÃ©moire** | 70% | **95%** | +25% ğŸ§  |
| **Score global** | 62% | **92%** | +30% ğŸ† |

---

## ğŸš€ ORDRE D'EXÃ‰CUTION

### **AUJOURD'HUI (2h):**
1. âœ… Corriger Taille 4 prix MeiliSearch
2. âœ… Injection rÃ¨gles zones (FAIT)
3. âœ… Optimiser endpoint_init (parallÃ©liser)
4. âœ… RÃ©duire timeout Supabase Ã  5s

### **DEMAIN (4h):**
5. ğŸ” Recherche web mÃ©moire persistante
6. ğŸ§  ImplÃ©menter notepad amÃ©liorÃ©
7. ğŸ§ª Tester avec client hardcore

### **CETTE SEMAINE (6h):**
8. ğŸ’¾ Cache sÃ©mantique (si temps)
9. ğŸ’° SystÃ¨me acompte (ton idÃ©e)
10. ğŸ“Š Monitoring performances

---

## ğŸ¯ CRITÃˆRES DE SUCCÃˆS

**Test Hardcore doit atteindre:**
- âœ… 0 timeout (actuellement 5)
- âœ… 95%+ rÃ©ussite (actuellement 77%)
- âœ… Temps < 15s moyen (actuellement 24.8s)
- âœ… MÃ©moire parfaite (actuellement 70%)
- âœ… 0 erreur donnÃ©es (actuellement 3)

**Score cible: 90%+** ğŸ†

---

## ğŸ“ NOTES IMPORTANTES

1. **MeiliSearch dÃ©jÃ  prioritaire** âœ…
2. **Pas de rÃ©duction tokens Ã  512** âœ…
3. **Cache non sÃ©mantique = normal** âœ…
4. **DonnÃ©es base = cause principale erreurs** âœ…
5. **Supabase = goulot principal** ğŸ”´

---

**PROCHAINE Ã‰TAPE:** Synchroniser fichiers et tester!

```bash
# Copier les modifs
cp -v "/mnt/c/Users/hp/Documents/ZETA APP/chatbot/CHATBOT2.0/core/universal_rag_engine.py" ~/ZETA_APP/CHATBOT2.0/core/universal_rag_engine.py

cp -v "/mnt/c/Users/hp/Documents/ZETA APP/chatbot/CHATBOT2.0/app.py" ~/ZETA_APP/CHATBOT2.0/app.py

# RedÃ©marrer
cd ~/ZETA_APP/CHATBOT2.0
python3 -m uvicorn app:app --host 0.0.0.0 --port 8002 --reload

# Relancer test
python3 test_client_hardcore.py
```

**FIN DU PLAN** ğŸ¯
