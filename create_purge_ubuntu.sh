#!/bin/bash
# üßπ CR√âATION ET EX√âCUTION DU SCRIPT DE PURGE MEILISEARCH SUR UBUNTU

echo "üöÄ CR√âATION DU SCRIPT DE PURGE MEILISEARCH"
echo "=========================================="

# Cr√©er le script Python directement sur Ubuntu
cat > ~/CHATBOT2.0/purge_meili_complete.py << 'EOF'
#!/usr/bin/env python3
"""
üßπ PURGE COMPL√àTE MEILISEARCH
Supprime tous les index et documents pour repartir sur une base vierge
"""

import asyncio
import meilisearch
from datetime import datetime
import json

# Configuration MeiliSearch
MEILI_URL = "http://localhost:7700"
MEILI_KEY = "N80w8LbzObzK18rZk7zwiHNpJLA_YFSvYGt2XzGLP_4"

def log_purge(message, data=None):
    """Log format√© pour la purge"""
    timestamp = datetime.now().strftime("%H:%M:%S")
    print(f"[PURGE_MEILI][{timestamp}] {message}")
    if data:
        print(f"  üìä {json.dumps(data, indent=2, ensure_ascii=False)}")

class MeiliPurgeManager:
    """
    Gestionnaire de purge compl√®te MeiliSearch
    """
    
    def __init__(self):
        self.client = meilisearch.Client(MEILI_URL, MEILI_KEY)
        
    async def get_all_indexes(self):
        """
        R√©cup√®re tous les index existants
        """
        try:
            indexes = self.client.get_indexes()
            index_list = []
            
            for index_info in indexes['results']:
                index_list.append({
                    'uid': index_info['uid'],
                    'primaryKey': index_info.get('primaryKey'),
                    'createdAt': index_info.get('createdAt'),
                    'updatedAt': index_info.get('updatedAt')
                })
            
            log_purge("üìã INDEX TROUV√âS", {
                "total_indexes": len(index_list),
                "index_names": [idx['uid'] for idx in index_list]
            })
            
            return index_list
            
        except Exception as e:
            log_purge(f"‚ùå ERREUR R√âCUP√âRATION INDEX: {e}")
            return []

    async def get_index_stats(self, index_uid):
        """
        R√©cup√®re les statistiques d'un index
        """
        try:
            index = self.client.index(index_uid)
            stats = index.get_stats()
            
            return {
                'uid': index_uid,
                'numberOfDocuments': stats.get('numberOfDocuments', 0),
                'isIndexing': stats.get('isIndexing', False),
                'fieldDistribution': stats.get('fieldDistribution', {})
            }
            
        except Exception as e:
            log_purge(f"‚ö†Ô∏è ERREUR STATS INDEX {index_uid}: {e}")
            return {'uid': index_uid, 'error': str(e)}

    async def delete_all_documents_from_index(self, index_uid):
        """
        Supprime tous les documents d'un index
        """
        try:
            index = self.client.index(index_uid)
            
            # R√©cup√©rer le nombre de documents avant suppression
            stats = await self.get_index_stats(index_uid)
            doc_count = stats.get('numberOfDocuments', 0)
            
            if doc_count > 0:
                log_purge(f"üóëÔ∏è SUPPRESSION DOCUMENTS INDEX: {index_uid}", {
                    "documents_count": doc_count
                })
                
                # Supprimer tous les documents
                task = index.delete_all_documents()
                
                # Attendre la fin de la t√¢che
                self.client.wait_for_task(task['taskUid'])
                
                log_purge(f"‚úÖ DOCUMENTS SUPPRIM√âS: {index_uid}")
                return True
            else:
                log_purge(f"‚ÑπÔ∏è INDEX D√âJ√Ä VIDE: {index_uid}")
                return True
                
        except Exception as e:
            log_purge(f"‚ùå ERREUR SUPPRESSION DOCUMENTS {index_uid}: {e}")
            return False

    async def delete_index(self, index_uid):
        """
        Supprime compl√®tement un index
        """
        try:
            log_purge(f"üóëÔ∏è SUPPRESSION INDEX: {index_uid}")
            
            task = self.client.delete_index(index_uid)
            
            # Attendre la fin de la t√¢che
            self.client.wait_for_task(task['taskUid'])
            
            log_purge(f"‚úÖ INDEX SUPPRIM√â: {index_uid}")
            return True
            
        except Exception as e:
            log_purge(f"‚ùå ERREUR SUPPRESSION INDEX {index_uid}: {e}")
            return False

    async def purge_all_data(self, delete_indexes=True):
        """
        Purge compl√®te de toutes les donn√©es
        """
        log_purge("üöÄ D√âMARRAGE PURGE COMPL√àTE MEILISEARCH")
        
        # √âtape 1: R√©cup√©rer tous les index
        indexes = await self.get_all_indexes()
        
        if not indexes:
            log_purge("‚ÑπÔ∏è AUCUN INDEX TROUV√â - MEILISEARCH D√âJ√Ä VIERGE")
            return True
        
        # √âtape 2: Afficher les statistiques avant purge
        print(f"\nüìä STATISTIQUES AVANT PURGE:")
        total_documents = 0
        
        for index_info in indexes:
            stats = await self.get_index_stats(index_info['uid'])
            doc_count = stats.get('numberOfDocuments', 0)
            total_documents += doc_count
            
            print(f"  üìÅ {index_info['uid']}: {doc_count} documents")
        
        log_purge("üìà R√âSUM√â AVANT PURGE", {
            "total_indexes": len(indexes),
            "total_documents": total_documents
        })
        
        # √âtape 3: Supprimer selon la strat√©gie choisie
        success_count = 0
        
        if delete_indexes:
            # Suppression compl√®te des index
            log_purge("üóëÔ∏è SUPPRESSION COMPL√àTE DES INDEX")
            
            for index_info in indexes:
                success = await self.delete_index(index_info['uid'])
                if success:
                    success_count += 1
        else:
            # Suppression des documents seulement
            log_purge("üóëÔ∏è SUPPRESSION DES DOCUMENTS UNIQUEMENT")
            
            for index_info in indexes:
                success = await self.delete_all_documents_from_index(index_info['uid'])
                if success:
                    success_count += 1
        
        # √âtape 4: V√©rification finale
        final_indexes = await self.get_all_indexes()
        
        log_purge("üéâ PURGE TERMIN√âE", {
            "indexes_trait√©s": len(indexes),
            "succ√®s": success_count,
            "√©checs": len(indexes) - success_count,
            "indexes_restants": len(final_indexes) if delete_indexes else len(indexes)
        })
        
        return success_count == len(indexes)

    async def verify_clean_state(self):
        """
        V√©rifie que MeiliSearch est dans un √©tat vierge
        """
        log_purge("üîç V√âRIFICATION √âTAT VIERGE")
        
        indexes = await self.get_all_indexes()
        
        if not indexes:
            log_purge("‚úÖ MEILISEARCH COMPL√àTEMENT VIERGE")
            return True
        
        total_docs = 0
        for index_info in indexes:
            stats = await self.get_index_stats(index_info['uid'])
            doc_count = stats.get('numberOfDocuments', 0)
            total_docs += doc_count
        
        if total_docs == 0:
            log_purge("‚úÖ MEILISEARCH VIERGE (INDEX VIDES)", {
                "indexes_vides": len(indexes)
            })
            return True
        else:
            log_purge("‚ö†Ô∏è MEILISEARCH NON VIERGE", {
                "indexes_avec_donn√©es": len(indexes),
                "total_documents": total_docs
            })
            return False

async def main():
    """
    Fonction principale de purge
    """
    print("üßπ PURGE COMPL√àTE MEILISEARCH")
    print("=" * 60)
    
    manager = MeiliPurgeManager()
    
    try:
        # Test de connexion
        log_purge("üîå TEST CONNEXION MEILISEARCH")
        health = manager.client.health()
        log_purge("‚úÖ CONNEXION OK", health)
        
        # Purge compl√®te (suppression des index)
        success = await manager.purge_all_data(delete_indexes=True)
        
        if success:
            # V√©rification finale
            await manager.verify_clean_state()
            
            print(f"\nüéâ PURGE COMPL√àTE R√âUSSIE!")
            print(f"‚úÖ MeiliSearch est maintenant vierge")
            print(f"üöÄ Pr√™t pour nouvelle ingestion via N8N")
        else:
            print(f"\n‚ö†Ô∏è PURGE PARTIELLE - V√©rifier les erreurs ci-dessus")
            
    except Exception as e:
        print(f"\nüí• ERREUR CRITIQUE DURANT LA PURGE: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(main())

cp -v "/mnt/c/Users/hp/Documents/ZETA APP/chatbot/CHATBOT2.0/core/hyde_word_scorer.py" ~/ZETA_APP/CHATBOT2.0/core/hyde_word_scorer.py
cp -v "/mnt/c/Users/hp/Documents/ZETA APP/chatbot/CHATBOT2.0/core/ingestion_hyde_analyzer.py" ~/ZETA_APP/CHATBOT2.0/core/ingestion_hyde_analyzer.py
cp -v "/mnt/c/Users/hp/Documents/ZETA APP/chatbot/CHATBOT2.0/show_hyde_scores.py" ~/ZETA_APP/CHATBOT2.0/show_hyde_scores.py
cp -v "/mnt/c/Users/hp/Documents/ZETA APP/chatbot/CHATBOT2.0/rapport_performance_hyde.py" ~/ZETA_APP/CHATBOT2.0/rapport_performance_hyde.py

echo "üéâ PURGE TERMIN√âE!"
