#!/usr/bin/env python3
"""
ğŸ¯ TEST ULTIME RUE_DU_GROS - COUCHES BÃ‰BÃ‰
Test complet basÃ© sur les donnÃ©es rÃ©elles de l'entreprise Rue_du_gros
Secteur: BÃ©bÃ© & PuÃ©riculture - SpÃ©cialisÃ© couches
"""

import asyncio
import aiohttp
import json
import time
from datetime import datetime
from typing import List, Dict, Any

# Configuration
ENDPOINT_URL = "http://127.0.0.1:8001/chat"
COMPANY_ID = "MpfnlSbqwaZ6F4HvxQLRL9du0yG3"  # RUE_DU_GROS

def log_test(message, data=None):
    """Log formatÃ© pour les tests"""
    timestamp = datetime.now().strftime("%H:%M:%S")
    print(f"[TEST_RUE_DU_GROS][{timestamp}] {message}")
    if data:
        print(f"  ğŸ“Š {json.dumps(data, indent=2, ensure_ascii=False)}")

class RueDuGrosUltimateTest:
    """
    Testeur ultime pour RUE_DU_GROS - Couches bÃ©bÃ©
    """
    
    def __init__(self):
        self.test_results = []
        self.conversation_context = {}
        
    async def test_single_query(self, session, query, test_name, expected_elements=None, conversation_id=None):
        """
        Teste une requÃªte unique sur l'endpoint
        """
        print(f"\n{'='*70}")
        print(f"ğŸ“ TEST: {test_name}")
        print(f"ğŸ” RequÃªte: '{query}'")
        
        if expected_elements:
            print(f"ğŸ¯ Ã‰lÃ©ments attendus: {expected_elements}")
        
        payload = {
            "message": query,
            "company_id": COMPANY_ID,
            "user_id": "testuser123"
        }
        
        try:
            start_time = time.time()
            
            async with session.post(ENDPOINT_URL, json=payload) as response:
                end_time = time.time()
                duration = (end_time - start_time) * 1000
                
                if response.status == 200:
                    result = await response.json()
                    
                    # Analyser la rÃ©ponse
                    response_text = result.get('response', '')
                    debug_info = result.get('debug_info', {})
                    
                    # VÃ©rifier les Ã©lÃ©ments attendus
                    elements_found = []
                    if expected_elements:
                        for element in expected_elements:
                            if element.lower() in response_text.lower():
                                elements_found.append(element)
                    
                    # Analyser les performances
                    performance_score = self._calculate_performance_score(
                        duration, len(response_text), elements_found, expected_elements
                    )
                    
                    test_result = {
                        "test_name": test_name,
                        "query": query,
                        "status": "SUCCESS",
                        "duration_ms": round(duration, 1),
                        "response_length": len(response_text),
                        "elements_found": elements_found,
                        "elements_expected": expected_elements or [],
                        "performance_score": performance_score,
                        "response_preview": response_text[:300] + "..." if len(response_text) > 300 else response_text
                    }
                    
                    print(f"âœ… SUCCÃˆS ({duration:.1f}ms)")
                    print(f"ğŸ“„ RÃ©ponse: {len(response_text)} caractÃ¨res")
                    print(f"ğŸ¯ Ã‰lÃ©ments trouvÃ©s: {elements_found}")
                    print(f"â­ Score performance: {performance_score}/100")
                    print(f"ğŸ’¬ AperÃ§u: {response_text[:200]}...")
                    
                    # Afficher les infos de debug si disponibles
                    if debug_info:
                        rag_info = debug_info.get('rag_results', {})
                        if rag_info:
                            print(f"ğŸ” RAG - Documents trouvÃ©s: {rag_info.get('total_results', 'N/A')}")
                            print(f"ğŸ” RAG - Mode: {rag_info.get('mode', 'N/A')}")
                    
                    self.test_results.append(test_result)
                    return test_result
                    
                else:
                    error_text = await response.text()
                    print(f"âŒ ERREUR HTTP {response.status}")
                    print(f"ğŸ’¥ DÃ©tails: {error_text[:200]}")
                    
                    test_result = {
                        "test_name": test_name,
                        "query": query,
                        "status": "ERROR",
                        "error": f"HTTP {response.status}: {error_text[:100]}"
                    }
                    
                    self.test_results.append(test_result)
                    return test_result
                    
        except Exception as e:
            print(f"ğŸ’¥ EXCEPTION: {str(e)}")
            
            test_result = {
                "test_name": test_name,
                "query": query,
                "status": "EXCEPTION",
                "error": str(e)
            }
            
            self.test_results.append(test_result)
            return test_result

    def _calculate_performance_score(self, duration_ms, response_length, elements_found, expected_elements):
        """
        Calcule un score de performance sur 100
        """
        score = 100
        
        # PÃ©nalitÃ© durÃ©e (optimal < 3s, acceptable < 8s, lent > 15s)
        if duration_ms > 15000:
            score -= 40
        elif duration_ms > 8000:
            score -= 20
        elif duration_ms > 3000:
            score -= 10
        
        # PÃ©nalitÃ© longueur rÃ©ponse (trop courte < 80, trop longue > 1500)
        if response_length < 80:
            score -= 25
        elif response_length > 1500:
            score -= 15
        
        # Bonus Ã©lÃ©ments trouvÃ©s
        if expected_elements:
            found_ratio = len(elements_found) / len(expected_elements)
            score += int(found_ratio * 25)  # Bonus jusqu'Ã  25 points
        
        return max(0, min(100, score))

    async def run_ultimate_test_suite(self):
        """
        Lance la suite complÃ¨te de tests RUE_DU_GROS
        """
        print("ğŸš€ DÃ‰MARRAGE TESTS ULTIME RUE_DU_GROS")
        print(f"ğŸ¯ URL: {ENDPOINT_URL}")
        print(f"ğŸ¢ Company ID: {COMPANY_ID}")
        print(f"ğŸ¼ Secteur: BÃ©bÃ© & PuÃ©riculture - Couches")
        
        # Tests spÃ©cifiques RUE_DU_GROS
        test_cases = [
            # === TESTS PRODUITS COUCHES ===
            {
                "name": "Prix Couches Taille 1 (nouveau-nÃ©)",
                "query": "combien coÃ»tent les couches pour nouveau-nÃ© taille 1",
                "expected": ["taille 1", "17.900", "17900", "0 Ã  4 kg", "300 couches", "fcfa"]
            },
            {
                "name": "Prix Couches Taille 4 (populaire)",
                "query": "prix couches taille 4 pour enfant 10 kg",
                "expected": ["taille 4", "25.900", "25900", "9 Ã  14 kg", "300 couches", "fcfa"]
            },
            {
                "name": "Couches Culottes - Tarif dÃ©gressif",
                "query": "couches culottes prix pour 6 paquets",
                "expected": ["culottes", "6 paquets", "25.000", "25000", "4.150", "fcfa"]
            },
            {
                "name": "Couches Adultes - Gros volume",
                "query": "couches adultes 1 colis combien Ã§a coÃ»te",
                "expected": ["adultes", "1 colis", "240 unitÃ©s", "216.000", "216000", "900", "fcfa"]
            },
            {
                "name": "Comparaison Tailles Couches",
                "query": "diffÃ©rence prix entre taille 3 et taille 6",
                "expected": ["taille 3", "taille 6", "22.900", "27.900", "diffÃ©rence", "5000"]
            },
            
            # === TESTS LIVRAISON SPÃ‰CIFIQUES ===
            {
                "name": "Livraison Yopougon (zone spÃ©ciale)",
                "query": "livraison Ã  Yopougon combien Ã§a coÃ»te",
                "expected": ["yopougon", "1000", "1.000", "fcfa", "livraison"]
            },
            {
                "name": "Livraison Cocody (centre Abidjan)",
                "query": "vous livrez Ã  Cocody quel tarif",
                "expected": ["cocody", "1500", "1.500", "fcfa", "centre", "abidjan"]
            },
            {
                "name": "Livraison Hors Abidjan",
                "query": "livraison possible Ã  BouakÃ© combien Ã§a coÃ»te",
                "expected": ["hors abidjan", "3500", "5000", "tÃ©lÃ©phone", "48h", "72h"]
            },
            {
                "name": "DÃ©lais Livraison Urgente",
                "query": "commande avant 11h livraison jour mÃªme possible",
                "expected": ["11h", "jour mÃªme", "avant", "livraison", "dÃ©lai"]
            },
            
            # === TESTS PAIEMENT & COMMANDE ===
            {
                "name": "Paiement Wave Money",
                "query": "je peux payer avec wave money",
                "expected": ["wave", "paiement", "+2250787360757", "acceptÃ©"]
            },
            {
                "name": "Acompte Obligatoire",
                "query": "faut-il payer un acompte pour commander",
                "expected": ["acompte", "2000", "2.000", "fcfa", "obligatoire", "avant"]
            },
            {
                "name": "Processus Commande Gamma",
                "query": "comment passer commande avec gamma",
                "expected": ["gamma", "assistant", "commande", "automatique", "traitement"]
            },
            
            # === TESTS SUPPORT & CONTACT ===
            {
                "name": "Contact WhatsApp",
                "query": "numÃ©ro whatsapp pour commander",
                "expected": ["whatsapp", "+2250160924560", "contact", "commander"]
            },
            {
                "name": "Contact TÃ©lÃ©phone Direct",
                "query": "numÃ©ro tÃ©lÃ©phone pour appeler directement",
                "expected": ["tÃ©lÃ©phone", "appel direct", "+2250787360757", "contact"]
            },
            {
                "name": "Horaires Support",
                "query": "Ã  quelle heure je peux vous contacter",
                "expected": ["horaires", "toujours ouvert", "24h", "contact"]
            },
            
            # === TESTS POLITIQUE RETOUR ===
            {
                "name": "Politique de Retour",
                "query": "puis-je retourner les couches si problÃ¨me",
                "expected": ["retour", "24h", "politique", "dÃ©finitives", "confirmÃ©e"]
            },
            
            # === TESTS CONVERSATIONNELS COMPLEXES ===
            {
                "name": "Conseil Taille BÃ©bÃ© 8kg",
                "query": "mon bÃ©bÃ© fait 8 kg quelle taille de couches choisir",
                "expected": ["8 kg", "taille 2", "taille 3", "3 Ã  8 kg", "6 Ã  11 kg", "conseil"]
            },
            {
                "name": "Commande ComplÃ¨te avec Livraison",
                "query": "je veux 2 paquets couches culottes livraison Ã  Marcory total combien",
                "expected": ["2 paquets", "culottes", "9.800", "marcory", "1500", "total", "11.300"]
            },
            {
                "name": "Comparaison Ã‰conomique Gros Volume",
                "query": "plus Ã©conomique acheter 12 paquets ou 1 colis couches culottes",
                "expected": ["12 paquets", "1 colis", "48.000", "168.000", "Ã©conomique", "4.000", "3.500"]
            },
            {
                "name": "Question Secteur PuÃ©riculture",
                "query": "vous vendez quoi d'autre que les couches pour bÃ©bÃ©",
                "expected": ["bÃ©bÃ©", "puÃ©riculture", "spÃ©cialisÃ©e", "couches", "gros", "dÃ©tail"]
            },
            
            # === TEST IDENTITÃ‰ ENTREPRISE ===
            {
                "name": "PrÃ©sentation Entreprise",
                "query": "prÃ©sentez-vous qui Ãªtes-vous",
                "expected": ["rue_du_gros", "gamma", "cÃ´te d'ivoire", "couches", "bÃ©bÃ©", "puÃ©riculture"]
            },
            {
                "name": "Mission Entreprise",
                "query": "quelle est votre mission",
                "expected": ["mission", "faciliter", "accÃ¨s", "couches", "fiables", "confortables", "livraison"]
            }
        ]
        
        async with aiohttp.ClientSession() as session:
            success_count = 0
            total_duration = 0
            conversation_id = f"ultimate_test_{int(time.time())}"
            
            for i, test_case in enumerate(test_cases, 1):
                result = await self.test_single_query(
                    session,
                    test_case["query"],
                    f"{i:02d}. {test_case['name']}",
                    test_case["expected"],
                    conversation_id
                )
                
                if result["status"] == "SUCCESS":
                    success_count += 1
                    total_duration += result["duration_ms"]
                
                # Pause entre les tests pour Ã©viter la surcharge
                await asyncio.sleep(1.5)
            
            # Statistiques finales
            self._display_final_statistics(success_count, len(test_cases), total_duration)

    def _display_final_statistics(self, success_count, total_tests, total_duration):
        """
        Affiche les statistiques finales
        """
        print(f"\n{'='*70}")
        print("ğŸ‰ RÃ‰SULTATS FINAUX - RUE_DU_GROS ULTIMATE TEST")
        print(f"{'='*70}")
        
        success_rate = (success_count / total_tests) * 100
        avg_duration = total_duration / success_count if success_count > 0 else 0
        
        print(f"âœ… Tests rÃ©ussis: {success_count}/{total_tests} ({success_rate:.1f}%)")
        print(f"â±ï¸ DurÃ©e moyenne: {avg_duration:.1f}ms")
        print(f"ğŸ“Š DurÃ©e totale: {total_duration:.1f}ms")
        
        # Analyse par performance
        successful_tests = [t for t in self.test_results if t["status"] == "SUCCESS"]
        if successful_tests:
            avg_score = sum(t["performance_score"] for t in successful_tests) / len(successful_tests)
            best_test = max(successful_tests, key=lambda x: x["performance_score"])
            worst_test = min(successful_tests, key=lambda x: x["performance_score"])
            
            print(f"â­ Score moyen: {avg_score:.1f}/100")
            print(f"ğŸ† Meilleur test: {best_test['test_name']} ({best_test['performance_score']}/100)")
            print(f"âš ï¸ Test Ã  amÃ©liorer: {worst_test['test_name']} ({worst_test['performance_score']}/100)")
        
        # Analyse par catÃ©gorie
        self._analyze_by_category()
        
        # Recommandations finales
        if success_rate >= 95:
            print("\nğŸ¯ EXCELLENT! SystÃ¨me RUE_DU_GROS prÃªt pour la production")
            print("ğŸ¼ Toutes les fonctionnalitÃ©s couches bÃ©bÃ© opÃ©rationnelles")
        elif success_rate >= 85:
            print("\nğŸ‘ TRÃˆS BON! Quelques optimisations mineures recommandÃ©es")
        elif success_rate >= 70:
            print("\nâš ï¸ BON mais amÃ©liorations nÃ©cessaires")
        else:
            print("\nğŸš¨ ATTENTION! Corrections majeures requises")
        
        # DÃ©tail des Ã©checs
        failed_tests = [t for t in self.test_results if t["status"] != "SUCCESS"]
        if failed_tests:
            print(f"\nâŒ TESTS Ã‰CHOUÃ‰S ({len(failed_tests)}):")
            for test in failed_tests:
                print(f"  - {test['test_name']}: {test.get('error', 'Erreur inconnue')}")

    def _analyze_by_category(self):
        """
        Analyse les rÃ©sultats par catÃ©gorie de test
        """
        categories = {
            "Produits": ["Prix", "Couches", "Taille", "Comparaison"],
            "Livraison": ["Livraison", "DÃ©lais", "Yopougon", "Abidjan"],
            "Paiement": ["Paiement", "Wave", "Acompte", "Commande"],
            "Support": ["Contact", "WhatsApp", "TÃ©lÃ©phone", "Horaires"],
            "Conversationnel": ["Conseil", "ComplÃ¨te", "Ã‰conomique", "Secteur"],
            "IdentitÃ©": ["PrÃ©sentation", "Mission", "Entreprise"]
        }
        
        print(f"\nğŸ“Š ANALYSE PAR CATÃ‰GORIE:")
        
        for category, keywords in categories.items():
            category_tests = [
                t for t in self.test_results 
                if any(keyword in t["test_name"] for keyword in keywords)
            ]
            
            if category_tests:
                success_count = len([t for t in category_tests if t["status"] == "SUCCESS"])
                success_rate = (success_count / len(category_tests)) * 100
                avg_score = sum(t.get("performance_score", 0) for t in category_tests if t["status"] == "SUCCESS")
                avg_score = avg_score / success_count if success_count > 0 else 0
                
                status_icon = "âœ…" if success_rate >= 90 else "âš ï¸" if success_rate >= 70 else "âŒ"
                print(f"  {status_icon} {category}: {success_count}/{len(category_tests)} ({success_rate:.0f}%) - Score: {avg_score:.0f}/100")

async def main():
    """
    Fonction principale
    """
    print("ğŸ¼ TEST ULTIME RUE_DU_GROS - COUCHES BÃ‰BÃ‰ & PUÃ‰RICULTURE")
    print("=" * 70)
    print("ğŸ¯ Tests basÃ©s sur les donnÃ©es rÃ©elles de l'entreprise")
    print("ğŸ“‹ Couverture complÃ¨te: Produits, Livraison, Paiement, Support")
    
    tester = RueDuGrosUltimateTest()
    await tester.run_ultimate_test_suite()

if __name__ == "__main__":
    asyncio.run(main())
